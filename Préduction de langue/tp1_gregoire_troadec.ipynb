{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zsl01VoVzqw1"
   },
   "source": [
    "#Détection de la langue d'un texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JRncvE0bG9H"
   },
   "source": [
    "**Le but de ce projet est de programmer un classifieur permettant de détecter la langue d'un texte à partir de la fréquence des bigrammes de ce dernier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5h2d3wAPs1d"
   },
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ukOAFtwO2Ov"
   },
   "source": [
    "On récupère les corpus de d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2I1R9Z_hss2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mmj2hOWwNcDQ",
    "outputId": "15737b51-4881-40d9-cb00-5f9a144c765b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/\n",
      "train/uk_iu-ud-train.txt\n",
      "train/zh_gsd-ud-train.txt\n",
      "train/la_ittb-ud-train.txt\n",
      "train/af_afribooms-ud-train.txt\n",
      "train/be_hse-ud-train.txt\n",
      "train/cs_cac-ud-train.txt\n",
      "train/fro_srcmf-ud-train.txt\n",
      "train/hsb_ufal-ud-train.txt\n",
      "train/mt_mudt-ud-train.txt\n",
      "train/mr_ufal-ud-train.txt\n",
      "train/en_lines-ud-train.txt\n",
      "train/fr_sequoia-ud-train.txt\n",
      "train/cu_proiel-ud-train.txt\n",
      "train/fi_ftb-ud-train.txt\n",
      "train/ro_rrt-ud-train.txt\n",
      "train/sv_talbanken-ud-train.txt\n",
      "train/hi_hdtb-ud-train.txt\n",
      "train/en_esl-ud-train.txt\n",
      "train/pl_sz-ud-train.txt\n",
      "train/cs_pdt-ud-train.txt\n",
      "train/bg_btb-ud-train.txt\n",
      "train/el_gdt-ud-train.txt\n",
      "train/fr_partut-ud-train.txt\n",
      "train/sme_giella-ud-train.txt\n",
      "train/da_ddt-ud-train.txt\n",
      "train/qhe_hiencs-ud-train.txt\n",
      "train/lv_lvtb-ud-train.txt\n",
      "train/no_nynorsk-ud-train.txt\n",
      "train/cs_fictree-ud-train.txt\n",
      "train/en_ewt-ud-train.txt\n",
      "train/ga_idt-ud-train.txt\n",
      "train/fr_spoken-ud-train.txt\n",
      "train/ca_ancora-ud-train.txt\n",
      "train/sl_sst-ud-train.txt\n",
      "train/ur_udtb-ud-train.txt\n",
      "train/got_proiel-ud-train.txt\n",
      "train/te_mtg-ud-train.txt\n",
      "train/eu_bdt-ud-train.txt\n",
      "train/sk_snk-ud-train.txt\n",
      "train/fa_seraji-ud-train.txt\n",
      "train/grc_proiel-ud-train.txt\n",
      "train/fr_ftb-ud-train.txt\n",
      "train/sl_ssj-ud-train.txt\n",
      "train/bxr_bdt-ud-train.txt\n",
      "train/pl_lfg-ud-train.txt\n",
      "train/sv_lines-ud-train.txt\n",
      "train/ja_gsd-ud-train.txt\n",
      "train/et_edt-ud-train.txt\n",
      "train/hu_szeged-ud-train.txt\n",
      "train/he_htb-ud-train.txt\n",
      "train/ta_ttb-ud-train.txt\n",
      "train/hr_set-ud-train.txt\n",
      "train/grc_perseus-ud-train.txt\n",
      "train/ko_kaist-ud-train.txt\n",
      "train/ru_gsd-ud-train.txt\n",
      "train/kk_ktb-ud-train.txt\n",
      "train/no_nynorsklia-ud-train.txt\n",
      "train/gl_treegal-ud-train.txt\n",
      "train/nl_lassysmall-ud-train.txt\n",
      "train/sr_set-ud-train.txt\n",
      "train/ru_syntagrus-ud-train.txt\n",
      "train/es_ancora-ud-train.txt\n",
      "train/ug_udt-ud-train.txt\n",
      "train/pt_gsd-ud-train.txt\n",
      "train/ru_taiga-ud-train.txt\n",
      "train/en_gum-ud-train.txt\n",
      "train/pt_bosque-ud-train.txt\n",
      "train/de_gsd-ud-train.txt\n",
      "train/it_isdt-ud-train.txt\n",
      "train/id_gsd-ud-train.txt\n",
      "train/fr_gsd-ud-train.txt\n",
      "train/it_postwita-ud-train.txt\n",
      "train/es_gsd-ud-train.txt\n",
      "train/kmr_mg-ud-train.txt\n",
      "train/cs_cltt-ud-train.txt\n",
      "train/tr_imst-ud-train.txt\n",
      "train/swl_sslc-ud-train.txt\n",
      "train/ja_bccwj-ud-train.txt\n",
      "train/en_partut-ud-train.txt\n",
      "train/lt_hse-ud-train.txt\n",
      "train/cop_scriptorium-ud-train.txt\n",
      "train/la_perseus-ud-train.txt\n",
      "train/gl_ctg-ud-train.txt\n",
      "train/nl_alpino-ud-train.txt\n",
      "train/ko_gsd-ud-train.txt\n",
      "train/ar_nyuad-ud-train.txt\n",
      "train/it_partut-ud-train.txt\n",
      "train/ro_nonstandard-ud-train.txt\n",
      "train/la_proiel-ud-train.txt\n",
      "train/no_bokmaal-ud-train.txt\n",
      "train/ar_padt-ud-train.txt\n",
      "train/fi_tdt-ud-train.txt\n",
      "train/vi_vtb-ud-train.txt\n",
      "train/hy_armtdp-ud-train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'train.tgz': No such file or directory\n",
      "--2021-02-24 07:54:12--  http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_Apprentissage_Automatique/train.tgz\n",
      "Resolving pageperso.lif.univ-mrs.fr (pageperso.lif.univ-mrs.fr)... 139.124.22.27\n",
      "Connecting to pageperso.lif.univ-mrs.fr (pageperso.lif.univ-mrs.fr)|139.124.22.27|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29281190 (28M) [application/x-gzip]\n",
      "Saving to: ‘train.tgz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  240K 1m59s\n",
      "    50K .......... .......... .......... .......... ..........  0%  475K 89s\n",
      "   100K .......... .......... .......... .......... ..........  0% 60.8M 60s\n",
      "   150K .......... .......... .......... .......... ..........  0% 73.4M 45s\n",
      "   200K .......... .......... .......... .......... ..........  0%  493K 47s\n",
      "   250K .......... .......... .......... .......... ..........  1%  206M 39s\n",
      "   300K .......... .......... .......... .......... ..........  1%  278M 34s\n",
      "   350K .......... .......... .......... .......... ..........  1%  289M 29s\n",
      "   400K .......... .......... .......... .......... ..........  1%  497K 32s\n",
      "   450K .......... .......... .......... .......... ..........  1%  109M 29s\n",
      "   500K .......... .......... .......... .......... ..........  1%  115M 26s\n",
      "   550K .......... .......... .......... .......... ..........  2%  249M 24s\n",
      "   600K .......... .......... .......... .......... ..........  2% 55.5M 22s\n",
      "   650K .......... .......... .......... .......... ..........  2%  230M 21s\n",
      "   700K .......... .......... .......... .......... ..........  2%  288M 19s\n",
      "   750K .......... .......... .......... .......... ..........  2%  152M 18s\n",
      "   800K .......... .......... .......... .......... ..........  2%  512K 20s\n",
      "   850K .......... .......... .......... .......... ..........  3% 64.0M 19s\n",
      "   900K .......... .......... .......... .......... ..........  3%  285M 18s\n",
      "   950K .......... .......... .......... .......... ..........  3% 55.0M 17s\n",
      "  1000K .......... .......... .......... .......... ..........  3% 50.9M 16s\n",
      "  1050K .......... .......... .......... .......... ..........  3%  338M 16s\n",
      "  1100K .......... .......... .......... .......... ..........  4%  331M 15s\n",
      "  1150K .......... .......... .......... .......... ..........  4%  398M 14s\n",
      "  1200K .......... .......... .......... .......... ..........  4% 27.6M 14s\n",
      "  1250K .......... .......... .......... .......... ..........  4% 63.0M 13s\n",
      "  1300K .......... .......... .......... .......... ..........  4%  274M 13s\n",
      "  1350K .......... .......... .......... .......... ..........  4%  265M 12s\n",
      "  1400K .......... .......... .......... .......... ..........  5%  345M 12s\n",
      "  1450K .......... .......... .......... .......... ..........  5%  361M 11s\n",
      "  1500K .......... .......... .......... .......... ..........  5%  281M 11s\n",
      "  1550K .......... .......... .......... .......... ..........  5%  212M 11s\n",
      "  1600K .......... .......... .......... .......... ..........  5%  290M 10s\n",
      "  1650K .......... .......... .......... .......... ..........  5%  530K 11s\n",
      "  1700K .......... .......... .......... .......... ..........  6% 87.1M 11s\n",
      "  1750K .......... .......... .......... .......... ..........  6%  442M 11s\n",
      "  1800K .......... .......... .......... .......... ..........  6%  137M 10s\n",
      "  1850K .......... .......... .......... .......... ..........  6%  136M 10s\n",
      "  1900K .......... .......... .......... .......... ..........  6% 78.5M 10s\n",
      "  1950K .......... .......... .......... .......... ..........  6% 83.0M 10s\n",
      "  2000K .......... .......... .......... .......... ..........  7% 81.6M 9s\n",
      "  2050K .......... .......... .......... .......... ..........  7%  426M 9s\n",
      "  2100K .......... .......... .......... .......... ..........  7%  143M 9s\n",
      "  2150K .......... .......... .......... .......... ..........  7% 93.9M 9s\n",
      "  2200K .......... .......... .......... .......... ..........  7% 70.5M 8s\n",
      "  2250K .......... .......... .......... .......... ..........  8% 58.9M 8s\n",
      "  2300K .......... .......... .......... .......... ..........  8% 76.7M 8s\n",
      "  2350K .......... .......... .......... .......... ..........  8% 79.9M 8s\n",
      "  2400K .......... .......... .......... .......... ..........  8% 78.4M 8s\n",
      "  2450K .......... .......... .......... .......... ..........  8% 65.9M 8s\n",
      "  2500K .......... .......... .......... .......... ..........  8%  399M 7s\n",
      "  2550K .......... .......... .......... .......... ..........  9%  320M 7s\n",
      "  2600K .......... .......... .......... .......... ..........  9%  453M 7s\n",
      "  2650K .......... .......... .......... .......... ..........  9%  330M 7s\n",
      "  2700K .......... .......... .......... .......... ..........  9%  428M 7s\n",
      "  2750K .......... .......... .......... .......... ..........  9% 74.5M 7s\n",
      "  2800K .......... .......... .......... .......... ..........  9% 62.2M 7s\n",
      "  2850K .......... .......... .......... .......... .......... 10% 93.6M 6s\n",
      "  2900K .......... .......... .......... .......... .......... 10% 85.4M 6s\n",
      "  2950K .......... .......... .......... .......... .......... 10%  222M 6s\n",
      "  3000K .......... .......... .......... .......... .......... 10%  218M 6s\n",
      "  3050K .......... .......... .......... .......... .......... 10%  151M 6s\n",
      "  3100K .......... .......... .......... .......... .......... 11%  390M 6s\n",
      "  3150K .......... .......... .......... .......... .......... 11% 33.3M 6s\n",
      "  3200K .......... .......... .......... .......... .......... 11%  394M 6s\n",
      "  3250K .......... .......... .......... .......... .......... 11%  477M 6s\n",
      "  3300K .......... .......... .......... .......... .......... 11% 89.5M 6s\n",
      "  3350K .......... .......... .......... .......... .......... 11%  575K 6s\n",
      "  3400K .......... .......... .......... .......... .......... 12%  298M 6s\n",
      "  3450K .......... .......... .......... .......... .......... 12% 53.5M 6s\n",
      "  3500K .......... .......... .......... .......... .......... 12% 59.4M 6s\n",
      "  3550K .......... .......... .......... .......... .......... 12%  239M 6s\n",
      "  3600K .......... .......... .......... .......... .......... 12%  464M 6s\n",
      "  3650K .......... .......... .......... .......... .......... 12% 95.4M 6s\n",
      "  3700K .......... .......... .......... .......... .......... 13% 68.0M 5s\n",
      "  3750K .......... .......... .......... .......... .......... 13%  397M 5s\n",
      "  3800K .......... .......... .......... .......... .......... 13%  405M 5s\n",
      "  3850K .......... .......... .......... .......... .......... 13%  177M 5s\n",
      "  3900K .......... .......... .......... .......... .......... 13% 64.7M 5s\n",
      "  3950K .......... .......... .......... .......... .......... 13% 60.1M 5s\n",
      "  4000K .......... .......... .......... .......... .......... 14%  155M 5s\n",
      "  4050K .......... .......... .......... .......... .......... 14% 75.2M 5s\n",
      "  4100K .......... .......... .......... .......... .......... 14%  518M 5s\n",
      "  4150K .......... .......... .......... .......... .......... 14%  377M 5s\n",
      "  4200K .......... .......... .......... .......... .......... 14% 60.7M 5s\n",
      "  4250K .......... .......... .......... .......... .......... 15% 81.5M 5s\n",
      "  4300K .......... .......... .......... .......... .......... 15%  189M 5s\n",
      "  4350K .......... .......... .......... .......... .......... 15% 57.1M 5s\n",
      "  4400K .......... .......... .......... .......... .......... 15% 70.2M 5s\n",
      "  4450K .......... .......... .......... .......... .......... 15% 89.3M 4s\n",
      "  4500K .......... .......... .......... .......... .......... 15%  466M 4s\n",
      "  4550K .......... .......... .......... .......... .......... 16%  314M 4s\n",
      "  4600K .......... .......... .......... .......... .......... 16%  329M 4s\n",
      "  4650K .......... .......... .......... .......... .......... 16%  415M 4s\n",
      "  4700K .......... .......... .......... .......... .......... 16% 65.5M 4s\n",
      "  4750K .......... .......... .......... .......... .......... 16% 66.3M 4s\n",
      "  4800K .......... .......... .......... .......... .......... 16% 79.9M 4s\n",
      "  4850K .......... .......... .......... .......... .......... 17%  219M 4s\n",
      "  4900K .......... .......... .......... .......... .......... 17%  464M 4s\n",
      "  4950K .......... .......... .......... .......... .......... 17%  445M 4s\n",
      "  5000K .......... .......... .......... .......... .......... 17% 95.9M 4s\n",
      "  5050K .......... .......... .......... .......... .......... 17% 73.7M 4s\n",
      "  5100K .......... .......... .......... .......... .......... 18% 58.1M 4s\n",
      "  5150K .......... .......... .......... .......... .......... 18% 82.5M 4s\n",
      "  5200K .......... .......... .......... .......... .......... 18%  289M 4s\n",
      "  5250K .......... .......... .......... .......... .......... 18%  230M 4s\n",
      "  5300K .......... .......... .......... .......... .......... 18% 58.7M 4s\n",
      "  5350K .......... .......... .......... .......... .......... 18%  280M 4s\n",
      "  5400K .......... .......... .......... .......... .......... 19%  413M 4s\n",
      "  5450K .......... .......... .......... .......... .......... 19% 67.2M 4s\n",
      "  5500K .......... .......... .......... .......... .......... 19% 82.0M 3s\n",
      "  5550K .......... .......... .......... .......... .......... 19%  470M 3s\n",
      "  5600K .......... .......... .......... .......... .......... 19% 78.2M 3s\n",
      "  5650K .......... .......... .......... .......... .......... 19% 67.1M 3s\n",
      "  5700K .......... .......... .......... .......... .......... 20%  326M 3s\n",
      "  5750K .......... .......... .......... .......... .......... 20%  455M 3s\n",
      "  5800K .......... .......... .......... .......... .......... 20%  196M 3s\n",
      "  5850K .......... .......... .......... .......... .......... 20% 70.3M 3s\n",
      "  5900K .......... .......... .......... .......... .......... 20% 69.9M 3s\n",
      "  5950K .......... .......... .......... .......... .......... 20%  215M 3s\n",
      "  6000K .......... .......... .......... .......... .......... 21%  397M 3s\n",
      "  6050K .......... .......... .......... .......... .......... 21% 82.0M 3s\n",
      "  6100K .......... .......... .......... .......... .......... 21% 38.2M 3s\n",
      "  6150K .......... .......... .......... .......... .......... 21% 74.9M 3s\n",
      "  6200K .......... .......... .......... .......... .......... 21% 83.8M 3s\n",
      "  6250K .......... .......... .......... .......... .......... 22%  216M 3s\n",
      "  6300K .......... .......... .......... .......... .......... 22%  252M 3s\n",
      "  6350K .......... .......... .......... .......... .......... 22%  665K 3s\n",
      "  6400K .......... .......... .......... .......... .......... 22% 76.9M 3s\n",
      "  6450K .......... .......... .......... .......... .......... 22% 53.6M 3s\n",
      "  6500K .......... .......... .......... .......... .......... 22% 97.2M 3s\n",
      "  6550K .......... .......... .......... .......... .......... 23% 77.1M 3s\n",
      "  6600K .......... .......... .......... .......... .......... 23% 62.4M 3s\n",
      "  6650K .......... .......... .......... .......... .......... 23% 75.7M 3s\n",
      "  6700K .......... .......... .......... .......... .......... 23%  148M 3s\n",
      "  6750K .......... .......... .......... .......... .......... 23%  170M 3s\n",
      "  6800K .......... .......... .......... .......... .......... 23% 86.4M 3s\n",
      "  6850K .......... .......... .......... .......... .......... 24% 87.7M 3s\n",
      "  6900K .......... .......... .......... .......... .......... 24% 99.7M 3s\n",
      "  6950K .......... .......... .......... .......... .......... 24% 42.6M 3s\n",
      "  7000K .......... .......... .......... .......... .......... 24% 69.2M 3s\n",
      "  7050K .......... .......... .......... .......... .......... 24%  134M 3s\n",
      "  7100K .......... .......... .......... .......... .......... 25%  137M 3s\n",
      "  7150K .......... .......... .......... .......... .......... 25%  428M 3s\n",
      "  7200K .......... .......... .......... .......... .......... 25% 61.9M 3s\n",
      "  7250K .......... .......... .......... .......... .......... 25% 90.0M 3s\n",
      "  7300K .......... .......... .......... .......... .......... 25% 79.0M 3s\n",
      "  7350K .......... .......... .......... .......... .......... 25% 88.3M 3s\n",
      "  7400K .......... .......... .......... .......... .......... 26%  430M 3s\n",
      "  7450K .......... .......... .......... .......... .......... 26% 85.2M 3s\n",
      "  7500K .......... .......... .......... .......... .......... 26% 76.8M 3s\n",
      "  7550K .......... .......... .......... .......... .......... 26%  431M 3s\n",
      "  7600K .......... .......... .......... .......... .......... 26% 2.60M 3s\n",
      "  7650K .......... .......... .......... .......... .......... 26% 81.7M 3s\n",
      "  7700K .......... .......... .......... .......... .......... 27%  231M 3s\n",
      "  7750K .......... .......... .......... .......... .......... 27% 49.1M 3s\n",
      "  7800K .......... .......... .......... .......... .......... 27% 92.3M 3s\n",
      "  7850K .......... .......... .......... .......... .......... 27% 78.5M 3s\n",
      "  7900K .......... .......... .......... .......... .......... 27%  182M 2s\n",
      "  7950K .......... .......... .......... .......... .......... 27% 45.6M 2s\n",
      "  8000K .......... .......... .......... .......... .......... 28% 67.4M 2s\n",
      "  8050K .......... .......... .......... .......... .......... 28% 59.0M 2s\n",
      "  8100K .......... .......... .......... .......... .......... 28% 44.9M 2s\n",
      "  8150K .......... .......... .......... .......... .......... 28% 81.3M 2s\n",
      "  8200K .......... .......... .......... .......... .......... 28%  118M 2s\n",
      "  8250K .......... .......... .......... .......... .......... 29%  532M 2s\n",
      "  8300K .......... .......... .......... .......... .......... 29%  533M 2s\n",
      "  8350K .......... .......... .......... .......... .......... 29% 83.4M 2s\n",
      "  8400K .......... .......... .......... .......... .......... 29%  236M 2s\n",
      "  8450K .......... .......... .......... .......... .......... 29% 93.1M 2s\n",
      "  8500K .......... .......... .......... .......... .......... 29%  101M 2s\n",
      "  8550K .......... .......... .......... .......... .......... 30%  137M 2s\n",
      "  8600K .......... .......... .......... .......... .......... 30%  135M 2s\n",
      "  8650K .......... .......... .......... .......... .......... 30%  105M 2s\n",
      "  8700K .......... .......... .......... .......... .......... 30% 84.6M 2s\n",
      "  8750K .......... .......... .......... .......... .......... 30% 69.1M 2s\n",
      "  8800K .......... .......... .......... .......... .......... 30% 79.6M 2s\n",
      "  8850K .......... .......... .......... .......... .......... 31%  429M 2s\n",
      "  8900K .......... .......... .......... .......... .......... 31% 55.0M 2s\n",
      "  8950K .......... .......... .......... .......... .......... 31%  181M 2s\n",
      "  9000K .......... .......... .......... .......... .......... 31%  161M 2s\n",
      "  9050K .......... .......... .......... .......... .......... 31%  109M 2s\n",
      "  9100K .......... .......... .......... .......... .......... 31%  111M 2s\n",
      "  9150K .......... .......... .......... .......... .......... 32% 85.1M 2s\n",
      "  9200K .......... .......... .......... .......... .......... 32% 94.1M 2s\n",
      "  9250K .......... .......... .......... .......... .......... 32%  112M 2s\n",
      "  9300K .......... .......... .......... .......... .......... 32%  958K 2s\n",
      "  9350K .......... .......... .......... .......... .......... 32%  148M 2s\n",
      "  9400K .......... .......... .......... .......... .......... 33%  199M 2s\n",
      "  9450K .......... .......... .......... .......... .......... 33% 60.4M 2s\n",
      "  9500K .......... .......... .......... .......... .......... 33%  155M 2s\n",
      "  9550K .......... .......... .......... .......... .......... 33% 56.0M 2s\n",
      "  9600K .......... .......... .......... .......... .......... 33% 82.3M 2s\n",
      "  9650K .......... .......... .......... .......... .......... 33% 83.0M 2s\n",
      "  9700K .......... .......... .......... .......... .......... 34% 63.6M 2s\n",
      "  9750K .......... .......... .......... .......... .......... 34%  152M 2s\n",
      "  9800K .......... .......... .......... .......... .......... 34% 51.1M 2s\n",
      "  9850K .......... .......... .......... .......... .......... 34%  372M 2s\n",
      "  9900K .......... .......... .......... .......... .......... 34% 79.0M 2s\n",
      "  9950K .......... .......... .......... .......... .......... 34% 42.4M 2s\n",
      " 10000K .......... .......... .......... .......... .......... 35% 77.5M 2s\n",
      " 10050K .......... .......... .......... .......... .......... 35%  211M 2s\n",
      " 10100K .......... .......... .......... .......... .......... 35% 76.8M 2s\n",
      " 10150K .......... .......... .......... .......... .......... 35%  406M 2s\n",
      " 10200K .......... .......... .......... .......... .......... 35% 80.1M 2s\n",
      " 10250K .......... .......... .......... .......... .......... 36% 44.0M 2s\n",
      " 10300K .......... .......... .......... .......... .......... 36% 2.36M 2s\n",
      " 10350K .......... .......... .......... .......... .......... 36% 54.5M 2s\n",
      " 10400K .......... .......... .......... .......... .......... 36% 77.0M 2s\n",
      " 10450K .......... .......... .......... .......... .......... 36%  104M 2s\n",
      " 10500K .......... .......... .......... .......... .......... 36%  284M 2s\n",
      " 10550K .......... .......... .......... .......... .......... 37%  397M 2s\n",
      " 10600K .......... .......... .......... .......... .......... 37% 47.0M 2s\n",
      " 10650K .......... .......... .......... .......... .......... 37% 88.1M 2s\n",
      " 10700K .......... .......... .......... .......... .......... 37%  328M 2s\n",
      " 10750K .......... .......... .......... .......... .......... 37% 56.8M 2s\n",
      " 10800K .......... .......... .......... .......... .......... 37%  394M 2s\n",
      " 10850K .......... .......... .......... .......... .......... 38% 87.9M 2s\n",
      " 10900K .......... .......... .......... .......... .......... 38% 69.2M 2s\n",
      " 10950K .......... .......... .......... .......... .......... 38%  192M 2s\n",
      " 11000K .......... .......... .......... .......... .......... 38%  127M 2s\n",
      " 11050K .......... .......... .......... .......... .......... 38% 81.2M 2s\n",
      " 11100K .......... .......... .......... .......... .......... 38%  123M 2s\n",
      " 11150K .......... .......... .......... .......... .......... 39%  123M 2s\n",
      " 11200K .......... .......... .......... .......... .......... 39%  103M 2s\n",
      " 11250K .......... .......... .......... .......... .......... 39%  186M 2s\n",
      " 11300K .......... .......... .......... .......... .......... 39% 39.0M 2s\n",
      " 11350K .......... .......... .......... .......... .......... 39%  421M 2s\n",
      " 11400K .......... .......... .......... .......... .......... 40%  527M 2s\n",
      " 11450K .......... .......... .......... .......... .......... 40%  116M 2s\n",
      " 11500K .......... .......... .......... .......... .......... 40% 93.3M 2s\n",
      " 11550K .......... .......... .......... .......... .......... 40%  179M 2s\n",
      " 11600K .......... .......... .......... .......... .......... 40%  118M 2s\n",
      " 11650K .......... .......... .......... .......... .......... 40% 56.0M 2s\n",
      " 11700K .......... .......... .......... .......... .......... 41% 38.9M 2s\n",
      " 11750K .......... .......... .......... .......... .......... 41% 78.2M 2s\n",
      " 11800K .......... .......... .......... .......... .......... 41%  142M 2s\n",
      " 11850K .......... .......... .......... .......... .......... 41%  207M 2s\n",
      " 11900K .......... .......... .......... .......... .......... 41% 68.9M 1s\n",
      " 11950K .......... .......... .......... .......... .......... 41%  285M 1s\n",
      " 12000K .......... .......... .......... .......... .......... 42% 85.9M 1s\n",
      " 12050K .......... .......... .......... .......... .......... 42% 77.2M 1s\n",
      " 12100K .......... .......... .......... .......... .......... 42% 57.4M 1s\n",
      " 12150K .......... .......... .......... .......... .......... 42%  531M 1s\n",
      " 12200K .......... .......... .......... .......... .......... 42%  358M 1s\n",
      " 12250K .......... .......... .......... .......... .......... 43% 93.7M 1s\n",
      " 12300K .......... .......... .......... .......... .......... 43% 79.1M 1s\n",
      " 12350K .......... .......... .......... .......... .......... 43%  998K 1s\n",
      " 12400K .......... .......... .......... .......... .......... 43%  185M 1s\n",
      " 12450K .......... .......... .......... .......... .......... 43%  161M 1s\n",
      " 12500K .......... .......... .......... .......... .......... 43%  130M 1s\n",
      " 12550K .......... .......... .......... .......... .......... 44%  112M 1s\n",
      " 12600K .......... .......... .......... .......... .......... 44% 61.9M 1s\n",
      " 12650K .......... .......... .......... .......... .......... 44% 58.4M 1s\n",
      " 12700K .......... .......... .......... .......... .......... 44% 69.9M 1s\n",
      " 12750K .......... .......... .......... .......... .......... 44%  152M 1s\n",
      " 12800K .......... .......... .......... .......... .......... 44%  122M 1s\n",
      " 12850K .......... .......... .......... .......... .......... 45% 41.7M 1s\n",
      " 12900K .......... .......... .......... .......... .......... 45% 91.2M 1s\n",
      " 12950K .......... .......... .......... .......... .......... 45%  114M 1s\n",
      " 13000K .......... .......... .......... .......... .......... 45%  112M 1s\n",
      " 13050K .......... .......... .......... .......... .......... 45% 1.96M 1s\n",
      " 13100K .......... .......... .......... .......... .......... 45%  146M 1s\n",
      " 13150K .......... .......... .......... .......... .......... 46%  129M 1s\n",
      " 13200K .......... .......... .......... .......... .......... 46%  409M 1s\n",
      " 13250K .......... .......... .......... .......... .......... 46% 48.9M 1s\n",
      " 13300K .......... .......... .......... .......... .......... 46%  131M 1s\n",
      " 13350K .......... .......... .......... .......... .......... 46%  445M 1s\n",
      " 13400K .......... .......... .......... .......... .......... 47% 72.8M 1s\n",
      " 13450K .......... .......... .......... .......... .......... 47%  333M 1s\n",
      " 13500K .......... .......... .......... .......... .......... 47%  102M 1s\n",
      " 13550K .......... .......... .......... .......... .......... 47% 82.0M 1s\n",
      " 13600K .......... .......... .......... .......... .......... 47%  384M 1s\n",
      " 13650K .......... .......... .......... .......... .......... 47% 49.4M 1s\n",
      " 13700K .......... .......... .......... .......... .......... 48%  212M 1s\n",
      " 13750K .......... .......... .......... .......... .......... 48% 78.7M 1s\n",
      " 13800K .......... .......... .......... .......... .......... 48% 97.3M 1s\n",
      " 13850K .......... .......... .......... .......... .......... 48%  439M 1s\n",
      " 13900K .......... .......... .......... .......... .......... 48% 80.3M 1s\n",
      " 13950K .......... .......... .......... .......... .......... 48%  132M 1s\n",
      " 14000K .......... .......... .......... .......... .......... 49% 75.0M 1s\n",
      " 14050K .......... .......... .......... .......... .......... 49% 74.6M 1s\n",
      " 14100K .......... .......... .......... .......... .......... 49% 65.2M 1s\n",
      " 14150K .......... .......... .......... .......... .......... 49%  252M 1s\n",
      " 14200K .......... .......... .......... .......... .......... 49%  426M 1s\n",
      " 14250K .......... .......... .......... .......... .......... 50%  383M 1s\n",
      " 14300K .......... .......... .......... .......... .......... 50%  194M 1s\n",
      " 14350K .......... .......... .......... .......... .......... 50% 63.5M 1s\n",
      " 14400K .......... .......... .......... .......... .......... 50% 50.5M 1s\n",
      " 14450K .......... .......... .......... .......... .......... 50% 29.4M 1s\n",
      " 14500K .......... .......... .......... .......... .......... 50% 75.1M 1s\n",
      " 14550K .......... .......... .......... .......... .......... 51% 97.8M 1s\n",
      " 14600K .......... .......... .......... .......... .......... 51%  482M 1s\n",
      " 14650K .......... .......... .......... .......... .......... 51% 99.0M 1s\n",
      " 14700K .......... .......... .......... .......... .......... 51%  121M 1s\n",
      " 14750K .......... .......... .......... .......... .......... 51%  184M 1s\n",
      " 14800K .......... .......... .......... .......... .......... 51%  132M 1s\n",
      " 14850K .......... .......... .......... .......... .......... 52% 82.5M 1s\n",
      " 14900K .......... .......... .......... .......... .......... 52% 50.9M 1s\n",
      " 14950K .......... .......... .......... .......... .......... 52% 86.1M 1s\n",
      " 15000K .......... .......... .......... .......... .......... 52% 85.1M 1s\n",
      " 15050K .......... .......... .......... .......... .......... 52%  236M 1s\n",
      " 15100K .......... .......... .......... .......... .......... 52%  126M 1s\n",
      " 15150K .......... .......... .......... .......... .......... 53%  192M 1s\n",
      " 15200K .......... .......... .......... .......... .......... 53%  132M 1s\n",
      " 15250K .......... .......... .......... .......... .......... 53% 82.8M 1s\n",
      " 15300K .......... .......... .......... .......... .......... 53% 86.0M 1s\n",
      " 15350K .......... .......... .......... .......... .......... 53% 1.92M 1s\n",
      " 15400K .......... .......... .......... .......... .......... 54% 2.22M 1s\n",
      " 15450K .......... .......... .......... .......... .......... 54% 51.1M 1s\n",
      " 15500K .......... .......... .......... .......... .......... 54%  195M 1s\n",
      " 15550K .......... .......... .......... .......... .......... 54%  409M 1s\n",
      " 15600K .......... .......... .......... .......... .......... 54% 55.9M 1s\n",
      " 15650K .......... .......... .......... .......... .......... 54% 77.9M 1s\n",
      " 15700K .......... .......... .......... .......... .......... 55%  475M 1s\n",
      " 15750K .......... .......... .......... .......... .......... 55% 45.1M 1s\n",
      " 15800K .......... .......... .......... .......... .......... 55%  123M 1s\n",
      " 15850K .......... .......... .......... .......... .......... 55% 63.1M 1s\n",
      " 15900K .......... .......... .......... .......... .......... 55%  185M 1s\n",
      " 15950K .......... .......... .......... .......... .......... 55% 72.2M 1s\n",
      " 16000K .......... .......... .......... .......... .......... 56% 42.6M 1s\n",
      " 16050K .......... .......... .......... .......... .......... 56% 87.7M 1s\n",
      " 16100K .......... .......... .......... .......... .......... 56% 2.04M 1s\n",
      " 16150K .......... .......... .......... .......... .......... 56% 68.4M 1s\n",
      " 16200K .......... .......... .......... .......... .......... 56%  488M 1s\n",
      " 16250K .......... .......... .......... .......... .......... 57% 56.3M 1s\n",
      " 16300K .......... .......... .......... .......... .......... 57% 64.8M 1s\n",
      " 16350K .......... .......... .......... .......... .......... 57% 82.1M 1s\n",
      " 16400K .......... .......... .......... .......... .......... 57% 19.0M 1s\n",
      " 16450K .......... .......... .......... .......... .......... 57% 86.1M 1s\n",
      " 16500K .......... .......... .......... .......... .......... 57%  238M 1s\n",
      " 16550K .......... .......... .......... .......... .......... 58%  473M 1s\n",
      " 16600K .......... .......... .......... .......... .......... 58% 71.2M 1s\n",
      " 16650K .......... .......... .......... .......... .......... 58%  134M 1s\n",
      " 16700K .......... .......... .......... .......... .......... 58% 81.2M 1s\n",
      " 16750K .......... .......... .......... .......... .......... 58%  139M 1s\n",
      " 16800K .......... .......... .......... .......... .......... 58%  292M 1s\n",
      " 16850K .......... .......... .......... .......... .......... 59% 94.4M 1s\n",
      " 16900K .......... .......... .......... .......... .......... 59% 84.2M 1s\n",
      " 16950K .......... .......... .......... .......... .......... 59%  112M 1s\n",
      " 17000K .......... .......... .......... .......... .......... 59%  403M 1s\n",
      " 17050K .......... .......... .......... .......... .......... 59% 59.5M 1s\n",
      " 17100K .......... .......... .......... .......... .......... 59%  271M 1s\n",
      " 17150K .......... .......... .......... .......... .......... 60% 62.6M 1s\n",
      " 17200K .......... .......... .......... .......... .......... 60%  134M 1s\n",
      " 17250K .......... .......... .......... .......... .......... 60%  150M 1s\n",
      " 17300K .......... .......... .......... .......... .......... 60% 73.3M 1s\n",
      " 17350K .......... .......... .......... .......... .......... 60%  157M 1s\n",
      " 17400K .......... .......... .......... .......... .......... 61%  108M 1s\n",
      " 17450K .......... .......... .......... .......... .......... 61% 73.4M 1s\n",
      " 17500K .......... .......... .......... .......... .......... 61%  499M 1s\n",
      " 17550K .......... .......... .......... .......... .......... 61%  181M 1s\n",
      " 17600K .......... .......... .......... .......... .......... 61% 57.6M 1s\n",
      " 17650K .......... .......... .......... .......... .......... 61% 68.4M 1s\n",
      " 17700K .......... .......... .......... .......... .......... 62%  130M 1s\n",
      " 17750K .......... .......... .......... .......... .......... 62% 21.9M 1s\n",
      " 17800K .......... .......... .......... .......... .......... 62% 64.0M 1s\n",
      " 17850K .......... .......... .......... .......... .......... 62%  299M 1s\n",
      " 17900K .......... .......... .......... .......... .......... 62% 31.6M 1s\n",
      " 17950K .......... .......... .......... .......... .......... 62%  528M 1s\n",
      " 18000K .......... .......... .......... .......... .......... 63%  342M 1s\n",
      " 18050K .......... .......... .......... .......... .......... 63%  536M 1s\n",
      " 18100K .......... .......... .......... .......... .......... 63%  393M 1s\n",
      " 18150K .......... .......... .......... .......... .......... 63% 79.5M 1s\n",
      " 18200K .......... .......... .......... .......... .......... 63% 62.8M 1s\n",
      " 18250K .......... .......... .......... .......... .......... 63% 69.6M 1s\n",
      " 18300K .......... .......... .......... .......... .......... 64% 80.7M 1s\n",
      " 18350K .......... .......... .......... .......... .......... 64% 2.29M 1s\n",
      " 18400K .......... .......... .......... .......... .......... 64% 2.18M 1s\n",
      " 18450K .......... .......... .......... .......... .......... 64% 42.6M 1s\n",
      " 18500K .......... .......... .......... .......... .......... 64%  366M 1s\n",
      " 18550K .......... .......... .......... .......... .......... 65%  102M 1s\n",
      " 18600K .......... .......... .......... .......... .......... 65% 66.7M 1s\n",
      " 18650K .......... .......... .......... .......... .......... 65%  116M 1s\n",
      " 18700K .......... .......... .......... .......... .......... 65% 82.4M 1s\n",
      " 18750K .......... .......... .......... .......... .......... 65%  138M 1s\n",
      " 18800K .......... .......... .......... .......... .......... 65% 82.4M 1s\n",
      " 18850K .......... .......... .......... .......... .......... 66% 83.3M 1s\n",
      " 18900K .......... .......... .......... .......... .......... 66% 60.0M 1s\n",
      " 18950K .......... .......... .......... .......... .......... 66%  403M 1s\n",
      " 19000K .......... .......... .......... .......... .......... 66% 32.4M 1s\n",
      " 19050K .......... .......... .......... .......... .......... 66% 2.03M 1s\n",
      " 19100K .......... .......... .......... .......... .......... 66% 60.1M 1s\n",
      " 19150K .......... .......... .......... .......... .......... 67% 7.98M 1s\n",
      " 19200K .......... .......... .......... .......... .......... 67%  292M 1s\n",
      " 19250K .......... .......... .......... .......... .......... 67%  130M 1s\n",
      " 19300K .......... .......... .......... .......... .......... 67% 79.1M 1s\n",
      " 19350K .......... .......... .......... .......... .......... 67% 77.6M 1s\n",
      " 19400K .......... .......... .......... .......... .......... 68%  405M 1s\n",
      " 19450K .......... .......... .......... .......... .......... 68% 62.1M 1s\n",
      " 19500K .......... .......... .......... .......... .......... 68% 99.9M 1s\n",
      " 19550K .......... .......... .......... .......... .......... 68%  215M 1s\n",
      " 19600K .......... .......... .......... .......... .......... 68%  189M 1s\n",
      " 19650K .......... .......... .......... .......... .......... 68%  123M 1s\n",
      " 19700K .......... .......... .......... .......... .......... 69% 91.3M 1s\n",
      " 19750K .......... .......... .......... .......... .......... 69% 32.2M 1s\n",
      " 19800K .......... .......... .......... .......... .......... 69%  483M 1s\n",
      " 19850K .......... .......... .......... .......... .......... 69%  421M 1s\n",
      " 19900K .......... .......... .......... .......... .......... 69%  113M 1s\n",
      " 19950K .......... .......... .......... .......... .......... 69%  112M 1s\n",
      " 20000K .......... .......... .......... .......... .......... 70%  241M 1s\n",
      " 20050K .......... .......... .......... .......... .......... 70%  164M 1s\n",
      " 20100K .......... .......... .......... .......... .......... 70%  129M 1s\n",
      " 20150K .......... .......... .......... .......... .......... 70% 45.8M 1s\n",
      " 20200K .......... .......... .......... .......... .......... 70%  486M 1s\n",
      " 20250K .......... .......... .......... .......... .......... 70% 90.7M 1s\n",
      " 20300K .......... .......... .......... .......... .......... 71% 75.3M 1s\n",
      " 20350K .......... .......... .......... .......... .......... 71% 75.0M 1s\n",
      " 20400K .......... .......... .......... .......... .......... 71% 83.2M 1s\n",
      " 20450K .......... .......... .......... .......... .......... 71%  124M 1s\n",
      " 20500K .......... .......... .......... .......... .......... 71%  288M 1s\n",
      " 20550K .......... .......... .......... .......... .......... 72% 37.1M 1s\n",
      " 20600K .......... .......... .......... .......... .......... 72% 92.4M 1s\n",
      " 20650K .......... .......... .......... .......... .......... 72% 86.9M 1s\n",
      " 20700K .......... .......... .......... .......... .......... 72%  115M 1s\n",
      " 20750K .......... .......... .......... .......... .......... 72% 80.2M 1s\n",
      " 20800K .......... .......... .......... .......... .......... 72%  336M 1s\n",
      " 20850K .......... .......... .......... .......... .......... 73% 86.5M 1s\n",
      " 20900K .......... .......... .......... .......... .......... 73% 74.2M 1s\n",
      " 20950K .......... .......... .......... .......... .......... 73%  521M 0s\n",
      " 21000K .......... .......... .......... .......... .......... 73%  123M 0s\n",
      " 21050K .......... .......... .......... .......... .......... 73% 56.7M 0s\n",
      " 21100K .......... .......... .......... .......... .......... 73%  169M 0s\n",
      " 21150K .......... .......... .......... .......... .......... 74% 90.5M 0s\n",
      " 21200K .......... .......... .......... .......... .......... 74% 91.9M 0s\n",
      " 21250K .......... .......... .......... .......... .......... 74%  255M 0s\n",
      " 21300K .......... .......... .......... .......... .......... 74% 79.0M 0s\n",
      " 21350K .......... .......... .......... .......... .......... 74% 2.45M 0s\n",
      " 21400K .......... .......... .......... .......... .......... 75%  425M 0s\n",
      " 21450K .......... .......... .......... .......... .......... 75% 2.26M 0s\n",
      " 21500K .......... .......... .......... .......... .......... 75% 66.0M 0s\n",
      " 21550K .......... .......... .......... .......... .......... 75% 55.4M 0s\n",
      " 21600K .......... .......... .......... .......... .......... 75% 62.0M 0s\n",
      " 21650K .......... .......... .......... .......... .......... 75% 74.8M 0s\n",
      " 21700K .......... .......... .......... .......... .......... 76%  349M 0s\n",
      " 21750K .......... .......... .......... .......... .......... 76%  119M 0s\n",
      " 21800K .......... .......... .......... .......... .......... 76%  153M 0s\n",
      " 21850K .......... .......... .......... .......... .......... 76% 44.4M 0s\n",
      " 21900K .......... .......... .......... .......... .......... 76% 1.45M 0s\n",
      " 21950K .......... .......... .......... .......... .......... 76%  199M 0s\n",
      " 22000K .......... .......... .......... .......... .......... 77% 65.9M 0s\n",
      " 22050K .......... .......... .......... .......... .......... 77%  326M 0s\n",
      " 22100K .......... .......... .......... .......... .......... 77% 57.1M 0s\n",
      " 22150K .......... .......... .......... .......... .......... 77% 41.1M 0s\n",
      " 22200K .......... .......... .......... .......... .......... 77% 66.0M 0s\n",
      " 22250K .......... .......... .......... .......... .......... 77%  190M 0s\n",
      " 22300K .......... .......... .......... .......... .......... 78%  251M 0s\n",
      " 22350K .......... .......... .......... .......... .......... 78%  245M 0s\n",
      " 22400K .......... .......... .......... .......... .......... 78%  199M 0s\n",
      " 22450K .......... .......... .......... .......... .......... 78%  220M 0s\n",
      " 22500K .......... .......... .......... .......... .......... 78%  252M 0s\n",
      " 22550K .......... .......... .......... .......... .......... 79%  252M 0s\n",
      " 22600K .......... .......... .......... .......... .......... 79%  221M 0s\n",
      " 22650K .......... .......... .......... .......... .......... 79%  108M 0s\n",
      " 22700K .......... .......... .......... .......... .......... 79%  102M 0s\n",
      " 22750K .......... .......... .......... .......... .......... 79% 84.2M 0s\n",
      " 22800K .......... .......... .......... .......... .......... 79%  141M 0s\n",
      " 22850K .......... .......... .......... .......... .......... 80% 67.2M 0s\n",
      " 22900K .......... .......... .......... .......... .......... 80%  394M 0s\n",
      " 22950K .......... .......... .......... .......... .......... 80% 85.2M 0s\n",
      " 23000K .......... .......... .......... .......... .......... 80% 91.4M 0s\n",
      " 23050K .......... .......... .......... .......... .......... 80%  164M 0s\n",
      " 23100K .......... .......... .......... .......... .......... 80%  113M 0s\n",
      " 23150K .......... .......... .......... .......... .......... 81%  139M 0s\n",
      " 23200K .......... .......... .......... .......... .......... 81%  121M 0s\n",
      " 23250K .......... .......... .......... .......... .......... 81% 88.9M 0s\n",
      " 23300K .......... .......... .......... .......... .......... 81% 21.7M 0s\n",
      " 23350K .......... .......... .......... .......... .......... 81% 69.2M 0s\n",
      " 23400K .......... .......... .......... .......... .......... 82%  152M 0s\n",
      " 23450K .......... .......... .......... .......... .......... 82%  231M 0s\n",
      " 23500K .......... .......... .......... .......... .......... 82% 47.5M 0s\n",
      " 23550K .......... .......... .......... .......... .......... 82% 78.8M 0s\n",
      " 23600K .......... .......... .......... .......... .......... 82%  349M 0s\n",
      " 23650K .......... .......... .......... .......... .......... 82%  327M 0s\n",
      " 23700K .......... .......... .......... .......... .......... 83% 98.3M 0s\n",
      " 23750K .......... .......... .......... .......... .......... 83% 62.6M 0s\n",
      " 23800K .......... .......... .......... .......... .......... 83% 82.1M 0s\n",
      " 23850K .......... .......... .......... .......... .......... 83%  266M 0s\n",
      " 23900K .......... .......... .......... .......... .......... 83%  393M 0s\n",
      " 23950K .......... .......... .......... .......... .......... 83% 79.5M 0s\n",
      " 24000K .......... .......... .......... .......... .......... 84%  296M 0s\n",
      " 24050K .......... .......... .......... .......... .......... 84%  336M 0s\n",
      " 24100K .......... .......... .......... .......... .......... 84% 42.4M 0s\n",
      " 24150K .......... .......... .......... .......... .......... 84% 76.5M 0s\n",
      " 24200K .......... .......... .......... .......... .......... 84% 67.4M 0s\n",
      " 24250K .......... .......... .......... .......... .......... 84% 82.4M 0s\n",
      " 24300K .......... .......... .......... .......... .......... 85% 87.0M 0s\n",
      " 24350K .......... .......... .......... .......... .......... 85% 2.95M 0s\n",
      " 24400K .......... .......... .......... .......... .......... 85% 71.1M 0s\n",
      " 24450K .......... .......... .......... .......... .......... 85%  259M 0s\n",
      " 24500K .......... .......... .......... .......... .......... 85% 2.23M 0s\n",
      " 24550K .......... .......... .......... .......... .......... 86% 85.8M 0s\n",
      " 24600K .......... .......... .......... .......... .......... 86% 56.6M 0s\n",
      " 24650K .......... .......... .......... .......... .......... 86% 1.32M 0s\n",
      " 24700K .......... .......... .......... .......... .......... 86%  117M 0s\n",
      " 24750K .......... .......... .......... .......... .......... 86%  304M 0s\n",
      " 24800K .......... .......... .......... .......... .......... 86% 69.4M 0s\n",
      " 24850K .......... .......... .......... .......... .......... 87% 77.2M 0s\n",
      " 24900K .......... .......... .......... .......... .......... 87%  344M 0s\n",
      " 24950K .......... .......... .......... .......... .......... 87%  421M 0s\n",
      " 25000K .......... .......... .......... .......... .......... 87% 62.3M 0s\n",
      " 25050K .......... .......... .......... .......... .......... 87%  110M 0s\n",
      " 25100K .......... .......... .......... .......... .......... 87%  382M 0s\n",
      " 25150K .......... .......... .......... .......... .......... 88% 68.4M 0s\n",
      " 25200K .......... .......... .......... .......... .......... 88%  157M 0s\n",
      " 25250K .......... .......... .......... .......... .......... 88%  135M 0s\n",
      " 25300K .......... .......... .......... .......... .......... 88% 56.3M 0s\n",
      " 25350K .......... .......... .......... .......... .......... 88%  234M 0s\n",
      " 25400K .......... .......... .......... .......... .......... 89%  331M 0s\n",
      " 25450K .......... .......... .......... .......... .......... 89% 45.2M 0s\n",
      " 25500K .......... .......... .......... .......... .......... 89%  233M 0s\n",
      " 25550K .......... .......... .......... .......... .......... 89%  132M 0s\n",
      " 25600K .......... .......... .......... .......... .......... 89% 69.5M 0s\n",
      " 25650K .......... .......... .......... .......... .......... 89%  143M 0s\n",
      " 25700K .......... .......... .......... .......... .......... 90% 76.5M 0s\n",
      " 25750K .......... .......... .......... .......... .......... 90%  431M 0s\n",
      " 25800K .......... .......... .......... .......... .......... 90%  456M 0s\n",
      " 25850K .......... .......... .......... .......... .......... 90% 65.3M 0s\n",
      " 25900K .......... .......... .......... .......... .......... 90%  224M 0s\n",
      " 25950K .......... .......... .......... .......... .......... 90% 91.7M 0s\n",
      " 26000K .......... .......... .......... .......... .......... 91% 94.3M 0s\n",
      " 26050K .......... .......... .......... .......... .......... 91% 61.5M 0s\n",
      " 26100K .......... .......... .......... .......... .......... 91% 29.0M 0s\n",
      " 26150K .......... .......... .......... .......... .......... 91% 82.1M 0s\n",
      " 26200K .......... .......... .......... .......... .......... 91%  129M 0s\n",
      " 26250K .......... .......... .......... .......... .......... 91%  536M 0s\n",
      " 26300K .......... .......... .......... .......... .......... 92% 65.7M 0s\n",
      " 26350K .......... .......... .......... .......... .......... 92% 96.2M 0s\n",
      " 26400K .......... .......... .......... .......... .......... 92%  400M 0s\n",
      " 26450K .......... .......... .......... .......... .......... 92% 76.9M 0s\n",
      " 26500K .......... .......... .......... .......... .......... 92% 78.0M 0s\n",
      " 26550K .......... .......... .......... .......... .......... 93%  446M 0s\n",
      " 26600K .......... .......... .......... .......... .......... 93% 58.3M 0s\n",
      " 26650K .......... .......... .......... .......... .......... 93%  154M 0s\n",
      " 26700K .......... .......... .......... .......... .......... 93% 88.9M 0s\n",
      " 26750K .......... .......... .......... .......... .......... 93%  111M 0s\n",
      " 26800K .......... .......... .......... .......... .......... 93%  404M 0s\n",
      " 26850K .......... .......... .......... .......... .......... 94% 69.3M 0s\n",
      " 26900K .......... .......... .......... .......... .......... 94% 98.3M 0s\n",
      " 26950K .......... .......... .......... .......... .......... 94%  280M 0s\n",
      " 27000K .......... .......... .......... .......... .......... 94%  218M 0s\n",
      " 27050K .......... .......... .......... .......... .......... 94% 93.4M 0s\n",
      " 27100K .......... .......... .......... .......... .......... 94% 78.3M 0s\n",
      " 27150K .......... .......... .......... .......... .......... 95%  190M 0s\n",
      " 27200K .......... .......... .......... .......... .......... 95%  253M 0s\n",
      " 27250K .......... .......... .......... .......... .......... 95% 3.05M 0s\n",
      " 27300K .......... .......... .......... .......... .......... 95% 90.3M 0s\n",
      " 27350K .......... .......... .......... .......... .......... 95%  290M 0s\n",
      " 27400K .......... .......... .......... .......... .......... 95%  105M 0s\n",
      " 27450K .......... .......... .......... .......... .......... 96% 62.1M 0s\n",
      " 27500K .......... .......... .......... .......... .......... 96%  825K 0s\n",
      " 27550K .......... .......... .......... .......... .......... 96%  123M 0s\n",
      " 27600K .......... .......... .......... .......... .......... 96%  183M 0s\n",
      " 27650K .......... .......... .......... .......... .......... 96% 83.3M 0s\n",
      " 27700K .......... .......... .......... .......... .......... 97%  245M 0s\n",
      " 27750K .......... .......... .......... .......... .......... 97%  108M 0s\n",
      " 27800K .......... .......... .......... .......... .......... 97% 63.1M 0s\n",
      " 27850K .......... .......... .......... .......... .......... 97% 59.5M 0s\n",
      " 27900K .......... .......... .......... .......... .......... 97% 76.3M 0s\n",
      " 27950K .......... .......... .......... .......... .......... 97%  275M 0s\n",
      " 28000K .......... .......... .......... .......... .......... 98%  191M 0s\n",
      " 28050K .......... .......... .......... .......... .......... 98%  483M 0s\n",
      " 28100K .......... .......... .......... .......... .......... 98% 70.4M 0s\n",
      " 28150K .......... .......... .......... .......... .......... 98% 74.2M 0s\n",
      " 28200K .......... .......... .......... .......... .......... 98%  230M 0s\n",
      " 28250K .......... .......... .......... .......... .......... 98%  114M 0s\n",
      " 28300K .......... .......... .......... .......... .......... 99% 87.3M 0s\n",
      " 28350K .......... .......... .......... .......... .......... 99%  327M 0s\n",
      " 28400K .......... .......... .......... .......... .......... 99% 63.5M 0s\n",
      " 28450K .......... .......... .......... .......... .......... 99% 86.3M 0s\n",
      " 28500K .......... .......... .......... .......... .......... 99%  164M 0s\n",
      " 28550K .......... .......... .......... .......... ....      100%  109M=1.7s\n",
      "\n",
      "2021-02-24 07:54:14 (16.6 MB/s) - ‘train.tgz’ saved [29281190/29281190]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm train.tgz\n",
    "wget http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_Apprentissage_Automatique/train.tgz\n",
    "tar xvfz train.tgz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsTvOk9QOkOL"
   },
   "source": [
    "**On fait la liste des fichiers dont on veut se servir pour construire les données d'apprentissage.**\n",
    "**A chaque corpus on associe un identificateur de la langue (en, fr, it ...)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFmXa3O_O_Td"
   },
   "outputs": [],
   "source": [
    "l_corpus_train=[\n",
    "['en', './train/en_partut-ud-train.txt'],\n",
    "['fr', './train/fr_sequoia-ud-train.txt'],\n",
    "['it', './train/it_partut-ud-train.txt'],\n",
    "['nl', './train/nl_lassysmall-ud-train.txt'],\n",
    "['sl', './train/sl_sst-ud-train.txt'],\n",
    "['es', './train/es_ancora-ud-train.txt'],\n",
    "['pt', './train/pt_bosque-ud-train.txt'],\n",
    "['de', './train/de_gsd-ud-train.txt'],\n",
    "['ca', './train/ca_ancora-ud-train.txt']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4uRxiNs_br4g",
    "outputId": "98c07f80-d511-4ec9-cb37-31c88c075987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langue : en code =  0\n",
      "langue : fr code =  1\n",
      "langue : it code =  2\n",
      "langue : nl code =  3\n",
      "langue : sl code =  4\n",
      "langue : es code =  5\n",
      "langue : pt code =  6\n",
      "langue : de code =  7\n",
      "langue : ca code =  8\n"
     ]
    }
   ],
   "source": [
    "def calculeCodeLangues(l_corpus):\n",
    "    nbLangues = 0\n",
    "    codeLangue = { } # dictionnaire\n",
    "\n",
    "    for corpus in l_corpus:\n",
    "        idLangue = corpus[0]\n",
    "        fichierCorpus = corpus[1]  # Je suis pas sur que ce soit utile pour cette fonction \n",
    "        if not idLangue in codeLangue :\n",
    "          print('langue :', idLangue, 'code = ', nbLangues)\n",
    "          codeLangue[idLangue] = nbLangues\n",
    "          nbLangues += 1\n",
    "    return codeLangue\n",
    "  \n",
    "codeLangues = calculeCodeLangues(l_corpus_train)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w54QUvxu2q0B"
   },
   "source": [
    "**On extrait des corpus d'apprentissage des bigrammes dont on calcule la fréquence.**\n",
    "**Les fréquences de bigrammes sont stockées dans un fichier dont le format est le suivant :**\n",
    "**chaque ligne se présente sous la forme de l'identificateur d'une langue, suivie de la fréquence des différents bigrammes dans un ordre fixé (voir la fonction bigram_code())**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXw2bL2fWEaM",
    "outputId": "0ea683f6-92bd-4165-f03a-cfb489ca10c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n"
     ]
    }
   ],
   "source": [
    "def calculFreq(bigrammes):\n",
    "    ''' Renvois une liste de fréquence pour chaque code de bigramme '''\n",
    "    somme = 0 #ici\n",
    "    for elt in bigrammes :\n",
    "        somme += elt\n",
    "    i = 0\n",
    "    while i < len(bigrammes):\n",
    "        bigrammes[i] /= somme\n",
    "        i = i + 1\n",
    "\n",
    "def afficheBigrammes(bigrammes, fic):\n",
    "    for frequence in bigrammes :\n",
    "        print(frequence, ' ', file = fic, end='')\n",
    "    print('', file = fic)\n",
    "\n",
    "def char_code(c):\n",
    "    ''' Chaque lettre est associée à un code '''\n",
    "    if 'a' <= c and c <= 'z':\n",
    "        return ord(c) - ord('a') \n",
    "    elif c == ' ':\n",
    "        return 26\n",
    "    else :\n",
    "        return 27\n",
    "    \n",
    "\n",
    "def bigram_code(c1, c2): \n",
    "    ''' Les bigrammes sont définis par des codes '''\n",
    "    return 27 * char_code(c1) + char_code(c2) # PROPOSITION : la première lettre du bigramme est multiplié par 27 pour augmenter le poids des bigrammes commencant par la lettre c1 \n",
    "\n",
    "def process_corpus_random(corpus, maxBigrammes, maxTirage):\n",
    "    try:\n",
    "        fic = open(corpus, 'r') # ouvre le fichier corpus \n",
    "    except IOError:\n",
    "        print(\"le fichier\", corpus, \"n'existe pas\")\n",
    "        return None\n",
    "\n",
    "    corpus_str = fic.read()  # le fichier est écrit dans corpus_str\n",
    "    longueur_corpus = len(corpus_str)\n",
    "#   print(\"longueur corpus = \", longueur_corpus)\n",
    "    fic.close() # on ferme le fichier, il est copié dans corpus_str\n",
    "    \n",
    "    l_bigrammes = [] # liste de liste \n",
    "    tirage = 0\n",
    "    while tirage < maxTirage: # Pour chaque tirage\n",
    "        bigrammes = [0] * 784 # 784 car le code associé au bigramme maximum \n",
    "        nbBigrammes = 0\n",
    "        while nbBigrammes <= maxBigrammes : # on cherche le max de bigrammes possibles\n",
    "            position = random.randint(0,longueur_corpus - 2) # position aléatoire (-2 parce qu'on cherche des bigramme cf voir ligne suivante)\n",
    "            code_bigramme = bigram_code(corpus_str[position], corpus_str[position + 1]) \n",
    "            bigrammes[code_bigramme] += 1 # à la position du code du bigramme dans la liste bigramme on incrémente de 1 \n",
    "            nbBigrammes += 1\n",
    "        calculFreq(bigrammes) \n",
    "        l_bigrammes.append(bigrammes) # liste dee liste des frequences de bigrammes pour chaque tirage \n",
    "        tirage += 1\n",
    "    return l_bigrammes\n",
    "\n",
    "def process_corpus_sequential(corpus, maxBigrammes, maxTirage):\n",
    "    try:\n",
    "        fic = open(corpus, 'r')\n",
    "    except IOError:\n",
    "        print(\"le fichier\", corpus, \"n'existe pas\")\n",
    "        return None\n",
    "\n",
    "    corpus_str = fic.read() \n",
    "    longueur_corpus = len(corpus_str) \n",
    "#    print(\"longueur corpus = \", longueur_corpus)\n",
    "    fic.close() \n",
    "    \n",
    "    l_bigrammes = [] \n",
    "    tirage = 0\n",
    "    while tirage < maxTirage :  \n",
    "        bigrammes = [0] * 784  \n",
    "        nbBigrammes = 0\n",
    "        position = random.randint(0,longueur_corpus - maxBigrammes - 2) \n",
    "        while nbBigrammes <= maxBigrammes : \n",
    "            code_bigramme = bigram_code(corpus_str[position], corpus_str[position + 1]) \n",
    "            bigrammes[code_bigramme] += 1\n",
    "            nbBigrammes += 1\n",
    "            position += 1\n",
    "            \n",
    "        calculFreq(bigrammes)\n",
    "        l_bigrammes.append(bigrammes)\n",
    "        tirage += 1\n",
    "    return l_bigrammes\n",
    "\n",
    "def extract_bigrams(l_corpus, mode, nbBigrammes, nbTirages, fichierSortie) :\n",
    "    try:\n",
    "        ficOut = open(fichierSortie, 'w') # ouvre un ficher en mode écriture nommée 'train.dat'->cf dernière ligne du chunck\n",
    "    except IOError:\n",
    "        print(\"le fichier\", fichierSortie, \"n'existe pas\")\n",
    "        exit\n",
    "\n",
    "    for corpus in l_corpus: \n",
    "        idLangue = corpus[0]\n",
    "        fichierCorpus = corpus[1]\n",
    "        print('traite corpus', fichierCorpus) \n",
    "        if(mode == 'random'):\n",
    "            l_bigrammes = process_corpus_random(fichierCorpus, nbBigrammes, nbTirages) ##\n",
    "        else :\n",
    "            l_bigrammes = process_corpus_sequential(fichierCorpus, nbBigrammes, nbTirages)\n",
    "        for bigrammes in l_bigrammes:\n",
    "            print(idLangue, ' ', file = ficOut, end='')\n",
    "            afficheBigrammes(bigrammes, ficOut)\n",
    "    ficOut.close()\n",
    "    \n",
    "extract_bigrams(l_corpus_train, 'random', 100, 100, 'train.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waNtyfLLcgRH"
   },
   "source": [
    "**On met en forme les données de manière à pouvoir les fournir au réseau de neurones pour l'apprentissage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yrmo_c4zMbUm",
    "outputId": "c45f4607-c4d2-4d86-99ba-1c62b233972d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.dat\n",
      "900 exemples lus\n"
     ]
    }
   ],
   "source": [
    "def lectureDonnees(nomFichier, codeLangue):\n",
    "    print(nomFichier)\n",
    "    try:\n",
    "        fic = open(nomFichier, 'r')\n",
    "    except IOError:\n",
    "        print(\"le fichier\", nomFichier, \"n'existe pas\")\n",
    "        return None\n",
    "\n",
    "    nbLangues = len(codeLangue.keys()) \n",
    "    lx = []\n",
    "    langues = []\n",
    "\n",
    "    for ligne in fic:\n",
    "        # Le chaque ligne d'un fichier on enleve les espaces et on récupère \n",
    "        ## le premier caractere dans la variable langue\n",
    "        ligne = ligne.strip('\\n\\r')\n",
    "        liste = ligne.split()\n",
    "        langue = liste.pop(0)\n",
    "        \n",
    "        langues.append(codeLangue[langue])\n",
    "        resultat = [float(x) for x in liste]\n",
    "        lx.append(resultat)\n",
    "    fic.close()\n",
    "\n",
    "    ly = []\n",
    "    for i in range(len(langues)):\n",
    "        v = [0] * nbLangues\n",
    "        v[langues[i]] = 1\n",
    "        ly.append(v)\n",
    "\n",
    "    t = list(zip(lx, ly))\n",
    "    random.shuffle(t)\n",
    "    lx, ly = list(zip(*t))\n",
    "\n",
    "    x_train = np.array(lx, dtype=\"float\")\n",
    "    y_train = np.array(ly, dtype=\"int\")\n",
    "    print(len(x_train), \"exemples lus\")\n",
    "    #print(x_train)\n",
    "    return (x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train) = lectureDonnees('train.dat', codeLangues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIj6DEVYiFZL"
   },
   "source": [
    "**On construit la structure du réseau et on fait l'apprentissage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UfXcam76hm5B",
    "outputId": "9757cff0-9ad8-4faf-bafe-407692178b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.1852 - accuracy: 0.1835 - val_loss: 2.1420 - val_accuracy: 0.5778\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.1140 - accuracy: 0.6946 - val_loss: 2.0488 - val_accuracy: 0.7000\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.0059 - accuracy: 0.7784 - val_loss: 1.9049 - val_accuracy: 0.7389\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.8441 - accuracy: 0.8276 - val_loss: 1.7195 - val_accuracy: 0.7444\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.6329 - accuracy: 0.9237 - val_loss: 1.5023 - val_accuracy: 0.9444\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.4321 - accuracy: 0.9485 - val_loss: 1.3057 - val_accuracy: 0.9444\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.2095 - accuracy: 0.9788 - val_loss: 1.1285 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0698 - accuracy: 0.9898 - val_loss: 0.9798 - val_accuracy: 0.9778\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8920 - accuracy: 0.9897 - val_loss: 0.8537 - val_accuracy: 0.9722\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7616 - accuracy: 0.9959 - val_loss: 0.7473 - val_accuracy: 0.9833\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.9927 - val_loss: 0.6571 - val_accuracy: 0.9778\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.9907 - val_loss: 0.5761 - val_accuracy: 0.9944\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.9982 - val_loss: 0.5148 - val_accuracy: 0.9889\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.9974 - val_loss: 0.4617 - val_accuracy: 0.9833\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.9948 - val_loss: 0.4087 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.9981 - val_loss: 0.3691 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.9953 - val_loss: 0.3360 - val_accuracy: 0.9944\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2401 - accuracy: 0.9957 - val_loss: 0.3025 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2334 - accuracy: 0.9948 - val_loss: 0.2757 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.9993 - val_loss: 0.2554 - val_accuracy: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6678672410>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential() # type de model \n",
    "nbLangues = len(codeLangues.keys()) \n",
    "\n",
    "model.add(Dense(units=100, activation='tanh', input_dim=28*28)) # premiere couche du RNN \n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(units=nbLangues, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=16, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rs2phFdouuP"
   },
   "source": [
    "**On charge les données de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7Cvb15gsjNg",
    "outputId": "aab002df-2f90-47cb-bb37-b2bcb193df37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/\n",
      "test/cs_fictree-ud-test.txt\n",
      "test/akk_pisandub-ud-test.txt\n",
      "test/la_ittb-ud-test.txt\n",
      "test/gl_ctg-ud-test.txt\n",
      "test/bg_btb-ud-test.txt\n",
      "test/sv_talbanken-ud-test.txt\n",
      "test/hi_hdtb-ud-test.txt\n",
      "test/fi_pud-ud-test.txt\n",
      "test/et_edt-ud-test.txt\n",
      "test/ga_idt-ud-test.txt\n",
      "test/da_ddt-ud-test.txt\n",
      "test/br_keb-ud-test.txt\n",
      "test/ja_pud-ud-test.txt\n",
      "test/cs_pdt-ud-test.txt\n",
      "test/pl_lfg-ud-test.txt\n",
      "test/no_nynorsk-ud-test.txt\n",
      "test/pt_bosque-ud-test.txt\n",
      "test/id_pud-ud-test.txt\n",
      "test/bm_crb-ud-test.txt\n",
      "test/kpv_ikdp-ud-test.txt\n",
      "test/ar_padt-ud-test.txt\n",
      "test/kk_ktb-ud-test.txt\n",
      "test/ar_nyuad-ud-test.txt\n",
      "test/hy_armtdp-ud-test.txt\n",
      "test/fi_ftb-ud-test.txt\n",
      "test/it_postwita-ud-test.txt\n",
      "test/fa_seraji-ud-test.txt\n",
      "test/en_partut-ud-test.txt\n",
      "test/zh_pud-ud-test.txt\n",
      "test/cs_pud-ud-test.txt\n",
      "test/sk_snk-ud-test.txt\n",
      "test/tr_imst-ud-test.txt\n",
      "test/eu_bdt-ud-test.txt\n",
      "test/got_proiel-ud-test.txt\n",
      "test/ug_udt-ud-test.txt\n",
      "test/kpv_lattice-ud-test.txt\n",
      "test/ru_taiga-ud-test.txt\n",
      "test/ru_syntagrus-ud-test.txt\n",
      "test/wbp_ufal-ud-test.txt\n",
      "test/fr_partut-ud-test.txt\n",
      "test/bxr_bdt-ud-test.txt\n",
      "test/kmr_mg-ud-test.txt\n",
      "test/sl_ssj-ud-test.txt\n",
      "test/yue_hk-ud-test.txt\n",
      "test/fr_gsd-ud-test.txt\n",
      "test/de_gsd-ud-test.txt\n",
      "test/pcm_nsc-ud-test.txt\n",
      "test/id_gsd-ud-test.txt\n",
      "test/mr_ufal-ud-test.txt\n",
      "test/sa_ufal-ud-test.txt\n",
      "test/cu_proiel-ud-test.txt\n",
      "test/myv_jr-ud-test.txt\n",
      "test/es_ancora-ud-test.txt\n",
      "test/hr_set-ud-test.txt\n",
      "test/la_proiel-ud-test.txt\n",
      "test/th_pud-ud-test.txt\n",
      "test/te_mtg-ud-test.txt\n",
      "test/sr_set-ud-test.txt\n",
      "test/it_isdt-ud-test.txt\n",
      "test/uk_iu-ud-test.txt\n",
      "test/fr_pud-ud-test.txt\n",
      "test/ja_modern-ud-test.txt\n",
      "test/cs_cac-ud-test.txt\n",
      "test/fo_oft-ud-test.txt\n",
      "test/qhe_hiencs-ud-test.txt\n",
      "test/mt_mudt-ud-test.txt\n",
      "test/ru_gsd-ud-test.txt\n",
      "test/en_esl-ud-test.txt\n",
      "test/be_hse-ud-test.txt\n",
      "test/de_pud-ud-test.txt\n",
      "test/fr_spoken-ud-test.txt\n",
      "test/vi_vtb-ud-test.txt\n",
      "test/en_pud-ud-test.txt\n",
      "test/ar_pud-ud-test.txt\n",
      "test/ro_rrt-ud-test.txt\n",
      "test/ko_pud-ud-test.txt\n",
      "test/lv_lvtb-ud-test.txt\n",
      "test/am_att-ud-test.txt\n",
      "test/ja_gsd-ud-test.txt\n",
      "test/hu_szeged-ud-test.txt\n",
      "test/grc_perseus-ud-test.txt\n",
      "test/ru_pud-ud-test.txt\n",
      "test/fr_sequoia-ud-test.txt\n",
      "test/ko_kaist-ud-test.txt\n",
      "test/hsb_ufal-ud-test.txt\n",
      "test/fi_tdt-ud-test.txt\n",
      "test/tr_pud-ud-test.txt\n",
      "test/yo_ytb-ud-test.txt\n",
      "test/no_bokmaal-ud-test.txt\n",
      "test/sl_sst-ud-test.txt\n",
      "test/sme_giella-ud-test.txt\n",
      "test/zh_gsd-ud-test.txt\n",
      "test/ta_ttb-ud-test.txt\n",
      "test/lt_hse-ud-test.txt\n",
      "test/gl_treegal-ud-test.txt\n",
      "test/ur_udtb-ud-test.txt\n",
      "test/la_perseus-ud-test.txt\n",
      "test/he_htb-ud-test.txt\n",
      "test/grc_proiel-ud-test.txt\n",
      "test/fr_ftb-ud-test.txt\n",
      "test/it_partut-ud-test.txt\n",
      "test/pl_sz-ud-test.txt\n",
      "test/el_gdt-ud-test.txt\n",
      "test/cop_scriptorium-ud-test.txt\n",
      "test/ko_gsd-ud-test.txt\n",
      "test/swl_sslc-ud-test.txt\n",
      "test/ca_ancora-ud-test.txt\n",
      "test/tl_trg-ud-test.txt\n",
      "test/ro_nonstandard-ud-test.txt\n",
      "test/en_ewt-ud-test.txt\n",
      "test/en_lines-ud-test.txt\n",
      "test/nl_lassysmall-ud-test.txt\n",
      "test/es_gsd-ud-test.txt\n",
      "test/pt_pud-ud-test.txt\n",
      "test/hi_pud-ud-test.txt\n",
      "test/pt_gsd-ud-test.txt\n",
      "test/zh_cfl-ud-test.txt\n",
      "test/en_gum-ud-test.txt\n",
      "test/ja_bccwj-ud-test.txt\n",
      "test/fro_srcmf-ud-test.txt\n",
      "test/es_pud-ud-test.txt\n",
      "test/sv_lines-ud-test.txt\n",
      "test/zh_hk-ud-test.txt\n",
      "test/af_afribooms-ud-test.txt\n",
      "test/cs_cltt-ud-test.txt\n",
      "test/no_nynorsklia-ud-test.txt\n",
      "test/it_pud-ud-test.txt\n",
      "test/nl_alpino-ud-test.txt\n",
      "test/sv_pud-ud-test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'test.tgz': No such file or directory\n",
      "--2021-02-24 07:55:05--  http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_Apprentissage_Automatique/test.tgz\n",
      "Resolving pageperso.lif.univ-mrs.fr (pageperso.lif.univ-mrs.fr)... 139.124.22.27\n",
      "Connecting to pageperso.lif.univ-mrs.fr (pageperso.lif.univ-mrs.fr)|139.124.22.27|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5342409 (5.1M) [application/x-gzip]\n",
      "Saving to: ‘test.tgz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  237K 22s\n",
      "    50K .......... .......... .......... .......... ..........  1%  488K 16s\n",
      "   100K .......... .......... .......... .......... ..........  2% 92.1M 11s\n",
      "   150K .......... .......... .......... .......... ..........  3%  498K 10s\n",
      "   200K .......... .......... .......... .......... ..........  4% 73.3M 8s\n",
      "   250K .......... .......... .......... .......... ..........  5%  498K 8s\n",
      "   300K .......... .......... .......... .......... ..........  6% 69.4M 7s\n",
      "   350K .......... .......... .......... .......... ..........  7% 84.1M 6s\n",
      "   400K .......... .......... .......... .......... ..........  8%  137M 5s\n",
      "   450K .......... .......... .......... .......... ..........  9%  505K 6s\n",
      "   500K .......... .......... .......... .......... .......... 10% 71.0M 5s\n",
      "   550K .......... .......... .......... .......... .......... 11% 64.8M 5s\n",
      "   600K .......... .......... .......... .......... .......... 12% 67.2M 4s\n",
      "   650K .......... .......... .......... .......... .......... 13% 73.8M 4s\n",
      "   700K .......... .......... .......... .......... .......... 14%  210M 4s\n",
      "   750K .......... .......... .......... .......... .......... 15%  266M 3s\n",
      "   800K .......... .......... .......... .......... .......... 16%  233M 3s\n",
      "   850K .......... .......... .......... .......... .......... 17%  497M 3s\n",
      "   900K .......... .......... .......... .......... .......... 18%  512K 3s\n",
      "   950K .......... .......... .......... .......... .......... 19%  329M 3s\n",
      "  1000K .......... .......... .......... .......... .......... 20% 74.3M 3s\n",
      "  1050K .......... .......... .......... .......... .......... 21%  140M 3s\n",
      "  1100K .......... .......... .......... .......... .......... 22%  441M 3s\n",
      "  1150K .......... .......... .......... .......... .......... 23% 92.8M 2s\n",
      "  1200K .......... .......... .......... .......... .......... 23% 65.7M 2s\n",
      "  1250K .......... .......... .......... .......... .......... 24%  283M 2s\n",
      "  1300K .......... .......... .......... .......... .......... 25%  314M 2s\n",
      "  1350K .......... .......... .......... .......... .......... 26% 72.3M 2s\n",
      "  1400K .......... .......... .......... .......... .......... 27%  136M 2s\n",
      "  1450K .......... .......... .......... .......... .......... 28%  107M 2s\n",
      "  1500K .......... .......... .......... .......... .......... 29%  141M 2s\n",
      "  1550K .......... .......... .......... .......... .......... 30% 61.8M 2s\n",
      "  1600K .......... .......... .......... .......... .......... 31%  298M 2s\n",
      "  1650K .......... .......... .......... .......... .......... 32%  146M 1s\n",
      "  1700K .......... .......... .......... .......... .......... 33% 79.3M 1s\n",
      "  1750K .......... .......... .......... .......... .......... 34%  326M 1s\n",
      "  1800K .......... .......... .......... .......... .......... 35%  530K 1s\n",
      "  1850K .......... .......... .......... .......... .......... 36%  440M 1s\n",
      "  1900K .......... .......... .......... .......... .......... 37% 43.6M 1s\n",
      "  1950K .......... .......... .......... .......... .......... 38%  104M 1s\n",
      "  2000K .......... .......... .......... .......... .......... 39% 88.8M 1s\n",
      "  2050K .......... .......... .......... .......... .......... 40% 98.4M 1s\n",
      "  2100K .......... .......... .......... .......... .......... 41% 89.7M 1s\n",
      "  2150K .......... .......... .......... .......... .......... 42% 62.8M 1s\n",
      "  2200K .......... .......... .......... .......... .......... 43% 94.3M 1s\n",
      "  2250K .......... .......... .......... .......... .......... 44%  113M 1s\n",
      "  2300K .......... .......... .......... .......... .......... 45% 63.0M 1s\n",
      "  2350K .......... .......... .......... .......... .......... 46% 63.2M 1s\n",
      "  2400K .......... .......... .......... .......... .......... 46% 84.7M 1s\n",
      "  2450K .......... .......... .......... .......... .......... 47% 86.8M 1s\n",
      "  2500K .......... .......... .......... .......... .......... 48%  115M 1s\n",
      "  2550K .......... .......... .......... .......... .......... 49%  164M 1s\n",
      "  2600K .......... .......... .......... .......... .......... 50% 44.7M 1s\n",
      "  2650K .......... .......... .......... .......... .......... 51%  251M 1s\n",
      "  2700K .......... .......... .......... .......... .......... 52%  410M 1s\n",
      "  2750K .......... .......... .......... .......... .......... 53% 59.9M 1s\n",
      "  2800K .......... .......... .......... .......... .......... 54% 78.5M 1s\n",
      "  2850K .......... .......... .......... .......... .......... 55%  390M 1s\n",
      "  2900K .......... .......... .......... .......... .......... 56%  151M 1s\n",
      "  2950K .......... .......... .......... .......... .......... 57% 65.8M 1s\n",
      "  3000K .......... .......... .......... .......... .......... 58%  267M 1s\n",
      "  3050K .......... .......... .......... .......... .......... 59%  272M 1s\n",
      "  3100K .......... .......... .......... .......... .......... 60% 63.7M 1s\n",
      "  3150K .......... .......... .......... .......... .......... 61%  261M 1s\n",
      "  3200K .......... .......... .......... .......... .......... 62% 69.9M 1s\n",
      "  3250K .......... .......... .......... .......... .......... 63%  176M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 64%  385M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 65% 66.5M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 66%  182M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 67%  104M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 68%  134M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 69%  137M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 69%  595K 0s\n",
      "  3650K .......... .......... .......... .......... .......... 70% 81.2M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 71% 85.2M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 72% 83.1M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 73% 74.2M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 74%  110M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 75% 57.3M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 76% 77.7M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 77%  105M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 78% 66.4M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 79% 66.4M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 80% 47.8M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 81%  106M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 82%  156M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 83% 49.5M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 84%  468M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 85%  119M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 86% 71.7M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 87%  231M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 88% 93.7M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 89% 95.5M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 90%  117M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 91% 75.3M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 92%  289M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 92%  121M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 93% 69.1M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 94%  134M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 95%  420M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 96% 45.5M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 97%  287M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 98%  128M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 99% 95.2M 0s\n",
      "  5200K .......... .......                                    100%  299M=0.9s\n",
      "\n",
      "2021-02-24 07:55:06 (5.44 MB/s) - ‘test.tgz’ saved [5342409/5342409]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm test.tgz\n",
    "wget http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_Apprentissage_Automatique/test.tgz\n",
    "tar xvfz test.tgz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5HMxaj2q4qY"
   },
   "outputs": [],
   "source": [
    "l_corpus_test=[\n",
    "['en', './test/en_partut-ud-test.txt'],\n",
    "['fr', './test/fr_sequoia-ud-test.txt'],\n",
    "['it', './test/it_partut-ud-test.txt'],\n",
    "['nl', './test/nl_lassysmall-ud-test.txt'],\n",
    "['sl', './test/sl_sst-ud-test.txt'],\n",
    "['es', './test/es_ancora-ud-test.txt'],\n",
    "['pt', './test/pt_bosque-ud-test.txt'],\n",
    "['de', './test/de_gsd-ud-test.txt'],\n",
    "['ca', './test/ca_ancora-ud-test.txt']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55nbZWWNo5mz",
    "outputId": "8509ec55-5d8e-473d-8561-1c0fb81208f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traite corpus ./test/en_partut-ud-test.txt\n",
      "traite corpus ./test/fr_sequoia-ud-test.txt\n",
      "traite corpus ./test/it_partut-ud-test.txt\n",
      "traite corpus ./test/nl_lassysmall-ud-test.txt\n",
      "traite corpus ./test/sl_sst-ud-test.txt\n",
      "traite corpus ./test/es_ancora-ud-test.txt\n",
      "traite corpus ./test/pt_bosque-ud-test.txt\n",
      "traite corpus ./test/de_gsd-ud-test.txt\n",
      "traite corpus ./test/ca_ancora-ud-test.txt\n",
      "test.dat\n",
      "90 exemples lus\n"
     ]
    }
   ],
   "source": [
    "extract_bigrams(l_corpus_test, 'random', 500, 10, 'test.dat')\n",
    "(x_test, y_test) = lectureDonnees('test.dat', codeLangues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcRNFKTculzj"
   },
   "source": [
    "**On évalue le modèle sur les données de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UoAoEoHByrF9",
    "outputId": "5c5be9a4-33d3-4d31-b653-0581fc28f8d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'fr', 'it', 'nl', 'sl', 'es', 'pt', 'de', 'ca']\n"
     ]
    }
   ],
   "source": [
    "def l_identifiants(cdLg) : \n",
    "  id = [''] * len(cdLg)\n",
    "  for (key, val) in (cdLg.items()):\n",
    "  #print(\"key =\", key , 'val =', val)\n",
    "    id[int(val)] = key\n",
    "  return id\n",
    "\n",
    "l_id = l_identifiants(codeLangues)\n",
    "print(l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OofcOojVuoxP",
    "outputId": "63c2ab44-f8ce-4fa2-a2c1-8d56050c84c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1972 - accuracy: 1.0000\n",
      "['loss', 'accuracy']\n",
      "test.dat score =  [0.1971767395734787, 1.0]\n",
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def argmax(l):\n",
    "  ''' Renvoie la position de l'argument maximum de la liste '''\n",
    "  i = 1\n",
    "  max = l[0] \n",
    "  arg = 0\n",
    "  while i < len(l) :\n",
    "    if l[i] > max :\n",
    "      max = l[i]\n",
    "      arg = i\n",
    "    i = i + 1\n",
    "  return arg\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(model.metrics_names) # noms des données de l'output de model.evaluate \n",
    "print('test.dat score = ', score)\n",
    "l_pred = model.predict(x_test, batch_size=None, verbose=1, steps=None) \n",
    "i = 0\n",
    "while i < len(l_pred) :\n",
    "  #print(l_pred[i])\n",
    "  predicted = l_id[argmax(l_pred[i])]\n",
    "  gold = l_id[argmax(y_test[i])]\n",
    "  #print('pred =', predicted, 'gold =', gold)\n",
    "  i = i + 1\n",
    "\n",
    "  \n",
    "def note(pred, y_t, cdlg) : \n",
    "  nt = [0]*len(cdlg)\n",
    "  i = 0\n",
    "  while i < len(pred) : \n",
    "    if argmax(pred[i]) == argmax(y_t[i]) : \n",
    "      nt[argmax(pred[i])] += 1 \n",
    "    i += 1\n",
    "  \n",
    "  i = 0\n",
    "  while i < len(nt) : \n",
    "    nt[i] /= len(pred)/len(cdlg)\n",
    "    i += 1\n",
    "\n",
    "  return nt\n",
    "\n",
    "note(l_pred, y_test, codeLangues)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_guEzn1qSIgz"
   },
   "source": [
    "# Projets de recherche \n",
    "\n",
    "- \"Taille des données d’apprentissage. Les performances obtenues par le classifieur dépendent du nombre d’exemples vus lors de l’apprentissage. Il est possible de tracer une courbe d’apprentissage donnant les performances du réseau selon la taille des données d’apprentissage pour chacune des langues. Toutes les langues ont-elles besoin d’autant de données ? pourquoi ?\"\n",
    "\n",
    "- \"Certaines langues sont elles plus difficiles à distinguer que d’autres ? est ce qu’une matrice de confusion nous permet de retrouver des familles de langues ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vm5nF7FmJc1Z"
   },
   "source": [
    "## Projet 1\n",
    "\n",
    "Nous souhaitons dans notre permier projet observer l'évolution de la performance du classifieur lorsque nous faisons varier le nombre de bigrammes, et le nombre de langues. De cette manière nous ferons varier la taille de nos données d'apprentissage, nous acquerrons plus de précision en fonction des langues, et pourrons donc les comparer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2n74y0YfhdJL"
   },
   "source": [
    "### L'évolution en fonction du nombre de bigrammes \n",
    "\n",
    "Dans un premier temps, nous voulons regarder l'évolution des valeurs de la fonction de perte \"loss\" en fonction du nombre de bigrammes : nous créeons donc une boucle dans laquelle le nombre de bigrammes augmente, et représentons ces résultats dans un graphique.\n",
    "\n",
    "Nous pourrons donc voir, pour l'ensemble des langues combien il faut de bigrammes pour que la fonction de pertes se rapproche de 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DwgkyQ1uXoHr",
    "outputId": "f37e7e51-edb9-45ce-aca3-3168fa959027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langue : en code =  0\n",
      "langue : fr code =  1\n",
      "langue : it code =  2\n",
      "langue : nl code =  3\n",
      "langue : sl code =  4\n",
      "langue : es code =  5\n",
      "langue : pt code =  6\n",
      "langue : de code =  7\n",
      "langue : ca code =  8\n",
      "traite corpus ./test/en_partut-ud-test.txt\n",
      "traite corpus ./test/fr_sequoia-ud-test.txt\n",
      "traite corpus ./test/it_partut-ud-test.txt\n",
      "traite corpus ./test/nl_lassysmall-ud-test.txt\n",
      "traite corpus ./test/sl_sst-ud-test.txt\n",
      "traite corpus ./test/es_ancora-ud-test.txt\n",
      "traite corpus ./test/pt_bosque-ud-test.txt\n",
      "traite corpus ./test/de_gsd-ud-test.txt\n",
      "traite corpus ./test/ca_ancora-ud-test.txt\n",
      "test_2.dat\n",
      "90 exemples lus\n",
      "/n 50 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 7ms/step - loss: 2.1877 - accuracy: 0.2615 - val_loss: 2.1577 - val_accuracy: 0.4611\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.1286 - accuracy: 0.6287 - val_loss: 2.0959 - val_accuracy: 0.5611\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.0386 - accuracy: 0.7393 - val_loss: 1.9949 - val_accuracy: 0.6500\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9064 - accuracy: 0.7958 - val_loss: 1.8561 - val_accuracy: 0.5944\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7182 - accuracy: 0.8022 - val_loss: 1.6892 - val_accuracy: 0.7111\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.5112 - accuracy: 0.9159 - val_loss: 1.5106 - val_accuracy: 0.8111\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.3426 - accuracy: 0.9112 - val_loss: 1.3553 - val_accuracy: 0.8444\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.1352 - accuracy: 0.9805 - val_loss: 1.2051 - val_accuracy: 0.8889\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.9949 - accuracy: 0.9797 - val_loss: 1.0857 - val_accuracy: 0.8778\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8730 - accuracy: 0.9739 - val_loss: 0.9712 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.9766 - val_loss: 0.8747 - val_accuracy: 0.9111\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.9795 - val_loss: 0.7884 - val_accuracy: 0.9278\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.9849 - val_loss: 0.7231 - val_accuracy: 0.9278\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.9801 - val_loss: 0.6561 - val_accuracy: 0.9444\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.9866 - val_loss: 0.6049 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.9900 - val_loss: 0.5594 - val_accuracy: 0.9444\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.9819 - val_loss: 0.5192 - val_accuracy: 0.9389\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.9837 - val_loss: 0.4882 - val_accuracy: 0.9389\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.9890 - val_loss: 0.4549 - val_accuracy: 0.9444\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.9885 - val_loss: 0.4291 - val_accuracy: 0.9556\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 1.0000\n",
      "/n 100 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 6ms/step - loss: 2.1873 - accuracy: 0.2014 - val_loss: 2.1459 - val_accuracy: 0.7222\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.1223 - accuracy: 0.7650 - val_loss: 2.0615 - val_accuracy: 0.7167\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.0183 - accuracy: 0.8174 - val_loss: 1.9266 - val_accuracy: 0.7667\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.8558 - accuracy: 0.8256 - val_loss: 1.7413 - val_accuracy: 0.7611\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.6394 - accuracy: 0.8223 - val_loss: 1.5341 - val_accuracy: 0.8778\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.4395 - accuracy: 0.9586 - val_loss: 1.3368 - val_accuracy: 0.9333\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.2471 - accuracy: 0.9523 - val_loss: 1.1604 - val_accuracy: 0.9444\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0462 - accuracy: 0.9773 - val_loss: 1.0046 - val_accuracy: 0.9667\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8948 - accuracy: 0.9834 - val_loss: 0.8724 - val_accuracy: 0.9889\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7693 - accuracy: 0.9934 - val_loss: 0.7623 - val_accuracy: 0.9889\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.9929 - val_loss: 0.6709 - val_accuracy: 0.9944\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.9969 - val_loss: 0.5868 - val_accuracy: 0.9889\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.9947 - val_loss: 0.5217 - val_accuracy: 0.9889\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.9955 - val_loss: 0.4609 - val_accuracy: 0.9944\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.9966 - val_loss: 0.4136 - val_accuracy: 0.9889\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.9988 - val_loss: 0.3685 - val_accuracy: 0.9944\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.9989 - val_loss: 0.3379 - val_accuracy: 0.9889\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9944\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9975 - val_loss: 0.2735 - val_accuracy: 0.9944\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9944\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 1.0000\n",
      "/n 150 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 6ms/step - loss: 2.1831 - accuracy: 0.1980 - val_loss: 2.1345 - val_accuracy: 0.6889\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.1057 - accuracy: 0.8138 - val_loss: 2.0331 - val_accuracy: 0.7722\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9791 - accuracy: 0.8504 - val_loss: 1.8730 - val_accuracy: 0.8556\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.8013 - accuracy: 0.8889 - val_loss: 1.6786 - val_accuracy: 0.8500\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.5982 - accuracy: 0.9279 - val_loss: 1.4670 - val_accuracy: 0.9667\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.3436 - accuracy: 0.9675 - val_loss: 1.2689 - val_accuracy: 0.9389\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.1512 - accuracy: 0.9714 - val_loss: 1.0862 - val_accuracy: 0.9611\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.9939 - accuracy: 0.9786 - val_loss: 0.9324 - val_accuracy: 0.9778\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8356 - accuracy: 0.9920 - val_loss: 0.8026 - val_accuracy: 0.9667\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.9931 - val_loss: 0.6885 - val_accuracy: 0.9889\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.9952 - val_loss: 0.5955 - val_accuracy: 0.9889\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.9977 - val_loss: 0.5161 - val_accuracy: 0.9889\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.9931 - val_loss: 0.4544 - val_accuracy: 0.9833\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.9987 - val_loss: 0.3928 - val_accuracy: 0.9944\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.9973 - val_loss: 0.3485 - val_accuracy: 0.9944\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.9992 - val_loss: 0.3069 - val_accuracy: 0.9944\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9944\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 0.9996 - val_loss: 0.2459 - val_accuracy: 0.9944\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9944\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9989 - val_loss: 0.1984 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1759 - accuracy: 1.0000\n",
      "/n 200 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 6ms/step - loss: 2.1814 - accuracy: 0.2228 - val_loss: 2.1414 - val_accuracy: 0.5389\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.1032 - accuracy: 0.7389 - val_loss: 2.0402 - val_accuracy: 0.7556\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9711 - accuracy: 0.8568 - val_loss: 1.8822 - val_accuracy: 0.7000\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7876 - accuracy: 0.8489 - val_loss: 1.6795 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.5544 - accuracy: 0.8911 - val_loss: 1.4672 - val_accuracy: 0.8278\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.3183 - accuracy: 0.9116 - val_loss: 1.2729 - val_accuracy: 0.8333\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.1319 - accuracy: 0.9116 - val_loss: 1.1016 - val_accuracy: 0.9056\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.9646 - accuracy: 0.9484 - val_loss: 0.9532 - val_accuracy: 0.9333\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8163 - accuracy: 0.9689 - val_loss: 0.8284 - val_accuracy: 0.9722\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.9811 - val_loss: 0.7200 - val_accuracy: 0.9722\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.9968 - val_loss: 0.6237 - val_accuracy: 0.9889\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.9975 - val_loss: 0.5501 - val_accuracy: 0.9889\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.9946 - val_loss: 0.4778 - val_accuracy: 0.9889\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.9965 - val_loss: 0.4207 - val_accuracy: 0.9889\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.9973 - val_loss: 0.3713 - val_accuracy: 0.9944\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.9985 - val_loss: 0.3260 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9987 - val_loss: 0.2895 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9980 - val_loss: 0.2562 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 0.9980 - val_loss: 0.2281 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1653 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 1.0000\n",
      "/n 250 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 6ms/step - loss: 2.1853 - accuracy: 0.2185 - val_loss: 2.1383 - val_accuracy: 0.6000\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.1089 - accuracy: 0.6184 - val_loss: 2.0339 - val_accuracy: 0.8111\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9840 - accuracy: 0.9334 - val_loss: 1.8662 - val_accuracy: 0.9556\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7930 - accuracy: 0.8951 - val_loss: 1.6499 - val_accuracy: 0.9778\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.5814 - accuracy: 0.9910 - val_loss: 1.4218 - val_accuracy: 0.9889\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.3311 - accuracy: 1.0000 - val_loss: 1.2017 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.1382 - accuracy: 1.0000 - val_loss: 1.0163 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.9673 - accuracy: 0.9981 - val_loss: 0.8535 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8095 - accuracy: 0.9976 - val_loss: 0.7178 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.9983 - val_loss: 0.5129 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 1.0000 - val_loss: 0.3213 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1388 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1392 - accuracy: 1.0000\n",
      "/n 300 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 7ms/step - loss: 2.1843 - accuracy: 0.2000 - val_loss: 2.1374 - val_accuracy: 0.4500\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.1049 - accuracy: 0.7030 - val_loss: 2.0289 - val_accuracy: 0.7222\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9776 - accuracy: 0.8925 - val_loss: 1.8548 - val_accuracy: 0.9722\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7720 - accuracy: 0.9207 - val_loss: 1.6331 - val_accuracy: 0.9333\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.5608 - accuracy: 0.9894 - val_loss: 1.3948 - val_accuracy: 0.9833\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.2960 - accuracy: 0.9885 - val_loss: 1.1756 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0916 - accuracy: 0.9915 - val_loss: 0.9900 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8982 - accuracy: 0.9924 - val_loss: 0.8370 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7716 - accuracy: 0.9996 - val_loss: 0.7087 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.9991 - val_loss: 0.6012 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.9993 - val_loss: 0.5181 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.9992 - val_loss: 0.4403 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.9996 - val_loss: 0.3292 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2282 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1779 - accuracy: 0.9987 - val_loss: 0.1933 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1414 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 1.0000\n",
      "/n 350 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 6ms/step - loss: 2.1829 - accuracy: 0.1524 - val_loss: 2.1314 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.1040 - accuracy: 0.8287 - val_loss: 2.0198 - val_accuracy: 0.8722\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9750 - accuracy: 0.8930 - val_loss: 1.8376 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7812 - accuracy: 0.9988 - val_loss: 1.6092 - val_accuracy: 0.9889\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.5598 - accuracy: 0.9910 - val_loss: 1.3643 - val_accuracy: 0.9944\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.3051 - accuracy: 0.9998 - val_loss: 1.1388 - val_accuracy: 0.9944\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0891 - accuracy: 0.9984 - val_loss: 0.9459 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.9272 - accuracy: 1.0000 - val_loss: 0.7868 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 1.0000 - val_loss: 0.6523 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 1.0000 - val_loss: 0.5480 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3134 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1615 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1243 - accuracy: 1.0000\n",
      "/n 400 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 7ms/step - loss: 2.1810 - accuracy: 0.2162 - val_loss: 2.1264 - val_accuracy: 0.5333\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.0894 - accuracy: 0.6938 - val_loss: 2.0017 - val_accuracy: 0.6889\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9365 - accuracy: 0.7618 - val_loss: 1.8093 - val_accuracy: 0.8556\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7257 - accuracy: 0.8576 - val_loss: 1.5749 - val_accuracy: 0.9389\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.4766 - accuracy: 0.9472 - val_loss: 1.3357 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.2375 - accuracy: 1.0000 - val_loss: 1.1220 - val_accuracy: 0.9944\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0098 - accuracy: 0.9993 - val_loss: 0.9534 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8587 - accuracy: 1.0000 - val_loss: 0.7943 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7257 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 1.0000 - val_loss: 0.5662 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1863 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 1.0000\n",
      "/n 450 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 6ms/step - loss: 2.1791 - accuracy: 0.2584 - val_loss: 2.1269 - val_accuracy: 0.5556\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.0866 - accuracy: 0.7482 - val_loss: 2.0090 - val_accuracy: 0.8222\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9435 - accuracy: 0.8555 - val_loss: 1.8332 - val_accuracy: 0.7944\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7496 - accuracy: 0.8755 - val_loss: 1.6161 - val_accuracy: 0.8500\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.4902 - accuracy: 0.9117 - val_loss: 1.3851 - val_accuracy: 0.9667\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.2888 - accuracy: 0.9869 - val_loss: 1.1837 - val_accuracy: 0.9389\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0714 - accuracy: 0.9772 - val_loss: 1.0030 - val_accuracy: 0.9556\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.9082 - accuracy: 0.9414 - val_loss: 0.8481 - val_accuracy: 0.9722\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.9926 - val_loss: 0.7208 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 1.0000 - val_loss: 0.6107 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.9990 - val_loss: 0.5165 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.9988 - val_loss: 0.3278 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 1.0000\n",
      "/n 500 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 6ms/step - loss: 2.1841 - accuracy: 0.1708 - val_loss: 2.1331 - val_accuracy: 0.8056\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.1029 - accuracy: 0.8278 - val_loss: 2.0238 - val_accuracy: 0.8333\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9702 - accuracy: 0.8932 - val_loss: 1.8481 - val_accuracy: 0.8500\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7581 - accuracy: 0.9114 - val_loss: 1.6219 - val_accuracy: 0.9556\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.5114 - accuracy: 0.9754 - val_loss: 1.3902 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.2707 - accuracy: 0.9903 - val_loss: 1.1721 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0762 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8637 - accuracy: 1.0000 - val_loss: 0.8252 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7225 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 1.0000 - val_loss: 0.5841 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2361 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2059 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1200 - accuracy: 1.0000\n",
      "/n 550 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 6ms/step - loss: 2.1799 - accuracy: 0.2175 - val_loss: 2.1262 - val_accuracy: 0.6833\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.0974 - accuracy: 0.7918 - val_loss: 2.0111 - val_accuracy: 0.9278\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9568 - accuracy: 0.9358 - val_loss: 1.8304 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7502 - accuracy: 0.9971 - val_loss: 1.6020 - val_accuracy: 0.9667\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.5058 - accuracy: 0.9838 - val_loss: 1.3655 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.2897 - accuracy: 1.0000 - val_loss: 1.1465 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0846 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8806 - accuracy: 1.0000 - val_loss: 0.7965 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7459 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 1.0000 - val_loss: 0.3883 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1378 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 1.0000\n",
      "/n 600 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 6ms/step - loss: 2.1832 - accuracy: 0.2758 - val_loss: 2.1279 - val_accuracy: 0.6833\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.0970 - accuracy: 0.7689 - val_loss: 2.0086 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9541 - accuracy: 0.8646 - val_loss: 1.8208 - val_accuracy: 0.9389\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7235 - accuracy: 0.9213 - val_loss: 1.5881 - val_accuracy: 0.9889\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.4808 - accuracy: 0.9664 - val_loss: 1.3537 - val_accuracy: 0.9944\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.2431 - accuracy: 0.9993 - val_loss: 1.1444 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0513 - accuracy: 0.9993 - val_loss: 0.9534 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8954 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7317 - accuracy: 0.9985 - val_loss: 0.6687 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.9990 - val_loss: 0.5588 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2976 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2582 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 1.0000\n",
      "/n 650 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_iter.dat\n",
      "900 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 6ms/step - loss: 2.1810 - accuracy: 0.3169 - val_loss: 2.1305 - val_accuracy: 0.7333\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.0993 - accuracy: 0.7953 - val_loss: 2.0161 - val_accuracy: 0.8556\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9525 - accuracy: 0.9099 - val_loss: 1.8348 - val_accuracy: 0.7722\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7437 - accuracy: 0.8893 - val_loss: 1.6055 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.4888 - accuracy: 0.9140 - val_loss: 1.3668 - val_accuracy: 0.9722\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.2530 - accuracy: 0.9891 - val_loss: 1.1486 - val_accuracy: 0.9833\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0299 - accuracy: 0.9925 - val_loss: 0.9640 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8804 - accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7343 - accuracy: 1.0000 - val_loss: 0.6772 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l_corpus_train=[\n",
    "['en', './train/en_partut-ud-train.txt'],\n",
    "['fr', './train/fr_sequoia-ud-train.txt'],\n",
    "['it', './train/it_partut-ud-train.txt'],\n",
    "['nl', './train/nl_lassysmall-ud-train.txt'],\n",
    "['sl', './train/sl_sst-ud-train.txt'],\n",
    "['es', './train/es_ancora-ud-train.txt'],\n",
    "['pt', './train/pt_bosque-ud-train.txt'],\n",
    "['de', './train/de_gsd-ud-train.txt'],\n",
    "['ca', './train/ca_ancora-ud-train.txt']\n",
    "]\n",
    "\n",
    "codeLangues = calculeCodeLangues(l_corpus_train)\n",
    "l_id = l_identifiants(codeLangues)\n",
    "\n",
    "l_corpus_test=[\n",
    "['en', './test/en_partut-ud-test.txt'],\n",
    "['fr', './test/fr_sequoia-ud-test.txt'],\n",
    "['it', './test/it_partut-ud-test.txt'],\n",
    "['nl', './test/nl_lassysmall-ud-test.txt'],\n",
    "['sl', './test/sl_sst-ud-test.txt'],\n",
    "['es', './test/es_ancora-ud-test.txt'],\n",
    "['pt', './test/pt_bosque-ud-test.txt'],\n",
    "['de', './test/de_gsd-ud-test.txt'],\n",
    "['ca', './test/ca_ancora-ud-test.txt']\n",
    "]\n",
    "\n",
    "extract_bigrams(l_corpus_test, 'random', 500, 10, 'test_2.dat')\n",
    "(x_test_2, y_test_2) = lectureDonnees('test_2.dat', codeLangues)\n",
    "\n",
    "def maxbigramms_variation(max_bigramms, corpus_train = l_corpus_train, cd_lg = codeLangues, x_tst = x_test_2, y_tst = y_test_2) :\n",
    "    ''' Fait varier le nombre de bigrammes durant la phase d'entrainement et qui renvoie les scores du model en fonction\n",
    "    '''\n",
    "    los =[]\n",
    "    accur = []\n",
    "    lg = []\n",
    "\n",
    "    for bigram in range(50,max_bigramms,50):\n",
    "\n",
    "      print(\"/n\", bigram,'/', max_bigramms, \"/n\")\n",
    "    \n",
    "      extract_bigrams(corpus_train, 'random', bigram, 100, 'train_iter.dat')\n",
    "      (x_train_iter, y_train_iter) = lectureDonnees('train_iter.dat', cd_lg)\n",
    "\n",
    "      model = Sequential() # type de model \n",
    "      nbLangues = len(cd_lg.keys()) \n",
    "      model.add(Dense(units=100, activation='tanh', input_dim=28*28)) # premiere couche du RNN \n",
    "      model.add(Dense(units=nbLangues, activation='softmax'))\n",
    "      model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "      model.fit(x_train_iter, y_train_iter, epochs=20, batch_size=16, validation_split=0.2)\n",
    "\n",
    "      score = model.evaluate(x_tst, y_tst)\n",
    "\n",
    "      los.append(score[0])\n",
    "      accur.append(score[1])\n",
    "\n",
    "    x = np.array([x*50 for x in range(1,max_bigramms//50)])\n",
    "    y = np.array(los)\n",
    "    plt.title('Loss en fonction du nombre de bigrammes')\n",
    "    plt.plot(x, y)\n",
    "\n",
    "\n",
    "    y = np.array(accur)\n",
    "    #plt.title('Accur en fonction du nombre de bigrammes')\n",
    "    #plt.plot(x, y)\n",
    "\n",
    "maxbigramms_variation(700)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMrhsAMh1ccY"
   },
   "source": [
    "Le graphique ci-dessus représente les valeurs finales de la fonction de perte en fonction du nombre de bigramme avec lequel le modèle a été entrainé. \n",
    "\n",
    "Nous observons qu'en augmentant le nombre de bigrammes, notre perte est minimale autour de 600 bigrammes, ensuite elle réaugmente. Nous pouvons émettre l'hypothèse que cette nouvelle augmentation du loss est dûe à un début de surapprentissage du classifieur, dans la suite de ce travail nous resterons donc à ce nombre de bigrammes pour garder cette précision.\n",
    "\n",
    "Si nous voulions être plus exacte sur la précision de la valeur minimale de la perte, nous pourrions faire une moyenne de plusieurs courbes, et voir où se situe en moyenne la perte la plus petite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuMkqWu8iZ3f"
   },
   "source": [
    "### Taille de l'échantillon nécessaire pour l'apprentissage d'une langue en particulier sur un grand nombre de données \n",
    "\n",
    "Nous voulons maintenant voir l'influence de l'augmentation du nombre de  langues dans le classifieur. Nous rajoutons donc au corpus dix langues, et réalisons le même traitement qu'au début, c'est-à-dire que nous faisons varier le nombre de bigrammes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_hDPV2LoJqAC",
    "outputId": "14c97cbb-7c55-4b25-be06-dfd7df555ba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langue : en code =  0\n",
      "langue : fr code =  1\n",
      "langue : it code =  2\n",
      "langue : nl code =  3\n",
      "langue : sl code =  4\n",
      "langue : es code =  5\n",
      "langue : pt code =  6\n",
      "langue : de code =  7\n",
      "langue : ca code =  8\n",
      "langue : af code =  9\n",
      "langue : el code =  10\n",
      "langue : be code =  11\n",
      "langue : ja code =  12\n",
      "langue : kk code =  13\n",
      "langue : la code =  14\n",
      "langue : ar code =  15\n",
      "langue : bg code =  16\n",
      "langue : bxr code =  17\n",
      "langue : cop code =  18\n",
      "traite corpus ./test/en_partut-ud-test.txt\n",
      "traite corpus ./test/fr_sequoia-ud-test.txt\n",
      "traite corpus ./test/it_partut-ud-test.txt\n",
      "traite corpus ./test/nl_lassysmall-ud-test.txt\n",
      "traite corpus ./test/sl_sst-ud-test.txt\n",
      "traite corpus ./test/es_ancora-ud-test.txt\n",
      "traite corpus ./test/pt_bosque-ud-test.txt\n",
      "traite corpus ./test/de_gsd-ud-test.txt\n",
      "traite corpus ./test/ca_ancora-ud-test.txt\n",
      "traite corpus ./test/af_afribooms-ud-test.txt\n",
      "traite corpus ./test/el_gdt-ud-test.txt\n",
      "traite corpus ./test/be_hse-ud-test.txt\n",
      "traite corpus ./test/ja_gsd-ud-test.txt\n",
      "traite corpus ./test/kk_ktb-ud-test.txt\n",
      "traite corpus ./test/la_ittb-ud-test.txt\n",
      "traite corpus ./test/ar_nyuad-ud-test.txt\n",
      "traite corpus ./test/be_hse-ud-test.txt\n",
      "traite corpus ./test/bxr_bdt-ud-test.txt\n",
      "traite corpus ./test/cop_scriptorium-ud-test.txt\n",
      "test_3.dat\n",
      "190 exemples lus\n",
      "/n 50 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8768 - accuracy: 0.2089 - val_loss: 2.5961 - val_accuracy: 0.3342\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4673 - accuracy: 0.4217 - val_loss: 2.2167 - val_accuracy: 0.4711\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.1273 - accuracy: 0.4425 - val_loss: 2.0299 - val_accuracy: 0.5500\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.9172 - accuracy: 0.5732 - val_loss: 1.8720 - val_accuracy: 0.5868\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.7585 - accuracy: 0.6554 - val_loss: 1.7129 - val_accuracy: 0.5658\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.5866 - accuracy: 0.6427 - val_loss: 1.5677 - val_accuracy: 0.6421\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.4523 - accuracy: 0.6627 - val_loss: 1.4388 - val_accuracy: 0.6368\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.2932 - accuracy: 0.7185 - val_loss: 1.3282 - val_accuracy: 0.6632\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.1859 - accuracy: 0.7166 - val_loss: 1.2338 - val_accuracy: 0.6658\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.1041 - accuracy: 0.7156 - val_loss: 1.1552 - val_accuracy: 0.6789\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.0572 - accuracy: 0.7129 - val_loss: 1.0942 - val_accuracy: 0.6605\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9528 - accuracy: 0.7483 - val_loss: 1.0436 - val_accuracy: 0.6553\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9253 - accuracy: 0.7326 - val_loss: 0.9915 - val_accuracy: 0.6895\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.8427 - accuracy: 0.7351 - val_loss: 0.9544 - val_accuracy: 0.6789\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8339 - accuracy: 0.7319 - val_loss: 0.9193 - val_accuracy: 0.6974\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7704 - accuracy: 0.7528 - val_loss: 0.8923 - val_accuracy: 0.6842\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7288 - accuracy: 0.7729 - val_loss: 0.8669 - val_accuracy: 0.6921\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7377 - accuracy: 0.7506 - val_loss: 0.8468 - val_accuracy: 0.6842\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7198 - accuracy: 0.7566 - val_loss: 0.8281 - val_accuracy: 0.7079\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.7470 - val_loss: 0.8179 - val_accuracy: 0.6895\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "/n 100 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8863 - accuracy: 0.2006 - val_loss: 2.6066 - val_accuracy: 0.5105\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4819 - accuracy: 0.3919 - val_loss: 2.1805 - val_accuracy: 0.5842\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.1433 - accuracy: 0.6135 - val_loss: 1.9277 - val_accuracy: 0.6658\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.9271 - accuracy: 0.6117 - val_loss: 1.7304 - val_accuracy: 0.6632\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.7398 - accuracy: 0.6987 - val_loss: 1.5486 - val_accuracy: 0.7395\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.5515 - accuracy: 0.6952 - val_loss: 1.3822 - val_accuracy: 0.7289\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.6976 - val_loss: 1.2459 - val_accuracy: 0.7553\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.2324 - accuracy: 0.7210 - val_loss: 1.1280 - val_accuracy: 0.7632\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.1577 - accuracy: 0.7112 - val_loss: 1.0259 - val_accuracy: 0.7658\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.0622 - accuracy: 0.7190 - val_loss: 0.9469 - val_accuracy: 0.7632\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9983 - accuracy: 0.7204 - val_loss: 0.8780 - val_accuracy: 0.7711\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9418 - accuracy: 0.7237 - val_loss: 0.8284 - val_accuracy: 0.7737\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8669 - accuracy: 0.7356 - val_loss: 0.7821 - val_accuracy: 0.7658\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8533 - accuracy: 0.7223 - val_loss: 0.7442 - val_accuracy: 0.7789\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7493 - accuracy: 0.7523 - val_loss: 0.7147 - val_accuracy: 0.7895\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7572 - accuracy: 0.7311 - val_loss: 0.6861 - val_accuracy: 0.7711\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.7279 - val_loss: 0.6586 - val_accuracy: 0.7921\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7552 - accuracy: 0.7293 - val_loss: 0.6428 - val_accuracy: 0.7763\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7254 - accuracy: 0.7279 - val_loss: 0.6224 - val_accuracy: 0.7842\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.7653 - val_loss: 0.6049 - val_accuracy: 0.7789\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "/n 150 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8920 - accuracy: 0.2051 - val_loss: 2.6055 - val_accuracy: 0.5421\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4862 - accuracy: 0.4495 - val_loss: 2.1601 - val_accuracy: 0.5947\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.1210 - accuracy: 0.5779 - val_loss: 1.8757 - val_accuracy: 0.7079\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.8853 - accuracy: 0.6597 - val_loss: 1.6522 - val_accuracy: 0.6895\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.6523 - accuracy: 0.6514 - val_loss: 1.4535 - val_accuracy: 0.7289\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.4808 - accuracy: 0.7197 - val_loss: 1.2758 - val_accuracy: 0.7316\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.3024 - accuracy: 0.7237 - val_loss: 1.1446 - val_accuracy: 0.7421\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.1844 - accuracy: 0.7130 - val_loss: 1.0320 - val_accuracy: 0.7658\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.0745 - accuracy: 0.7371 - val_loss: 0.9477 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9659 - accuracy: 0.7538 - val_loss: 0.8811 - val_accuracy: 0.7605\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9123 - accuracy: 0.7452 - val_loss: 0.8171 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8716 - accuracy: 0.7182 - val_loss: 0.7742 - val_accuracy: 0.7605\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8055 - accuracy: 0.7495 - val_loss: 0.7333 - val_accuracy: 0.7632\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.7352 - val_loss: 0.7053 - val_accuracy: 0.7605\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.7670 - val_loss: 0.6771 - val_accuracy: 0.7605\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.7603 - val_loss: 0.6547 - val_accuracy: 0.7605\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.7485 - val_loss: 0.6402 - val_accuracy: 0.7526\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.7608 - val_loss: 0.6221 - val_accuracy: 0.7763\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.7638 - val_loss: 0.6112 - val_accuracy: 0.7684\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.7360 - val_loss: 0.6036 - val_accuracy: 0.7632\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "/n 200 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8771 - accuracy: 0.1889 - val_loss: 2.5699 - val_accuracy: 0.3579\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4569 - accuracy: 0.4823 - val_loss: 2.1301 - val_accuracy: 0.4737\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.0806 - accuracy: 0.4737 - val_loss: 1.8784 - val_accuracy: 0.6605\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.8474 - accuracy: 0.6147 - val_loss: 1.6641 - val_accuracy: 0.6632\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.6174 - accuracy: 0.6540 - val_loss: 1.4617 - val_accuracy: 0.7184\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.4619 - accuracy: 0.7084 - val_loss: 1.2925 - val_accuracy: 0.7211\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.2526 - accuracy: 0.7009 - val_loss: 1.1635 - val_accuracy: 0.7263\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.1363 - accuracy: 0.7640 - val_loss: 1.0577 - val_accuracy: 0.7316\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.0260 - accuracy: 0.7588 - val_loss: 0.9647 - val_accuracy: 0.7474\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9269 - accuracy: 0.7695 - val_loss: 0.9044 - val_accuracy: 0.7289\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8706 - accuracy: 0.7599 - val_loss: 0.8444 - val_accuracy: 0.7342\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8269 - accuracy: 0.7550 - val_loss: 0.7981 - val_accuracy: 0.7263\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7927 - accuracy: 0.7491 - val_loss: 0.7617 - val_accuracy: 0.7368\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.7500 - accuracy: 0.7538 - val_loss: 0.7308 - val_accuracy: 0.7263\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7427 - accuracy: 0.7190 - val_loss: 0.7120 - val_accuracy: 0.7342\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.7737 - val_loss: 0.6797 - val_accuracy: 0.7684\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.7677 - val_loss: 0.6679 - val_accuracy: 0.7342\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.7471 - val_loss: 0.6483 - val_accuracy: 0.7579\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.7622 - val_loss: 0.6380 - val_accuracy: 0.7447\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.7665 - val_loss: 0.6288 - val_accuracy: 0.7474\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "/n 250 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8758 - accuracy: 0.1928 - val_loss: 2.5766 - val_accuracy: 0.3500\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4522 - accuracy: 0.4171 - val_loss: 2.1672 - val_accuracy: 0.4263\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.0788 - accuracy: 0.5057 - val_loss: 1.9178 - val_accuracy: 0.5526\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.8492 - accuracy: 0.6091 - val_loss: 1.6997 - val_accuracy: 0.5632\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.6071 - accuracy: 0.6352 - val_loss: 1.4994 - val_accuracy: 0.6079\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.4158 - accuracy: 0.6621 - val_loss: 1.3330 - val_accuracy: 0.6447\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.2520 - accuracy: 0.6989 - val_loss: 1.1971 - val_accuracy: 0.6947\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.1292 - accuracy: 0.7211 - val_loss: 1.0940 - val_accuracy: 0.7158\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.0264 - accuracy: 0.7406 - val_loss: 1.0029 - val_accuracy: 0.7132\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9069 - accuracy: 0.7556 - val_loss: 0.9336 - val_accuracy: 0.7079\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8770 - accuracy: 0.7427 - val_loss: 0.8714 - val_accuracy: 0.7342\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8072 - accuracy: 0.7581 - val_loss: 0.8259 - val_accuracy: 0.7342\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7812 - accuracy: 0.7504 - val_loss: 0.7819 - val_accuracy: 0.7342\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.7744 - val_loss: 0.7550 - val_accuracy: 0.7395\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.7526 - val_loss: 0.7225 - val_accuracy: 0.7395\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.7501 - val_loss: 0.6982 - val_accuracy: 0.7342\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.7518 - val_loss: 0.6779 - val_accuracy: 0.7368\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.7658 - val_loss: 0.6637 - val_accuracy: 0.7447\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.7484 - val_loss: 0.6483 - val_accuracy: 0.7342\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7780 - val_loss: 0.6403 - val_accuracy: 0.7342\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "/n 300 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8712 - accuracy: 0.1848 - val_loss: 2.5470 - val_accuracy: 0.4184\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4233 - accuracy: 0.4700 - val_loss: 2.1195 - val_accuracy: 0.6105\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.0550 - accuracy: 0.5930 - val_loss: 1.8681 - val_accuracy: 0.6368\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.8073 - accuracy: 0.6535 - val_loss: 1.6539 - val_accuracy: 0.6895\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.6190 - accuracy: 0.7270 - val_loss: 1.4612 - val_accuracy: 0.7079\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.4077 - accuracy: 0.7219 - val_loss: 1.3050 - val_accuracy: 0.7053\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.2530 - accuracy: 0.7305 - val_loss: 1.1795 - val_accuracy: 0.7000\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.1139 - accuracy: 0.7416 - val_loss: 1.0683 - val_accuracy: 0.7316\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9945 - accuracy: 0.7645 - val_loss: 0.9838 - val_accuracy: 0.7342\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9076 - accuracy: 0.7604 - val_loss: 0.9139 - val_accuracy: 0.7289\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8395 - accuracy: 0.7619 - val_loss: 0.8637 - val_accuracy: 0.7263\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7848 - accuracy: 0.7681 - val_loss: 0.8178 - val_accuracy: 0.7368\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7328 - accuracy: 0.7715 - val_loss: 0.7840 - val_accuracy: 0.7342\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.7740 - val_loss: 0.7530 - val_accuracy: 0.7342\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.7689 - val_loss: 0.7335 - val_accuracy: 0.7263\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.7477 - val_loss: 0.7108 - val_accuracy: 0.7211\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.7526 - val_loss: 0.6940 - val_accuracy: 0.7263\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.7538 - val_loss: 0.6790 - val_accuracy: 0.7368\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.7660 - val_loss: 0.6674 - val_accuracy: 0.7316\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.7718 - val_loss: 0.6567 - val_accuracy: 0.7395\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "/n 350 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8695 - accuracy: 0.2260 - val_loss: 2.5453 - val_accuracy: 0.5105\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4444 - accuracy: 0.5339 - val_loss: 2.0973 - val_accuracy: 0.4132\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.0751 - accuracy: 0.5508 - val_loss: 1.8470 - val_accuracy: 0.5658\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.8380 - accuracy: 0.6367 - val_loss: 1.6170 - val_accuracy: 0.7105\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.5868 - accuracy: 0.7437 - val_loss: 1.4176 - val_accuracy: 0.7342\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.7337 - val_loss: 1.2499 - val_accuracy: 0.7053\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.2336 - accuracy: 0.7459 - val_loss: 1.1152 - val_accuracy: 0.7684\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.1048 - accuracy: 0.7223 - val_loss: 1.0161 - val_accuracy: 0.7105\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9779 - accuracy: 0.7485 - val_loss: 0.9274 - val_accuracy: 0.7105\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.8962 - accuracy: 0.7718 - val_loss: 0.8491 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8405 - accuracy: 0.7567 - val_loss: 0.8010 - val_accuracy: 0.7474\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8110 - accuracy: 0.7410 - val_loss: 0.7640 - val_accuracy: 0.7237\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7513 - accuracy: 0.7484 - val_loss: 0.7256 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.7588 - val_loss: 0.7000 - val_accuracy: 0.7421\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.7638 - val_loss: 0.6732 - val_accuracy: 0.7632\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.7507 - val_loss: 0.6537 - val_accuracy: 0.7658\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.7618 - val_loss: 0.6403 - val_accuracy: 0.7289\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.7693 - val_loss: 0.6286 - val_accuracy: 0.7632\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.7747 - val_loss: 0.6114 - val_accuracy: 0.7605\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.7679 - val_loss: 0.6080 - val_accuracy: 0.7711\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "/n 400 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8671 - accuracy: 0.2284 - val_loss: 2.5612 - val_accuracy: 0.3421\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4291 - accuracy: 0.3166 - val_loss: 2.1523 - val_accuracy: 0.5316\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 2.0632 - accuracy: 0.6150 - val_loss: 1.8942 - val_accuracy: 0.7289\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.8284 - accuracy: 0.6859 - val_loss: 1.6630 - val_accuracy: 0.7053\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.6026 - accuracy: 0.6891 - val_loss: 1.4602 - val_accuracy: 0.7289\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.4185 - accuracy: 0.7037 - val_loss: 1.2845 - val_accuracy: 0.7605\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.2709 - accuracy: 0.7358 - val_loss: 1.1414 - val_accuracy: 0.7553\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.1127 - accuracy: 0.7489 - val_loss: 1.0223 - val_accuracy: 0.7526\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.0175 - accuracy: 0.7489 - val_loss: 0.9309 - val_accuracy: 0.7737\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8937 - accuracy: 0.7444 - val_loss: 0.8532 - val_accuracy: 0.7658\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8406 - accuracy: 0.7577 - val_loss: 0.7964 - val_accuracy: 0.7526\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7822 - accuracy: 0.7600 - val_loss: 0.7479 - val_accuracy: 0.7553\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7383 - accuracy: 0.7549 - val_loss: 0.7136 - val_accuracy: 0.7579\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.7423 - val_loss: 0.6760 - val_accuracy: 0.7737\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.7754 - val_loss: 0.6481 - val_accuracy: 0.7947\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.7784 - val_loss: 0.6235 - val_accuracy: 0.7789\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.7723 - val_loss: 0.6171 - val_accuracy: 0.7579\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.7561 - val_loss: 0.5932 - val_accuracy: 0.7842\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.7633 - val_loss: 0.5801 - val_accuracy: 0.7816\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7656 - val_loss: 0.5762 - val_accuracy: 0.7526\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "/n 450 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8746 - accuracy: 0.1716 - val_loss: 2.5596 - val_accuracy: 0.3553\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4263 - accuracy: 0.4787 - val_loss: 2.1496 - val_accuracy: 0.4684\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.0636 - accuracy: 0.5566 - val_loss: 1.9023 - val_accuracy: 0.5421\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.8057 - accuracy: 0.6268 - val_loss: 1.6640 - val_accuracy: 0.6658\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.5833 - accuracy: 0.6812 - val_loss: 1.4515 - val_accuracy: 0.6974\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.3867 - accuracy: 0.7227 - val_loss: 1.2750 - val_accuracy: 0.7263\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.2278 - accuracy: 0.7195 - val_loss: 1.1363 - val_accuracy: 0.7132\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.0882 - accuracy: 0.7481 - val_loss: 1.0221 - val_accuracy: 0.7553\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.9487 - accuracy: 0.7560 - val_loss: 0.9352 - val_accuracy: 0.7368\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9051 - accuracy: 0.7449 - val_loss: 0.8643 - val_accuracy: 0.7368\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7973 - accuracy: 0.7657 - val_loss: 0.8169 - val_accuracy: 0.7263\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7904 - accuracy: 0.7497 - val_loss: 0.7700 - val_accuracy: 0.7368\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.7208 - accuracy: 0.7618 - val_loss: 0.7383 - val_accuracy: 0.7447\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7331 - accuracy: 0.7555 - val_loss: 0.7156 - val_accuracy: 0.7289\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7200 - accuracy: 0.7426 - val_loss: 0.6845 - val_accuracy: 0.7526\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.7535 - val_loss: 0.6711 - val_accuracy: 0.7368\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7624 - val_loss: 0.6535 - val_accuracy: 0.7342\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.7625 - val_loss: 0.6396 - val_accuracy: 0.7553\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.7584 - val_loss: 0.6341 - val_accuracy: 0.7447\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.7538 - val_loss: 0.6206 - val_accuracy: 0.7526\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "/n 500 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8765 - accuracy: 0.1903 - val_loss: 2.5746 - val_accuracy: 0.3395\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4290 - accuracy: 0.3236 - val_loss: 2.1528 - val_accuracy: 0.5132\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.0641 - accuracy: 0.5721 - val_loss: 1.8892 - val_accuracy: 0.5816\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.8181 - accuracy: 0.5967 - val_loss: 1.6592 - val_accuracy: 0.6447\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.6064 - accuracy: 0.6256 - val_loss: 1.4426 - val_accuracy: 0.6947\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.4238 - accuracy: 0.6717 - val_loss: 1.2644 - val_accuracy: 0.7474\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.2472 - accuracy: 0.7420 - val_loss: 1.1212 - val_accuracy: 0.7842\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.1238 - accuracy: 0.7317 - val_loss: 1.0079 - val_accuracy: 0.7553\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.0087 - accuracy: 0.7551 - val_loss: 0.9113 - val_accuracy: 0.7658\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.9304 - accuracy: 0.7679 - val_loss: 0.8417 - val_accuracy: 0.7789\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8682 - accuracy: 0.7590 - val_loss: 0.7833 - val_accuracy: 0.7553\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8035 - accuracy: 0.7547 - val_loss: 0.7301 - val_accuracy: 0.7921\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7778 - accuracy: 0.7459 - val_loss: 0.6949 - val_accuracy: 0.7842\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.7470 - accuracy: 0.7554 - val_loss: 0.6646 - val_accuracy: 0.7684\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.7716 - val_loss: 0.6362 - val_accuracy: 0.7789\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.7609 - val_loss: 0.6152 - val_accuracy: 0.7842\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.7559 - val_loss: 0.5976 - val_accuracy: 0.7816\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7549 - val_loss: 0.5856 - val_accuracy: 0.7684\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7717 - val_loss: 0.5757 - val_accuracy: 0.7579\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.7588 - val_loss: 0.5670 - val_accuracy: 0.7763\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "/n 550 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8699 - accuracy: 0.2354 - val_loss: 2.5603 - val_accuracy: 0.2132\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4153 - accuracy: 0.3202 - val_loss: 2.1460 - val_accuracy: 0.4211\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.0482 - accuracy: 0.4528 - val_loss: 1.8944 - val_accuracy: 0.4789\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.7775 - accuracy: 0.5992 - val_loss: 1.6683 - val_accuracy: 0.5763\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.5384 - accuracy: 0.6482 - val_loss: 1.4688 - val_accuracy: 0.7053\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.3504 - accuracy: 0.7276 - val_loss: 1.3060 - val_accuracy: 0.6947\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.2114 - accuracy: 0.7505 - val_loss: 1.1725 - val_accuracy: 0.7053\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.0612 - accuracy: 0.7652 - val_loss: 1.0778 - val_accuracy: 0.6921\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9919 - accuracy: 0.7228 - val_loss: 0.9828 - val_accuracy: 0.7079\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.8826 - accuracy: 0.7615 - val_loss: 0.9181 - val_accuracy: 0.6947\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.8419 - accuracy: 0.7489 - val_loss: 0.8607 - val_accuracy: 0.7053\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7894 - accuracy: 0.7384 - val_loss: 0.8122 - val_accuracy: 0.7368\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7319 - accuracy: 0.7641 - val_loss: 0.7731 - val_accuracy: 0.7368\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.7202 - accuracy: 0.7598 - val_loss: 0.7445 - val_accuracy: 0.7237\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.7500 - val_loss: 0.7272 - val_accuracy: 0.7079\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.7522 - val_loss: 0.7024 - val_accuracy: 0.7421\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.7523 - val_loss: 0.6817 - val_accuracy: 0.7421\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.7489 - val_loss: 0.6705 - val_accuracy: 0.7421\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.7689 - val_loss: 0.6490 - val_accuracy: 0.7342\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.7728 - val_loss: 0.6468 - val_accuracy: 0.7526\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "/n 600 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8686 - accuracy: 0.1748 - val_loss: 2.5535 - val_accuracy: 0.2868\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 2.4198 - accuracy: 0.4319 - val_loss: 2.1331 - val_accuracy: 0.6158\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 2.0403 - accuracy: 0.5644 - val_loss: 1.8743 - val_accuracy: 0.5947\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.7951 - accuracy: 0.5774 - val_loss: 1.6356 - val_accuracy: 0.6605\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.5883 - accuracy: 0.6455 - val_loss: 1.4296 - val_accuracy: 0.7105\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.3802 - accuracy: 0.7175 - val_loss: 1.2553 - val_accuracy: 0.7132\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.2174 - accuracy: 0.7252 - val_loss: 1.1238 - val_accuracy: 0.7158\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.1010 - accuracy: 0.7293 - val_loss: 1.0144 - val_accuracy: 0.7395\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9873 - accuracy: 0.7739 - val_loss: 0.9331 - val_accuracy: 0.7342\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.9515 - accuracy: 0.7352 - val_loss: 0.8719 - val_accuracy: 0.7421\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8171 - accuracy: 0.7748 - val_loss: 0.8139 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.8066 - accuracy: 0.7648 - val_loss: 0.7700 - val_accuracy: 0.7368\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.7811 - accuracy: 0.7413 - val_loss: 0.7395 - val_accuracy: 0.7421\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7279 - accuracy: 0.7667 - val_loss: 0.7108 - val_accuracy: 0.7395\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.7197 - accuracy: 0.7522 - val_loss: 0.6882 - val_accuracy: 0.7447\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7789 - val_loss: 0.6631 - val_accuracy: 0.7526\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7717 - val_loss: 0.6473 - val_accuracy: 0.7763\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.7691 - val_loss: 0.6336 - val_accuracy: 0.7553\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.7736 - val_loss: 0.6271 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7629 - val_loss: 0.6116 - val_accuracy: 0.7500\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "/n 650 / 700 /n\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_iter.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8669 - accuracy: 0.2309 - val_loss: 2.5325 - val_accuracy: 0.5632\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4168 - accuracy: 0.5120 - val_loss: 2.1045 - val_accuracy: 0.6289\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 2.0520 - accuracy: 0.5797 - val_loss: 1.8281 - val_accuracy: 0.7289\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.7768 - accuracy: 0.7067 - val_loss: 1.5931 - val_accuracy: 0.7395\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.5841 - accuracy: 0.7020 - val_loss: 1.3989 - val_accuracy: 0.7342\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.3550 - accuracy: 0.7502 - val_loss: 1.2339 - val_accuracy: 0.7474\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.2160 - accuracy: 0.7298 - val_loss: 1.1016 - val_accuracy: 0.7711\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 1.0956 - accuracy: 0.7313 - val_loss: 0.9971 - val_accuracy: 0.7316\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.9727 - accuracy: 0.7648 - val_loss: 0.9063 - val_accuracy: 0.7368\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.9053 - accuracy: 0.7462 - val_loss: 0.8347 - val_accuracy: 0.7605\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8155 - accuracy: 0.7555 - val_loss: 0.7825 - val_accuracy: 0.7737\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.7542 - accuracy: 0.7473 - val_loss: 0.7400 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.7338 - accuracy: 0.7620 - val_loss: 0.7099 - val_accuracy: 0.7342\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.7547 - val_loss: 0.6807 - val_accuracy: 0.7289\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.7517 - val_loss: 0.6576 - val_accuracy: 0.7632\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.7589 - val_loss: 0.6408 - val_accuracy: 0.7526\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.7557 - val_loss: 0.6265 - val_accuracy: 0.7395\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.7526 - val_loss: 0.6126 - val_accuracy: 0.7658\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.7698 - val_loss: 0.6033 - val_accuracy: 0.7684\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.7642 - val_loss: 0.5927 - val_accuracy: 0.7868\n",
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "l_corpus_train=[\n",
    "['en', './train/en_partut-ud-train.txt'],\n",
    "['fr', './train/fr_sequoia-ud-train.txt'],\n",
    "['it', './train/it_partut-ud-train.txt'],\n",
    "['nl', './train/nl_lassysmall-ud-train.txt'],\n",
    "['sl', './train/sl_sst-ud-train.txt'],\n",
    "['es', './train/es_ancora-ud-train.txt'],\n",
    "['pt', './train/pt_bosque-ud-train.txt'],\n",
    "['de', './train/de_gsd-ud-train.txt'],\n",
    "['ca', './train/ca_ancora-ud-train.txt'],\n",
    "['af', './train/af_afribooms-ud-train.txt'],\n",
    "['el', './train/el_gdt-ud-train.txt'],\n",
    "['be', './train/be_hse-ud-train.txt'],\n",
    "['ja', './train/ja_gsd-ud-train.txt'],\n",
    "['kk', './train/kk_ktb-ud-train.txt'],\n",
    "['la', './train/la_ittb-ud-train.txt'], \n",
    "['ar', './train/ar_nyuad-ud-train.txt'], \n",
    "['bg','./train/be_hse-ud-train.txt'], \n",
    "['bxr', './train/bxr_bdt-ud-train.txt'],\n",
    "['cop', './train/cop_scriptorium-ud-train.txt']\n",
    "]\n",
    "\n",
    "codeLangues = calculeCodeLangues(l_corpus_train)\n",
    "l_id = l_identifiants(codeLangues)\n",
    "\n",
    "l_corpus_test=[\n",
    "['en', './test/en_partut-ud-test.txt'],\n",
    "['fr', './test/fr_sequoia-ud-test.txt'],\n",
    "['it', './test/it_partut-ud-test.txt'],\n",
    "['nl', './test/nl_lassysmall-ud-test.txt'],\n",
    "['sl', './test/sl_sst-ud-test.txt'],\n",
    "['es', './test/es_ancora-ud-test.txt'],\n",
    "['pt', './test/pt_bosque-ud-test.txt'],\n",
    "['de', './test/de_gsd-ud-test.txt'],\n",
    "['ca', './test/ca_ancora-ud-test.txt'],\n",
    "['af', './test/af_afribooms-ud-test.txt'],\n",
    "['el', './test/el_gdt-ud-test.txt'],\n",
    "['be', './test/be_hse-ud-test.txt'],\n",
    "['ja', './test/ja_gsd-ud-test.txt'],\n",
    "['kk', './test/kk_ktb-ud-test.txt'],\n",
    "['la', './test/la_ittb-ud-test.txt'],\n",
    "['ar', './test/ar_nyuad-ud-test.txt'], \n",
    "['bg','./test/be_hse-ud-test.txt'], \n",
    "['bxr', './test/bxr_bdt-ud-test.txt'],\n",
    "['cop', './test/cop_scriptorium-ud-test.txt']\n",
    "]\n",
    "\n",
    "extract_bigrams(l_corpus_test, 'random', 500, 10, 'test_3.dat')\n",
    "(x_test_3, y_test_3) = lectureDonnees('test_3.dat', codeLangues)\n",
    "\n",
    "def maxbigramms_variation_2(max_bigramms, corpus_train = l_corpus_train, cd_lg = codeLangues, x_tst = x_test_3, y_tst = y_test_3) :\n",
    "    ''' Fait varier le nombre de bigrammes durant la phase d'entrainement et qui renvoie les scores du model en fonction\n",
    "    '''\n",
    "    los =[]\n",
    "    accur = []\n",
    "    lg = []\n",
    "\n",
    "    for bigram in range(50,max_bigramms,50):\n",
    "\n",
    "      print(\"/n\", bigram,'/', max_bigramms, \"/n\")\n",
    "    \n",
    "      extract_bigrams(corpus_train, 'random', bigram, 100, 'train_iter.dat')\n",
    "      (x_train_iter, y_train_iter) = lectureDonnees('train_iter.dat', cd_lg)\n",
    "\n",
    "      model = Sequential() # type de model \n",
    "      nbLangues = len(cd_lg.keys()) \n",
    "      model.add(Dense(units=100, activation='tanh', input_dim=28*28)) # premiere couche du RNN \n",
    "      model.add(Dense(units=nbLangues, activation='softmax'))\n",
    "      model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "      model.fit(x_train_iter, y_train_iter, epochs=20, batch_size=16, validation_split=0.2)\n",
    "\n",
    "      l_pred = model.predict(x_tst, batch_size=None, verbose=1, steps=None) \n",
    "\n",
    "      lg.append(note(l_pred, y_tst, cd_lg))\n",
    "\n",
    "    return lg\n",
    "\n",
    "mx_big = 700\n",
    "lang = maxbigramms_variation_2(max_bigramms = mx_big)\n",
    "\n",
    "\n",
    "\n",
    "#print('toutes les langues possibles ', l_id)\n",
    "#print('Accuraccy avec le maximum de bigrammes ', lang[-1])\n",
    "\n",
    "#print('toutes accuracy pour une langue donnée',[i[-3] for i in lang])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "2kMa167AUUMl",
    "outputId": "33fa1ebc-705b-4226-8caf-7ea51d4b5167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0.  0.2 0.8 0.  0.  0.  0.3 0.  0.  0.  0.7 0.  0. ]\n",
      "[0.6 0.5 0.  0.8 0.8 0.3 0.  0.  0.3 0.5 0.  0.  0. ]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0.  0.4 0.  0.  0.  0.5 0.  0.  0.5 0.3 0.  0.  0.1]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0.  0.  0.3 0.  0.  0.  0.7 0.5 0.  0.  0.5 0.7 0.5]\n",
      "[0.  0.1 0.  0.1 0.1 0.  0.  0.2 0.  0.  0.  0.1 0.1]\n",
      "[0.9 0.  0.  0.  0.  0.9 0.6 0.  0.5 0.6 0.2 0.9 0.6]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEWCAYAAACjYXoKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXhcV3nwf+/suyRbi7VZki0ntrPYDs4CNE4gIRuQQGgJoTRJSwNtgdKWr6WlJYStdPloSymUrf3Ywx5IWEIgEBICzmpns7xbsiSPbO2aVZrlfH/cO/JoNCPNqtFyf8+jRzN3OefM3d77nncTpRQGBgYGBgalYKr2AAwMDAwMVj6GMDEwMDAwKBlDmBgYGBgYlIwhTAwMDAwMSsYQJgYGBgYGJWMIEwMDAwODklk1wkRElIh0F7nv5SJyqNxjytFXr4hcXcR+V4rIQCXGtJoRkdeLSL+IBEVk1xL2+xMRuX0J+rlDRH5d6X5KpdjrvoT+inoeLHY8l+q8rkSWXJjoF1VEv7lTf/+1xGOYc6EppR5VSp27lGMoFf04dlZ7HCuA/wu8UynlUUrtq0QHInK3iHw1fZlS6nql1Jcq0Z9B9TDOa24sVer3tUqpn1epb4MiEBGLUipe7XEUQQfwYrUHYZA/K/hay4mICCBKqWS1x1Ipls00l4jYRWRCRM5PW9agazGN+vc7ReSoiIyJyH0i0pKjrYdF5I/Tvs+qriLyiL74WV0ruiVzCklEtultTIjIiyJyY9q6L4rIp0TkRyISEJHHRWTzAr/rD0SkT0RGReTvM9aZRORvReSYvv5bIrKuwEOHiLxaRPaJyJQ+pXN3xvrfEZHf6L+nX0TuWOw46d+ViLxDRI4AR/Rln9DbmBKRp0Xk8rTtzSLyPv33BPT17frx+njGmO4Tkb/M8Xu2isjP9PN8SETemLYur+OvX09BwIx2ro/py4s+tyJyXtq4Tuu/9TrgfcAt+vX0bOax1c/zP+jXwRkR+bKI1OjrOvXjfLuInBSRkczrJON3rdeP3ZSIPAGkjy/VliVt2ZxznNHW3fo192X9974oIrvT1i92rD4t2rRPUEQeE5ENIvIfIjIuIgdl/rTixSJyQF///0TEobd1pYgMiMh7RWQI+H+F3hsi8tci4heRUyLyRxnr7CLyf/Xje1pEPiMizlxtabvIf4nIpP47rsp2PPXr/eP6OTshIu9MP/76th8VkceAMLBJRP5QRHr0431cRN6e1nbqOPyNfp34ReR1InKDiBzWr7v3ZZy/b4vIV/X2nheRc0Tk7/T9+0XkmrTta0Tkf/R2B0XkIyJi1td1i8iv9N88IiLfXOD4ZEcptaR/QC9wdY51/wt8NO37O4AH9M+vBEaAiwA78EngkbRtFdCtf34Y+OO0dXcAv862rf79SmBA/2wFjqI9IGx6vwHgXH39F4FR4BI0ze5rwDdy/J7tQBDYo4/534B46vcD7wb2Am36+s8C9+Roa3aMOdZdgPZycCFwGnidvq5DH/+t+m9bD+ws4Dj9DFgHOPVlb9HbsADvAYYAh77ur4HngXMBAXbo214CnAJM+nb1aDdXU5bf4gb6gT/U+9iln/fthR7/LNdF0ecW8AJ+/Tc79O+X6uvuBr6a0e/ssQX+SO93E+ABvgd8RV/XqY/x84BTP2bTwLYcv+cbwLf043Q+MJg6Z2ltWbKNI0tbdwNR4AY0ofsxYG8Bx2oEeIl+PH4BnABu09v6CPDLjPv+BaAd7Xp6DPhI2vUbB/4Z7T5wUti9cR3aNX++fly+nnHe/x24T+/XC9wPfCxHW3foY/lL/RjcAkwC67Kc1z8BDuhjrAN+nn789W1PAuehXU9W4NVoLwACXIF2H1yUcRzu0re9ExjWf49XbycCdGWcv2v19r+sn4O/T9v/RNpvu1c/jm6gEXgCeLu+7h59P5N+Pn+n4Gd7MQKhlD/9ogoCE2l/d+rrrgaOpW37GHCb/vl/gH9JW+cBYkBnlofG7Alf4CGZS5hcjvaANKWtvwe4O+0m+kLauhuAgzl+612kPej0kzjDWWHSA1yVtr5Z/02WLG3NjjGPY/wfwL/rn/8OuDfHdvkcp1cu0tc4sEP/fAi4Kcd2PcCr9M/vBH6cY7tbgEczln0W+EChxz/LdVH0uUUTxvty9HE3CwuTh4A/S1t3buo8c1YAtKWtfwJ4U5Z+zPp+W9OW/SOlCZOfp33fDkQKOFafT1v3LqAn7fsFwETa917gTzKO7bG0a3sG/aWkiHvjf4F/Svt+Tuq8oz20Q8DmtPUvJe0hm9HWHWgvPpJxPv4gy3n9BfrDWP9+NfOFyYcWuX++D7w77ThEALP+3au3d2na9k9z9kXxbuBnaetei/Zszdy/FmhCe0lxpm1/K7rARxNEnyPtOiz0r1o2k9ep7DaTXwIuEbkU7U1jJ5o0BWgBnkltqJQKisgo0Ip2oZaLFqBfzZ3b7NP7STGU9jmMJthytpX6opQK6WNO0QHcKyLpfSXQTvxgvgPWj9c/ob2Z2dDe5L6tr24HjuXbVhb607+IyP8B3or22xTgQ9M0FuvrS2hazc/0/5/IsV0HcKmITKQtswBfSfue7/HPpJRzW8pxbNH7Se/TgnaeF+s3nQZ9v/Rz0pdlu0LI7NehT9Pkc6xOp32OZPme+Rsyx50+TT2slIqmfS/k3mhBe8imt52iAXABT4tIapmgCeZcDCr9CZtjrOn9pv+m/izbZN4/1wMfQBN4Jn1sz6dtMqqUSuifI/r/hY5r5rqRLPt79LFaAX/acTClje9vgA8DT4jIOPBxpdT/Zvk9OVk2NhMA/SB8C01i3gr8UCkV0FefQrvAABARN9oUSraHbgjtJKXYUMAwTgHtIpJ+bDbm6Gcx/GgPIQBExIU25hT9wPVKqdq0P4dSqtC+vo6mxrcrpWqAz6DdMKk+ctl08jlOszeVaPaRvwHeCNQppWrRpgDy6eurwE0isgPYhvZGlo1+4FcZx8SjlPrTHNsXQinnth9tmiobKsfy9H470r5vRJvOOJ1985wM6/u1py3bmPY5pP8v9tpPp5z3QYrMcZ9K+555DAu5N+bcZ8w9JiNoD9Xz0tqpUUot9ALSKmlP3CxjTe+3Le17e5Zt0u8fO/BdNA/DJv3++TFn759K0o+mmdSnHQefUuo8AKXUkFLqTqVUC/B24NNSoGv1shImOl9Hm+r4ff1zinuAPxSRnfpJ+UfgcaVUb5Y29gM3i4hLPyBvzVh/mtwPhsfR3tD+RkSsInIlmvr4jSJ+y3eA14hmALcBH2LuMf8M8FER6YBZh4ObiujHC4wppaIicgnw5rR1XwOuFpE3iohFNAPuTn3dYscpWz9xtIeaRUTuQtNMUnwB+LCIbBGNC0VkPYBSagB4Ek3D+K5SKkJ2fgicI5rjglX/u1hEtuV9NHJTyrn9IdAsIn+hG3S9ukYI2vXUmfHgTece4C9FpEtEPGjX7jdVgR5L+svW94C79XO2Hbg9bf0w2sP+Lbpx+I/ILdwXo5z3QYp3iEibaIb0vwcWMvIWcm98C7hDRLbrL2wfSK3QNavPA/8uZx15WkXk2gX6bgT+XP/dv4f28vPjHP2+W2+vFnjvAm3C2VmDYSCuaynXLLxLeVBK+YEHgY+LiE80B4fNInIFgIj8noikBOM4mhAsyPOsWsLkfpkbZ5KaykIp9TjaG1YL8JO05T8H3o8m2f1oN8mbcrT/72hzsKfRple+lrH+buBLonmpvDF9hVJqBu2muR7trebTaHabg4X+SKXUi2hOBF/XxzwOpAcefgJNo3hQRAJoBsdLM9vJgz8DPqS3cRfaRZ4aw0m0+en3AGNoAmSHvnqx45TJT4EHgMNoqn+UuWr8v+l9PwhModm50r1mvoQ2l54+ZTUHXRO9Bu3cnkKbhkkZZkuilHOrj+tV+v5DaN5tr9BXp6YUR0XkmSy7/y/ab34EzUAaRbMxFMM70aYthtDsFv8vY/2daI4Qo2gG298U00k574M0vo52bRxHmzL8yALb5n1vKKV+gmYn/AWa08AvMjZ5r758r4hMoRnKF4orexzYgva7Pwr8rlJqNMt2n9d/z3PAPjSBE0ebjss2zgDw52j3yDjaS999C4yj3NyGJtAO6P1/B80WBXAx8LhoHpD3odlxjhfSuMydGjQwqBwisgdtuqtDGReewSpD1zQ+o5TqWHTjVchynOYyWIWIiBXN3fMLhiAxWA2IiFO0GBCLiLSiTa/du9h+qxVDmBhUHN3eMYGmUv9HlYdjYFAuBPgg2pTRPjR35ruqOqIqYkxzGRgYGBiUjKGZGBgYGBiUTLWCFoumvr5edXZ2VnsYBgYGBiuKp59+ekQp1VCp9lecMOns7OSpp56q9jAMDAwMVhQiUmq2hAUxprkMDAwMDErGECYGBgYGBiVjCBMDAwMDg5IxhImBgYGBQckYwsTAwMDAoGQqJkxE5H9FKx35Qo71IiL/KVoZ3udE5KJKjcXAwMDAoLJUUjP5Ilo5zVxcj5aZcwvwNuC/KzgWAwMDA4MKUrE4E6XUIyLSucAmNwFf1pP+7RWRWhFp1vPul50P/Nmf4QzmKqFhYGBgsPyJeJx88NOfrvYwslJNm0krc2thDDC3JOgsIvI2EXlKRJ4aHh5eksEZGBgYGOTPioiAV0p9Dq3YPbt37y4qM+VyleYGBgYGq4FqaiaDzK2Z3EZp9aUNDAwMDKpENYXJfcBtulfXZcBkpewlBgYGBgaVpWLTXCJyD3AlUC8iA2hVyKwASqnPoNVLvgGtNnMY+MNKjcXAwMDAoLJU0pvr1kXWK+AdlerfwMDAwGDpMCLgDQwMDAxKxhAmBgYGBgYlYwgTAwMDA4OSMYSJgYGBgUHJGMLEwMDAwKBkDGFiYGBgYFAyhjAxMDAwMCgZQ5gYGBgYGJSMIUwMDAwMDErGECYGBgYGBiVjCBMDAwMDg5IxhImBgYGBQckYwsTAwMDAoGTWjDAZOn0/Tz19C0olqj0UgyVmePhBTvR+qtrDMFilTAVe4OChu0gm49UeSlVZM8IkEQ8yOfkU0ehQtYdisMQMDH6d48f/jXD4RLWHYrAKGfLfy+Dg1xgZeajaQ6kqa0aYOF2dAEQivVUdh8HSEwn3ATAw8NUqj8RgNRII9gDQP/ClKo+kuqwZYeJydgAQjvRVeSQGS0kyOUMkOgCYOOX/DvF4sNpDMlhFKKUIBg9iNruZmHicQPBgtYdUNdaMMLHbN2Ay2YmEe6s9FIMlJBodBJK0tt5KIhHEP3RvtYdksIqYnvYTj0/SsfFOTCY7AwNfrvaQqsaaESYiJpzOjYZmssYI6y8PG5puxOfbwcDAl1EqWd1BGawagromUlf3UjY03cTQ0A+IxSaqPKrqsGaECYDL2UnEECZrirBuI3O5Omlru41w+DhjY49Vd1AGq4aUvcTjOZe29ttJJqOcOvWtKo+qOqwpYeJ0dRCJ9BlvpmuISKQPs9mD1bqepsbrsdnq17yh1KB8BIMHcTjasVi8eD1bqa29lIHBr67JEIQ1JUxczk6SyRmmpw334LVCONyLy9WBiGAy2WltuZXR0Ydnp78MDEohGOzB69k6+7297Tai0cE16Sa8poSJM+XRZcQbrBkikb7Z8w7Q2vpmRMwMDBpuwgalkUiECYd78Xi2zS6rr78au72Z/v61p/2uKWHi0mNNDCP82iCZjBGNDuJyds4us9sbaWy8nlOnvk08Hqre4AxWPMHgYUDh8Z7VTEwmC22tb2F8Yi/B4KHqDa4KrClhYrgHry2i0QGUSuB0dcxZ3t52O4lEkCHDTdigBIK68d2bppkAtLS8EZPJTv8acxNeU8LEcA9eW6TsIumaCYDPtxOv9wL6B76MUmrpB2awKggGD2E2e3A42uYst9nW0dR0o+4mPFml0S09a0qYgGY3MdyD1wap85xKpZNCRGhvu51w+Bhj44absEFxBII9eDznIjL/MdredhvJZIRT/m9XYWTVYc0JE5er03APXiOEI72YzR5s1vXz1jU13YDVun5NRywbFE8qjYonY4orhde7ndqaixkY+MqacRNec8LE6eww3IPXCJFwHy6n5haciclkp7X1VkZGfkEkcrIKozNYyUSjAyQSwTluwZm0td9ONDrAyMgvl3Bk1WPNCZPU/LkRZ7D6CUd65xnf02lLuQkb2YQNCiQ4G/meXTMBaKh/FXb7hjUTJLv2hMlsKnrDbrKaOesWnFuY2O1NNDZcxyn/tww3YYOC0LIDCx7POTm3mXUTHv8NwdCRpRtclaioMBGR60TkkIgcFZG/zbJ+o4j8UkT2ichzInJDJccDKfdg22zOJoPVyVm34M4Ft2trv414PMDQ6R8szcAMVgXBYA9OZwdms2vB7VpabsFksq0J21zFhImImIFPAdcD24FbRWR7xmb/AHxLKbULeBPw6UqN5+y4TJpHV9jQTFYzKffvTLfgTGp8F+H1nq9nEzbchA3yIxg4OC++JBspN2G//15isaklGFn1sFSw7UuAo0qp4wAi8g3gJuBA2jYK8Omfa4BTFRzPLE5nx4rWTD7ywwPMJJJ86KbzK9dJ32/ga78HiZnK9QEgJnjtf8KOW8rabCowdTHNRHMTvo0DPX/D+PhvWLfu5WUdh8HqIx4PEImepLn5DXlt3952G37/d/D7v83GjW+t8OiqRyWFSSvQn/Z9ALg0Y5u7gQdF5F2AG7g6W0Mi8jbgbQAbN24seWAuZwdjY4+iVDKrj/hyRinF9/efwmyissLkxKMwE4KXvxuyeEOVjWe/AS98t+zCJBzpw2x2Z3ULzqSx8TUcOfpP9A982RAmBouSSpPi8S6umQB4vedRU7ObgYGv0t5+B9qkzeqjksIkH24FvqiU+riIvBT4ioicrzKCQJRSnwM+B7B79+6S5yKcrk6SyWmmp4dwOFpKbW5JGZyIMBKcBmAqGsPnsFamo+GDULsRXvXByrSfIjoJz30LEjEwl++3RMK9uJydWd2CMzGb7bS2vInevv8mEunH6Wwv2zgMVh+pglj5THOlaG+7jRde/HNGRh+mof6qSg2tqlTytXwQSL8r2/Rl6bwV+BaAUuq3gAOor+CYgJVdD/7Z/rPpGY6eqWA985HD0HBu5dpP0bUHZoJwan9Zmw1H+hZ0C86kte33ETEZ2YQNFiUQ7MFi8WG3N+e9T0PDNdjtGxjoX72G+EoKkyeBLSLSJSI2NAP7fRnbnASuAhCRbWjCZLiCYwLA5eoCWJEJH/f3j89+rpgwSSZg5AjU53Z7LBudl2v/T/yqbE1qbsEDC7oFZ+Kwb6Ch4VpOnfoWiUS4bGMxWH2kIt/z0XpTmExWWlvfzNj4rwmFjlZwdNWjYsJEKRUH3gn8FOhB89p6UUQ+JCI36pu9B7hTRJ4F7gHuUEvgUnPWPXjlaSb7+ye4sK0Gm9nEsUoJk4k+SEwvjWbirofG86D30bI1GY0Oam7Bi3hyZdLedjvx+BRDQ4absEF2lEoSDB7Cs0Dkey5aW96EyWSjf+ArFRhZ9amo9Vkp9WOl1DlKqc1KqY/qy+5SSt2nfz6glHq5UmqHUmqnUurBSo4nxVn34N6l6K5sxBJJnh+c5CUddXTVuyunmQwf1v7XL4EwAW2q6+ReiE+Xpbn0uu+FUFPzErye8+gf+JLhJmyQlUikj2QyUpC9JIXNtp6mxtcwNPQ94vFABUZXXVaWK1MZ0dyDV5Zmcvh0gGgsyc72WrobPRwdrpAwGdGL+jQswTQXaMIkHoWBJ8vSXCqGyFnANBdobsJt7bcRCh1hfGJvWcZisLoI6Mb3YjQTgLa220gkwpzyf6ecw1oWrFlh4tJT0a+k7MH7+ycA2NVex+ZGD/1jYaKxCmQkHT4M7kZw1pW/7Wx0vEyLNzlRnqkuLVuwG5utcF+OpsbXYrWuY2ANll01WJxgsAcRM253cS9aPt8F1NRcpAfJrpxnTz6sWWFy1j34dLWHkjf7T06wzm2jfZ2T7kYPSQUnRiqQU2rk0NLYS1I4a6F5B5x4pCzNpeq+F2IgTaG5Cd/C8MhDRCIDZRmPweohGDyIy7UJs9ledBvtbbcTiZxkdLR8TifLgTUrTM66B/dWdyAFsL9/gh1tNYgI3Q0eoAIeXUppmslSeHKl07VHm+aaKd2TKhzuLdhekk5r6+8jIoabsME8goGeoqe4UjQ0XIvd1rTqsgmvWWGS8vRZKTm6AtEYR4eD7GzXpp42NbgRqYAwCZ6G6cml1UxAEybJGPSXZqtIZQsu1F6SjsPRnOYmHClpPAarh1hskuj0qQXTzufDrJvw2KOEQsfKNLrqs2aFicPRvKKyBz8/MIlSsHNjLQAOq5n2Olf5jfDDKeP7EguT9svAZCl5qktzC44vmuBxMdrabiMenzTchA1mCc4a30u/N1pb34SIjYFV5Ca8ZoWJiAmHY+OKqWuyTze+72irmV3W3egpf6zJyBK7Baewe6B1d8nC5Gzd9+I1E4Damt14PNuNbMIGs6QKYhXjFpyJzVZPU9Or8a8iN+E1K0xAi0NYKRUX9/dP0FXvptZlm13W3ejh+EiIRLKMD7vhQ2D3gXdD+drMl649cGqflq+rSFLns1TNJJVNOBg6xMTE4yW1ZbA6CAQPYrWuw2ZrLEt77W23kUiEVo2b8NoWJs4OIpGTy95FTynF/v4JdrbXzlne3eBhJp6kf6yM6T9GDmnG90pmCs5F1+WgktD326KbmM0WXIRbcCZNTa/Faq2jfw0UNjJYnGBQM74X4yWYDZ/vQmp8uxgY+Mqyfwblw5oWJpp7cHTZuwf7J6MMB6bnCZPNjRXw6BpeogSP2Wi7BMz2kqa6IpHeot2CMzGbHbS03MLw8M+IRDJzlBqsJZLJOKHQ4bJMcaXT1nYbkUjfqnATXtPCJOUevNztJqlgxR2ZmklKmJTLCB+dhODQ0rsFp7A6YOOlJQmTcLivoASPi9GmuwkPDn6tbG0arDzCkRMkkzMluwVn0th4HTZb46oo67umhUnKPXi52032909gM5vY1uyds7zGaaXBay+fZpLKyVUtzQQ0u8np5yE8VvCuyWScaHRg0eqKheBwtFBf/yoGT32TRCJatnYNVhbBgGZ8L9UtOBOTyUZr65sZHXuEUOh4Wdteata0MHE4NiBiWxGayfYWH3bL/Apt3Q0ejpRNmGiuj1XTTAA692j/i8gifNYtuHyaCaSyCU9w+nRmBYW5JCbLk6jSoHxMRWNEZkpPORQMHULEitu9ed46pRSJUKzotltbb0XEysDgynYTXtPCRMSM07lxWceaxBNJnh+YnGcvSZFyDy6L++rIIc1mUddZelvF0noRWN1FTXVF9PNYTs0EoLb2YjyerQtmE54+Pon/Y08Qfq7i5XgMCuC2/3mC9937fMntBIM9uN2bMZls89ZN/vA4/o89zoy/uNRGdls9TY2vxu9f2W7Ca1qYALhcHcs6Cv7w6SCRWGJBYRKcjnN6qgxvxcOHYX03mKpYo9ps1RI/FpH0MZUFutyaieYmfDvB4EEmJrJnNp4+OQXAxH3HSIaLf0s1KB/RWILnByd5qq/wKdNMgoGDWe0l031TBH9zCuKK8e8eRhXppt/efjuJRBC//3ulDrVqGMLE2Ul4GWcPThnfcwmTLeX06Bo5tHRp5xei63JtLIGhgnYLh3sxm13YbA1lH1JT041YLLU58ynF/CHEYSYZjjPxoxNl79+gcI6eCZJIKvrHIgSixQv4mZkxpmdOz7OXqHiS8e8exuyzU3tzN7GBoCZYisDnuxCfbycDgyvXTXjNCxOns0NzD545U+2hZOXZ/gnqXFY61ruyrp/16DpTonoci8B439JHvmejS7ebFKidlJIteDHMZgetLbcwMvIzotH5D4yYP4S9qwbvnjbCT58memQ8SysGS8kB/9Ts54NDxd8fuSLfAw/3Ez8TofbmbtwXb8CxdR1TP+0lPlaco0Z72+2EwycYGytf1dGlZM0Lk1R22eVadXF//wQ72mtzPiAbvHa8Dkvp7sGjRwG1PDSTDReCo6bguvDhcG/Jke8L0dr6+yilGMhwE1axJPGRMNZmN76r2rHUOxm/9yjJMhh+DYqnxz+FSc5+LpZgloJYsdMhpn7Zj3NnA85z1yEi1L5uM4gwfu+RomyYmptww4oNkl3zwsQ5m4p++dlNgtNxDp8JsKMt+xQXaPP53Y2e0qe5Ugkel4NmYjJDx+8U5NF11i24vPaSdJzOVhoaXsWpDDfh2OkQJMG6wY1YzdTd3E1iLMrUz5ffNbWW6PFPcUFbLTVOa0nCJBDswWZrwGZbD4BKKsa/ewST3UztazbNbmepdVBzXSfTRyYI7yt8pmPWTXj0YcLhlTdVuuaFicPRrLkHL0PNJDNTcC66GzwcPVNikayRw1q1w/XdpbVTLrr2wHivNvWWB+XKFrwY7W23EYuNc/r0/bPLYroXj7XZDYB9Uy3uSzYQfHSQmYGV652zklFK0eMPsL3Zy7ZmLwf8pUxzzTW+h/b6mTkZoOY1mzB75np3uS9rxrbRy+QPj5MIzhTcV2uL7iY8sPJq6ax5YaK5B7cvS81k1vi+gGYCmt1kJDjNZCleRMOHoLZDi0JfDnQVFm8ymy24zJ5cmdTWXorHfS79admEY/4QYjVhWe+c3a7m+i5MHhvj3z2CSqxMg+pKxj8ZZTISY1uzj23NPg4NTRWVEDWZnCEUOjprL4lPRJl8oBf7OXW4ds1P+Cgmoe4NW0hOJ5j4YeFBiHZ7A02NN3DK/x3i8TJnBK8wa16YgGY3WY6ayf7+cTrWu6hzz/dtT+dsWpUS3oJHqpiTKxuN28BVn7cRPhUrVEqFxXwQEdrabiMYPMDE5FMAzPhD2hSX6axdy+S0UHfTZmL+EIFHjbxeS01qWislTKKxJL2jhWvvofBxlIrh8WxDKcXEvUdBKepe153TjmltcuN7RTuR/cNEDhbultzWdpvmJjx0b8H7VhNDmKC9zWruwcurbkW2TMHZ6C7VPTgR1wzwy0mYiGguwice0UoJL0Ik3Fcxt+BMNmy4CYulZrbWSWwoNDvFlY7z/Hqc569n6ud9xEaMio1LScp7a+sGL9ubfdqyIqa6zqZR2Urk2WGih8bxXduJZd3CGtM0ozUAACAASURBVLz3ynYsjS4m7j1KcjpeUJ81NTvx+Xbo19fK0WoNYYIWa6K5By+f7MFDk1FOT83PFJyNtjoXNoupeGEy0QeJmeVhfE+naw8ETsHo4qVNw2XMFrwYZrOTlpY3Mjz8U0LDfahIPKswAai9sRuxmLTprnLWnTFYkAP+KdrXOfE6rHQ3ejCbpCgjfDDYg8lkw047E/cfw9ruxfOylkX3E4uJujdsITE1zdRPC59Cb2u7jXD4OGNjjxW8b7UwhAlnq/Itp0j4/f1anEI+wsRsEjbVu4sXJtUq1bsYXVdo/3sXT62SijFZKtpa36K5CZ/Q8inlEiZmn43aGzYxc2KS8FPL52VltdPjn2LbBk0jcVjNbG5wFylMDuJ2byHw45MkIwnWvWHLnOnMhbB3+HBf1kzwt6eY7ius76bG67HZ6nMGyS5HDGHC2ap8yylH177+CaxmYZuuoi9Gd6On+FiTkZRb8Jbi9q8U6zaBt2XRPF3JZJxIpL/i9pJ0nM42Guqv4nToXpKmmZzCBMB1cRP2TTVM/Pg4ianCPXwMCiMyk6B3JDTn3tnW7CtKmASCB3EmNhF+5gzeK9uwbsh9nrNRc10nZp9d00zj+U9ZmUx2Wltu1d2EewscdXUwhAnp7sHLSDM5OcH2Zh8Oa355srobPQyMR4jGigiUGz4M3mYtUHA5IaJNdZ14FJK5b8Tp6VMVyRa8GG3ttxNnktDmZzDZLTm3ExFqb96CiismfnB0CUe4Njl0OkBSMU+YnJqMMhHOX5hPTw8Ti40iB+uwNDjxvWJjwWMx2S3Uvr6b+JkwgYf7C9q3tfXNiJgZGFwZbsKGMCHdPbi32kMBIJFUPD+YO1NwNrobPSgFx4rRTlKlepcjXXsgPALDPTk3Sb25OSscY5JJXe1l2CPtjLc+uKjzhrXeie/qjUReHCXywsgSjXBtktJAtmcIE21d/kb4VBoV2+lm6m7egliLe1w6t67DuaOBqV/2awGueWK3N9LYeD2nTn2beLzEOLIlwBAmOlo9+OWhmRw5EyA8k1g0WDGdoj26lKpuqd7F6Lpc+7+Ai/BstuAKRr9nQ8WS1J54JRHbcSYnn150e+/lrVib3Yz/4BjJSGEePgb50+Ofwm0z01Z3Nu5n2wbv7Lp8mRjYD0DduRdj7ypNa6997SZMdnPBjhjtbVo24aEV4CZsCBMdp6uTcHh5uAfvP6mX6V0kWDGdrno3JoFjhQqTqVMwE1i+mkntRq2+ygJ2k0i4F5PJic02P4isksSGQvj8L8Ms3rzyKYlZ8/BJBmeY/MnKS5exUujxT7G12YcpzVDe4LWz3m3LW5ioRJLxo09jmV7P+usuKHlMZo+NmtdsYuZkgNDj/rz38/l24vVeMCdIdrlSUWEiIteJyCEROSoif5tjmzeKyAEReVFEvl7J8SyEy9lBMhlhZhlkD97fP0GN00pXff7GPrvFzMZ1rsKrLo4sU0+udLr2QO+vIZndHhSO9OFyLY1bcDoxfwhTwk5z/RsYHn6A6PTiKfNtbV48l7cSemKI6eMTSzDKtYVSioP+wLwS1yKaM0vPUH7CJPCrASLWE3h92zA5ctvDCsG1qxH7llomf9JLfCK/+kOpWjrh8DHGxpe3m3DFhImImIFPAdcD24FbRWR7xjZbgL8DXq6UOg/4i0qNZzFS1fmWg+fEYpmCc9Hd6C18mitV9325xZik03UFTE/C0HNZV0civUtuLwE9jYrdTPvm21EqyeBgfu9Cvqs7MK9zMP69o6hiHCYMcjIwHiEwHc/qBbmt2cvh00Hii6S3iZ0JM/HLo8y4/dRsKF0rSSEi1L1+CyjFxPeP5q1pNDXdgNW6noFlnk24kprJJcBRpdRxpdQM8A3gpoxt7gQ+pZQaB1BKVU4tmByA33wyp1dQyhOo2naT0HScw6cDBRnfU3Q3eugdDS16s8xh5JDmxeVZ2imiguj8He1/lqkuzS14YMk9uUATJtYNblyujdTXX8Xg4D0kEou/cZpsWmbh+EiEqYcK8/BZLSST05w58wDJZHmrUh5IS6OSybZmHzPxJMdHchuzVVIx/r0jxGqGQJLzCmKVimWdA981nUQPjhHJs8SzyWSntfVWRkZ+QSRysqzjKSeLChMRea2IFCN0WoH0O2VAX5bOOcA5IvKYiOwVketyjOFtIvKUiDw1PFxkje3998CD/wDfeDNE5k8vOBwtiFirrpk8PzhJUsHO9sINft2NHmIJRd9YOP+dhg9rWskSTxEVhHeDNsYswkRzC44taYwJaA+d9DQqra23EouNMTGxN6/9Hd11uF7SROCRfmZOrayEfqUSjZ7i6Wdu5fkX3sGpU98sa9s9/ilEtDQqmZz16Mo91RV6coiZ3ilML9PS35RbmAB4Xt6Ctc3DxH3HSYTyE6Ztupvw8MhDZR9PuchHSNwCHBGRfxGR+UWQS8MCbAGuBG4FPi8i817JlVKfU0rtVkrtbmgoMvfSnv8D1/8rHP0ZfO5KGHphzurlkj04lSm4EON7iqI8upZLqd7F6NoDfb+FxNybLxxemmzBmSTGo6jpxKwwqa3ZDQiTU9mn4rJR++ouTC6rnll4eRtXy8XY2GM88eRNhELHsNnqOTP807K23+OfonO9G5dtvp1jc4MHq1nmVGBMJzE5zeSPT2DfXMNM/SlMJkdFPAS1zMLnkIzEmfxRfpmF7fYmXnrZQ2xs/8Oyj6dcLCpMlFJvAXYBx4AvishvdU1hvuifyyDQnva9TV+WzgBwn1IqppQ6ARxGEy7lRwQufRvc8WOIR+ELV8Ozc9+KXM5OIlWONXm2f4KN61ys99gL3ndzg/Zgy1uYhMcgNLy87SUpui6HWAgGn5mzeKmyBWcSG5pbw8Ri8eB2dzM1tT/vNkwuK7U3biY2GCT42OrOLKxUkt7e/2bf/juw2dZz8e57aW7+PSYmHicWK1+J44ND843vKWwWE92N3qwJH5VSjH//KCQVdTdvIRjsweM5F830W35szW68V7QRfuYM0cP5/X6ns60iYykXeU1fKaWmgO+g2T2agdcDz4jIuxbY7Ulgi4h0iYgNeBNwX8Y230fTShCRerRpr8KLABTCxkvh7Y9A60vg3rfBj94DcS0q1unqqLp7cL6ZgrPhdVjZ4HPk7x48ohvfl7MnV4rOVLzJ3KmuSKSvOm7B/hAIc9Jr+Hw7mZp6tqDrx3lBPY5t65j6WR/x0dWZWTgWm+K55/+UY8f/L02NN7D7Jd/F7d5EY8M1KJUo29RNcDpO32h4NidXNrY1e7NOc0VeGCHaM4bvVZpzRGZBrErge+VGvcTzkVVR4jkfm8mNInIv8DBgBS5RSl0P7ADek2s/pVQceCfwU6AH+JZS6kUR+ZCI3Khv9lNgVEQOAL8E/lopNVrKD8oLTyPc9gN42bvgyS/AF2+AyUE9e3D13INPT0XxT0bZUaQwgQJzdM2W6l0B01yudbDhgnl14cPh3qq4Bc/4Q1jWOzHZzr651vh2EIuNF2Qk1WqHd4NJGL83fw+flUIweIgnn3odo6MPc86W93Peef+BxaIJYK/3Auz2ZoaHHyxLX4eGchvfU2xv9nEmMM1o8KyjRDIcY+IHx7C2evC8vJXpaT/x+GRF7CXpiNVE3c1bSIxPM/Xg8giYLoV8NJM3AP+ulLpAKfWvKY8rpVQYeOtCOyqlfqyUOkcptVkp9VF92V1Kqfv0z0op9VdKqe16+98o8ffkj9kC13wEfu9LcKYHPrsH5+QkcHYefqnZpwcrFquZgCZMjp0J5vdQGjkMFocWGLgS6LoC+p+A2Nn660udLThFzD+/honPtxOAqalnC2rLUmOn5vpOpo9OEH6m+nFO5WJo6Ac8+dTNJBIRLtr1Ndrb75gj9EWExoZrGRt7tCxVBVOlebe1LKSZzE+rMvHjEyTDMS1lilkIBrWXLG+FhQmAfVMN7ks3EHxskJn+lV3iOR9hcjfwROqLiDhFpBNAKbV8XQvy5bzXwZ2/BNd6XPffBUAkXJ3o5GcHtEzB5y1wMyzG5kYPoZkE/sno4hsPH9IyBZsqMy9cdjovh8Q0DGiX42y24CWOMUlG4yTGovOEidu9BZPJWbAwAXBf0oyt08fED4+TCKzszMLJ5AyHDt/Niwf+Cp/vQi65+D5qa3dn3bah8TqSyRlGRx8uud8e/xQ+h4WWmtyFqzI9uqJHJwg/dRrv5W3YWjUHllROLo9naaZ/a67vwuRd+SWe8xEm3wbSf2FCX7Z6aDgH7vwF9s2vQZKK8DP/BdHJJR/G/pMTbCsgU3A2uhsK8OgaObQyjO8pOl4GYp61m0xP+1EqNluPZqnINL6nMJks+LznM1mEMBGTUHfzFtRMgon7Fy8GtlyJRv0888ybGRj4Chvb38qunV/Gbs/tgVlbcxFW6/qyeHX1+KfY1uxbcMpzndtGk89Oj3+K5EyC8XuPYFnvwHf1We08EOzB4WjHYlnMx6g8mBwW6m7qJjYUIvDIwJL0WQnyESYWPegQAP3zwkXJVyJ2D6bf/SJO8zrNQ+hzr4DTB5as+0RS8dzARFEuwenk7R48E4aJ/pVhfE/h8EHLrtmkj6mYoKXWTGL+lDDxzFvnq9lBMPgiyWTh2oW10YXvlRuJPDdC5EDlTYflZmz8tzzx5E0EQ4c5//xPsmXL+zCZrAvuI2KmoeFVjI4+nFfAZy6SScWhoUBe9X+2Nfs44J9i6qGTJEaj1N68BUl7gQsGD+KtsPE9E+d563FeUM/UQyeJDRcQJ7aMyEeYDKcZzBGRm4DVmUNbBOe6nURaumEmCF+4Cp7/zpJ0ffRMkNBMoiR7CUC9x0aN07q4EX70CKBWhvE9na7LYfApmA7OZitYcs3EH0KcFsw189+pfL6dJJMzBIMHi2rbe0UbliYXEz84SjK6MjILK6Xo6/ss+/bdhtVay8W7v0dT4w1579/YcC2JRJix8V8XPYa+sTDhmUROt+B0tm7wYToTJvjoAO6LN+DYfPaeSyQihMO9FTe+Z6P2xs2Ixcz491Zmied8hMmfAO8TkZMi0g+8F3h7ZYdVPVyuTiKJEdTbfgXNO+C7b4WfvHfWfbhSPKsHKxaSdj4bIqJ5dC2mmQyvILfgdLr2QDIOJ/cSjmjZgu22piUdQswfwtbszjqdUuPbAVDUVBek1w6fYfKB3lKGuSTE4wGef+EdHD32LzQ2XsfFu7+H291dUBt1dZdhsXgZPlP8VFfPAmlUMtnW5OE9SQdJh4Wa6zvnrAuGDgNJPN6l1UwAzF4bta/uYubEFKEnF08autzIJ2jxmFLqMrRkjduUUi9TSq3acnFOZweJRJgZuxluvx8uewc8/hn40mtgKv/U0YWyr38Cn8NC1/rCyoJmo7vBs3isycghzf6wbnPJ/S0p7ZeByQq9jxAJL3224Mw0KpnY7c3YbA0FBS/Oa2OjD8/LWgjt9TPdu/S2u3wJBg/z5FOvZ2Tk52zpfh/nn/efWCzzp/4Ww2SyUb/+KoZHHio6V1ePfwqTwDlNi2smF56Kci5mju5Yh8k1dxouGNCN7+6lFyYArt1N2DfXMPnjEyQmi5/2qwZ5BS2KyKuBPwP+SkTuEpG7Kjus6jFbDz7cC2YrXPeP8Lv/q6Vf+ayeCr0CpDIFp9dgKJbuRg+joRnGQwtoU8MHYV0XWFaY+cvmgraL4cQjhKvgFhwfjaBiyZzCRETw+XYU5dGVju+aTsy1hdcOXyqGTt/Pk0/dTDweYNfOr7Jx41tLEuoNjdcQj08wMfHE4htnocc/xaYGz6LOK/GRCNa9p3lU4vzGPD9QMBg8iNnsxulsz7J35UllFlYJxfgPjq2ouKN8ghY/g5af612AAL8HLL1j/xKRysUzJ3vw+W+AO3+hZdf90o1a9uEynuTwTPGZgrMxa4RfyG6SSvC4Eunag/I/SyRysnrG9w25Ncga307C4RPEYsVrFSa7mbrXdxMfjjD1y+WTWTiZjHH48Id58cW/wOvdziUX30dd3SUlt7t+3R5MJidnigxg7PEvbnxXSssILGbhR02WrLVNArNpVKpXN9BS76TmVRuJHhgl8sLKccTI54i9TCl1GzCulPog8FK0tCerErtdzx6cmaOrcasmULbeoGUf/vbtMF2eIKMXBqdIJFXZhcmR0zmESSIGY8dWRoLHbHTtIWqjOm7B/hCYwNqUW5j4fBcCMFVA0sdsOM5dh2tXI4GH+2fdkavJ9PQZntn3+/QPfJH2tju4aNfXsNvLY68ym52sX38Fw8MPolRhmthkOMbgRGRR43v4qdNMH5+k5oYuWtp89PgDc978lVJ6GpWlN75n4vmdNqwtbibuO0oyXN40/ZUiH2GSin4Li0gLEEPLz7UqMZksOJ1tRLJFwTt88MavwKs+BD33w+dfeTYlSQns79cSvZWSRiWd1lonTqs5txF+7IRmxF6pmknbbsIerb73kmsmQyEs9S7EmvvW0YSJlGQ3SVHzmk2YHIXXDi834+NP8MSTryUQOMB55/0H55zz/kXdfgulseFaZmbOMDm1r6D9DuaRRiUxNcPEj05g6/LhvngD25p9jIVmGA6ctUtEowMkEsGK5+TKBzHrmYVDMSZ+vDJKPOcjTO7X08L/K/AM0AtUrbzuUuB0ds7XTFKIwMvfreX2ioxr8SgvfK+k/vb3T9BW56S+iEzB2TCZhE0N7tzTXLOleleoZmKxE2nZBFTHLTiXvSSFxeLF7e4u2qMrHbPbSu1rNzPTHyD421Mlt1coSilOnvwf9u1/CxaLl4t3f48NTa+tSF/19a9AxFqwV1fKk2v7AsJk4v5jqHhCS5liklnBk56OPhX5vhRpVPLB1urBc3kb4adOEz26/Es8LyhM9KJYDymlJpRS30WzlWxVSq1aAzxoVRcjkUWyB3ft0bIPN50H3/lDeOB982pt5Muz/ZNlm+JKkcrRlZWVlOAxB+H1jZgSCnts6VLBJMMxEhPTiwoTYNYIXw4DqnNHA45z65j6aS/x8TzS5JSJeDzICy/+OUeO/iP19Vdx8e578Xgqd81YLF7WrXsZZ4YfLOi49fgDrHPbaPRmfxmLvDhC5PkRfFd1YG1wAcxmFk7P0RUIHgRkydKo5IPvqo2Y1zsYv/fIsi/xvKAwUdrk5afSvk8rpZavr2KZcLo6NffgmUWqOvpa4I4fwSVvg72f0ozzgdMF9XUmEGVwIlJ+YdLgYXAiQmg6S+DbyGHwtYJ9adJFVIKI04IrkkD6KuNdl42U3cKWpzCJxcaIRktPjzGbWRiWLLNwKHSUJ5+6mTNnHqB783u54PxPL0l6kYaGa4lG+2e1hHzoGZpiW7M3qzdZMhpn/AfHsG5w491zttBrjctKa61zTjr6YPAgTmcHZrOrtB9RRrQSz1tIjEaZ+vnyLdkL+U1zPSQib5ClzvFdRVL1xPOqumixwQ3/Cjd/Hk7tg89eDiNH8u5rfxkyBWcjZYQ/PpzFcDt8aEVrJQBhNY5zWrKW8s0k+NhjjH+j9PKwMwukUcnkbPBi6XYTAEudA9+1nUwfHifybJGlq/Nk6Imv8cRvXkMsNs6uXV+mo+Nt5Y/liU5qwcAZL18N9VcBprxzdcUTSS2NSo4aJpMP9JIMzFD3u1sQ89zHXWZtk2CwZ9lMcaXj2FyLa3cTgUcHmBlcviWe8xEmb0dL7DgtIlMiEhCR3EWUVwGpqn2RQurBX/hGuPMhrXrhvq/kvdv+/gksJuH81sJrvi/EWffgDI+zZFITdist8j0NpRJEIgO47C15CZOR//oUpz/2MZIzpWUxiPlDmNxWTN7FDc9u97mYTI6S403S8by0BUu9k1CF09T3Hf4UBGJsm3gX6+peWplOfnaXFgz8/NycsTZbPbW1FzOcpzDpHQ0xHU9mNb6rhCK87wyuXY3Y2rLXhD8+EiIaSxCPB4lETi4L43s2am/owlLnWNYF1PKJgPcqpUxKKZtSyqd/Lz5H+gpAcw+2FF4Pvum82YC6fHl2YIKtzd6SMgVno2O9G7NJ5nt0TQ1q5W9XsGYSjfpRagZn7QUwehSmchumE8EQkeefR01PE9lfmpaQMr7n85ZuMlnwes8vqzARk2DfUsvMicmKBTIm4zOEas/geNHE+Ef/m/jYWPk76f01PP1F7XOWe6Wx4RpCoSOEQosXXZ2tYZJFmMROBVHTCRxb12Xdd1uzj0RSceR0kGBIsyN6vMtPMwGtxHPTX+3GdWHuDMzVJp+gxT3Z/pZicNVCcw9uL0wzSdG1B/zPap5ei5BMKp6rgPEdtHrXHetd84XJrCfXytVMUgGlrpYrtAV6FuGs2z7zNMQ1u1F47+NF96kSitjpxT250qnx7SAQeLHoFCHZcGyuRcWSzAxUppDS6AsPoFyK9W1XkwiFOP2xfypvB7Eo3PfnUNcJO26FvsfmOa40NFwDkFcFxh7/FBaTsLlx/nmJHtOmkO2bsmv9Wzd4Z9sIBrTEnMtxmiuFmJe3pSGfaa6/Tvt7P3A/WsGsVY3T2VG4ZgJaVluVhL7fLLrpseEggel4yWnnc9HdkCXh42yCx+WpzudDKvW8s/VKcNYtqAmG9j6OWK3YzzmH0OPFC5P4SBjiqiBh4vPtIJmcLjqDcDZsXTUgMF0hV9GRIz8EoOWad1H/9rczdf/9BB/JX9NelF/9sxYw+9pPwJZrtOzcp+ZqjA5HCz7fDs4MP7Bocz3+KbobPdgt8zX76WMTWJpcmD3ZUwZ1rHfjtJo54J8iGOzBYvFht6/aELqKk88012vT/l4FnA8s/tq9wnE6O4hEegv3nGm7WCuFu8Dbcop9eqbgXSVmCs5Fd6OHvtEwsfTqbSOHwLkO3PUV6XMpiET6MJkc2B0boPN3FhQm4ccfx7ljB54r9hB57jmS4eJqRSxUwyQXxZbxXQiz24q12c308co4VU5M78c6asPTup31b7sTW/dm/B+4m0SwDBH4Q8/DY5+AnW+BTVdqlTMBeuefv4aGawkEnicaXTi2JlUQKxMVTzLTOzUnvXwmZpNw7gbNCB8IHsTj2bqkSUNXG8UkoBkAlq8uWCZcs+7BBZZusdhh42V52U2e7Z/A67Cwqb7wTKv50N3oIZ5U9I2mPQiGD6/oKS6AcKQXl7NDy5/UdQVMnoTx3nnbJSYniR44gOuyy3BdehnEYoSfKSy6OkXMHwKzYG1w5r2Pw9GCzVZfVmECYN9cy3TfVNnjDhLTYSLrRvFMdwFgstlo/vCHiQ8NMfyJT5TYeBzuexe41sE1H9aWeRqg8bycdhNgQa+usdAMp6ems6ZRmekPoGJJ7AsIE9DsJgf9E4RCh5at8X2lkI/N5JMi8p/6338Bj6JFwq9qzroH9xa+c9ceOPMihBYWRPv7tcqK5cgUnI2sVRdHVoFbcLjvbOR76u02ywMp/OSToBTuyy7FddEusFoJP763qD5n/CGsjS7Ekv/7VyqDcDki4dOxb66FhGK6r7xOlSPP3YdywLqGy2eXuXbtou7Nb2b8q18tzYHh8c9orvPX/4smUFJ0XQ4n90J8brp1l6sLt/ucBe0mC9UwmT42AQL2roV9hbY3e7GbhkgkwsvaXrISyOfOeAp4Wv/7LfBepdRbKjqqZYBTz/mUNUfXYnTq/gm9CxiGZxIcHAqwo728LsHpbM6sBx8ahfDoitZMNLfgtGzBDeeCuzGrMAk9/gTicOC88EJMLhfOHRcSery4FOf5pFHJhs+3g3D4GLFY+R789k4fmGD6WHmnukZOaDaKpoveNGd5w1/+JZYNG/C///2oYtyrx07ALz4C51wP571+7rquPRCPwsBT83ZrbLiWiYknmc4xO7CQMIkem8Ta4plXrySTbc0+2r2DAIZmUiL5CJPvAF9VSn1JKfU1YK+ILJ8Q0QrhcLTq7sG9he/csgts3gWnul44NalnCq4rfpCL4LZbaKlxnBUmKU+ulZrgEYhGhzS34FQdExHtgXTi0XllAcJ79+K66CLEphlg3ZdcSvSFF0gECvOESgRnSAZmFkw7n4ualN0kUFoG4XRMDgu2Nq/29l1GJmPPYxt24GzomrPc7HGz4QN3MX3kKCOf/3xhjSoFP/wLMFng1R/Xzlc6HS8HMWW9VxoargUUI8M/z9p0jz9Ag9c+L6ddcibBzMmpRae4ALY2+2j3nEJhwu1e2Rp7tckrAh5Inyh2AtnP7irCZLLgcLTNrWuSL2YLdLxsQWEyW6a3Am7B6Wxu9JxN+DisexWt1ASPQEQX7qnAUkCbKgkOzck8EB8dZfrIEVyXXTa7zHXZpZBMEn5y/lvwQqTSqBSnmejp6CfLEwmfwr6plpmBAMls6XKKIB4NElk/gTeeveSu98or8b361Yx85rNMHy2g0Oqz98Dxh+FVd0NN6/z1zlrYcGHWe8Xj2YrTsTFnAGMu4/tM3xQkFPbNi2v9HruFc9YPEYg1YzY7Ft3eIDf5CBOHUmp20l3/vOo1E9AKZYWLiTUB7QG3QEDdvv4JWmudNORITlcutjR6OXYmRDKpNOO71QW+tor2WUlS7tpzKix26dOKJ351drsntOks92WXzi5z7tyJ2O2EC3QRPuvJVbgwsVi8uFyby6qZANqDMgnTveWZPhve9x2wwbrmK3Nu0/S+v8PscuF//12oZB5Bk8Ez8MDfaaWWX/JHubfr2gMDT8LMXE87EaGh8VrGxn87b5owlkhy9Ewwq/F9+vgkmESbDsyDNs8g/YEsgs6gIPIRJiERuSj1RUReAizfmP4y4nR2Lp49OBezD7jsdpP9JycqrpWAZoSPxBIMTkR04/sWMFWvilypRMK9mltwelGmui6oaZ9jowrtfRyT241j+/bZZSabDedFuwqON4n5Q5i8tpzxCotR49vB5OT+siZotHX4wCxlm+oa6XsQktC065ac21jWr6fpfX9HZN8+xu+5Z/FGf/JeiIXhxk8ufM11XQHJGPTPd45obLgWpWKMjv5yzvJjw0FmEsmsp3VhFwAAIABJREFUaeenj01ga/dislsWHWIsNonbMsLB0SbCM+XR8tYq+TxV/gL4tog8KiK/Br4JvLOyw1oeuJwdJBKhwt2DAZouAEdtVvV9ODBdkUzB2ZhTwncll+rV0eq+b5xbVjXdbqK/MYf37sV18cWIZe4DxX3pZUwfPEh8PP9QqWKN7yl8vp3EYqNEo4NFt5GJyWbGttFbNiP8VPIA9mEX9rqWBbfz3Xgj7pe/nOGP/xsxvz/3hod+Ai9+D/b8zeLTqhsv02wqWe4Vn28HdlvTvADGXMb35HScmYFAzqj3TIJBzY54MtDKoaHKZBVYK+QTtPgksBX4U+BPgG1KqacrPbDlwGzCx2LsJiZTzoC6WXtJhYIV00kJk75TZ2BqYEXbS0CLfp9jL0nReTlExuDMi8SGhpjp69NsJBmkpr3CeXp1qXiS2JlwXmnnc+Gr0TIIl6PyYjqOzbXETgVLLusaC4wQrQ/gY/EXDRFhwwfvRinF0Ac/lF3bik7Bj94Djdu1QnKLYfdA60uyavEiJhoarmF09BESibPTYD3+ADaLiU31c8/L9IkpSJKX8R3OFsQaCLTOqW1iUDj5xJm8A3ArpV5QSr0AeETkzyo/tOqTmpcv3m6SPaBuf/8EZpNwfkvl3IJTrHPbWOe2ERg4oC1YwZpJyi14jr0kRdfZeJOUTcSdZnxP4TjvPEwuF+En8pvqig1HIFFYGpVMPO5zMZnsJdeEz8S+uRYUTJ8oTTs5ve87YIF1rVfntb2trY2Gd/85wYcfJvCTn8zf4KEPabbCGz+plWjIh649cOoZLTV9Bg0N15BMRhkdPStsevxTnNPkwZKRVn762ARYBHtHfrVXgsGDWK11xFk3Jx29QeHkM811p1JqdmJWKTUO3Fm5IS0fHI42RCyzHkQFM2s3maud7O+f4NwmL07b0lQJ7G7woIZXfoLHlFtw1rrvNW2wbjOceJTQ3scx19ZiP2e+FiZWK86LdxPKM+ljzK/5npQiTEwmK17veWWrbZLC1u5FrKaSp7rGBn8OcWja9bt577PuD/4AxwUXMPSRj86dMjy5F578Alz6J9C2O/9BdO3Rc9r9dt6q2tpLsFhq53h19fin2Jqlhsn0sQnsG31Inlm4A8EePJ5tbN3gM4RJieQjTMzphbFExAwUZ4lcYWjuwa3FJXyErAF1yaTi2YGJJZniSrG50YN76hjKZIF1m5as33KTEuo56753XY7qfYzQ3r24LrkEyWH0dV96GTPHjxM7vXhdkJg/BBbBUl+aA6PPt5NA4IWyZhAWiwlbp282O26xTHEIx4gXqzf/fG1iNtP8kQ+TmJrizD//i7YwPq1lBK5ph1f+Q2GDaLsEzPas08Imk4WGhqsZHnmIZHKGM4EoI8GZ+faScIyYP5T3FFcyGScUOozXs01LqzIU0LweDYoiH2HyAPBNEblKRK4C7gGy6LbzEZHrROSQiBwVkb9dYLs3iIgSkQJeZZYGl6uzuCh40A3Dl88JqDs+EiIQjS+J8T1Fd6OHtkQ/idouMC9e2Gm5khLqWTUTgK49xMZCxP3+rPaSFLN2kycWt5vE/CGsTe6S03/7fBdqGYT1uhnlwr65lvjpMIlAcYW/psdPMd0QxmfavvjGGTjOPZf1f/xWJr//fYKPPQaPflzzGHzNv2t2kEKwOqD9kqxJH0Hz6kokgoyP/3bWtpHpFjx9fBIUecWXgPZykkxO4/Gcy7ZmH8HpOAPja8JRtSLkI0zeC/wCzfj+J8DzzA1izIquwXwKuB7YDtwqIvOuWBHxAu8Gis8PXkG0VPRFZA9O0bVnTkDd/lSm4CUWJt0yyJSna/GNlzGaW7B9rltwOp2XEzqtxe24L80tTOxbt2KqqSG0SJ4upVTJnlwpZiPhy2w3SWXFLTaL8Ol93wQT1HdcU9T+9X/6p9i6uhj6h/eR/OW/wYW3wJb8bC/z6LpCyywcnl+Qq67u5ZjNbs4M/3R2OirTLTh6bAKxmrJWVcxGQDe+ezzbZgXTAWOqq2jy8eZKoj3oe4FLgFcCPXm0fQlwVCl1XCk1A3wDuCnLdh8G/hmI5jnmJcXl7NTcg2Oji26bCIbovfXNWoLBFBkBdfv7x/HYLWxqqEym4Gx0r7fRIacZtGxcsj4rgeYW3DHXLTgdTyPhyQbMbjO2Tbmn88Rkwn3JxYsWy0oGYiRDsbIIE4ejDat1Xdkj4a0tHsRuLjreZMz/MMxAQwH2knRMdjvNH7ybmP8Mwwfq4NqPFdUOcNaJIktOO7PZTv36VzA8/DN6/OM01ziodc2dbZ8+NomtqybvZJzB4EFELLjdmzl3gxcRDLtJCeQ86iJyjoh8QEQOAp8ETgIopV6hlPqvPNpuBfrTvg/oy9L7uAhoV0r9aKGGRORtIvKUiDw1PDycR9flIzU/n0/VxeCvHtYDur5xdmFdlxZxrt8gz/ZPcmFbDeYKZQrORkviFBZJcji5sqN8I5G+2WzO2VBKEfKbcDeEkcTCtgnXpZcRGxhgZiB37EfK+F6KW3AKEaHGt7PsGYTFLNi7aorWTAKWozhHa7E4in+5cSWfobY7xNiLViLHF64/siAtF4HVnTPQt6HxWmKxMQJTz8yzlyQCM8T/P3vvHR7Xfd75fs70PuiNIAEQYAEp9gIWkaJIgZJFibIlW7ZVLMlF8t6bzbNOnM1mHSebOMnGTtmb6yd7Q9mxmiU5lizZVCdUKMosICl2EgQLiEIQZVCn99/948wMZoBpgAASXOHzPHlinXPmnAMQc97ze9/v+3173eiyTHGBLAs2GqpRKLQYNCqq8o0zweQzkC6En0dehdwjhLhVCPFTYNIGKEjy6+U/A3+c6VghxNNCiNVCiNWFhdd3BnI0P5+N4aOjQbYsc+7dS9gXsdSOa6jz+gM0ddmva70EQOqTpyse9xRd1+tOJkKE8Xja0CfrMYngb2kh5PBhKPRAZ3r/LWPdWoC01ioxT64JGDwmw2JZitt9mWBwcvsZtNU5BPs8BId8mQ+Ow2O7gr/Qi1W9ZOIXH2qHD/6aoi+uQlVYSNef/xARmKDIQKWBivUpPe3y825DkjSUaA4lqZdERvRmWXwHcDrOY4qznY8W4WeYGOmCyf1AF/CRJEk/ixTfx/M63QnMjvvv8si2KGbkqY17JUlqBdYBu6dbEV52D1ZmXJmEvV6c+/ahqaoi7HbjOhgncazaDJ4BWs42EgyL6x5MoqN69w9OnUPxVOPzdRMO+9OuTFyH5BqIsdifcdKlpqYGZX5+2rqJv8uF0qrNaGOeLfLkRTEF/Sby2/h4U109x+QVdEHVXRO7sBDw5h8BoPzyv8jOws3N9P/imYmdD+TvSl8zOLrH7FKpjGiM61lRdJLaklHB5PIwkk6Juiy7FZbfP4DP34PJPGI7X1tqpn3AjcM7eYq7zxMpg4kQ4rdCiK8hd79/hGyrUiRJ0v8nSVI21bojwDxJkqokSdIAXwN2x51/WAhRIISoFEJUAoeAnUKI8Vm6TjEKhRqdrjyjPNh14ADC7aboT/8rCpMJR0PDyM5ILth+7kNg6p2Cx9DXjF1byhU7OCfJZfZ643ZfAUi7MnEfakRdVoa6ZlHGSZeSJGGsq8N9qDGluGKyiu9RLJZoJ/zkprrUJUYUBtW4U10Dtk+QvFCwdOfELnz6VbjUANv+AnLmYN62DfNdd9H3r/+K78qViZ0zNsr390l39wfXk6cbYm5OR8J23+UhtFVWpCzTx8644nuUaOpsxlZlYmRTgHcJIV4SQtyLvLo4jqzwyvS5ILKH13vIBftfCyHOSpL015IkTfCv98Zg0FdklAc79jSgsFgwbdyI6fbbcX7wISIYeXBbyyFvLsZrBymz6iiyXGera1szvhzZWvxy/NTFm4gRWXDylYkIh3EfPoxh3TqkubfB1cMQSC/zNNTVEeztxd/aOvZ8gTBBm3tSg4labcFgmDv5dROFhHauFd/loXGpDp3aK+gH8lFqJ9BD4+qHd/8UZq2GtSM9zCU/+O9IOh3d2ToLj6Z0GWitCQ7Q8ZztX0oorEAdGHlZCA55CfZ7x5ficsrjGMym+JWJHExm6iYTY1z2sUKIwUj9YluWx78thJgvhKgWQvxtZNtfCCF2Jzl2y3RblUTRGypxp3EPFoEAjo8+wnz77UhqNeb6OwgNDeE+GvfjVG2mynWClbOzky1OGuEw9F1EXSJ/aS7dpMFkRBZcknS/r7mZ0PCwXAupug1CfuhIr9Ya8ekae1yg1w3hz9b5ngyLZSl2++Q6CINcKwgN+QgNZCeKdF49SyDfT452+cQu+N6fyR5cO38KipFuc1VhIcV/+l9xHz3K0Cuvjv+8CmVKTzuA012CTnctNtt7sd9h1AFgvMFEoylEoxlp1Cy16rDq1Zyb8eiaEDevF/l1RHYPdqaUB7sOHyY8PIx5ez0ApltvRdLpcOwZSXU5Stdjws22nDROq1PBcDsEPZjKF6NWSiODsm4ykroFxxG1RzHU1ckutJIyY6pLPWcOqtLSpNYqk2GjkgyLZTl+fx8+3+T+HUQfpNlaq/SeegWAgnn3jP9iF9+HU/8Bm/4Iisc2O1rvvx/DunX0/sM/ZOUyMIaqTbKf3VB7wmYhBE3ddlyKW/F4WnG55N4t3+UhFEYV6uLsV1gO5/kxY3olSaK21DyzMpkgM8EkC6J5+lRFeEdDA5LBgHHjRgAUBgOmTbfieP/92FL/hFJWzKwKn5ny+00gUnxXFS2kMt94865MPG2pO9+RVxeaykrUJSWgNUdcaLOom6xdi/vw4TEpmUCXC0mtQJWfsT93XFgjdZPJ9ulSFepRmNVZW6sMDOxHckvk3zLO4rvPCW9+Dwrmw6bkQkxJkij9q/+BCATo+Zsfje/8kHIWULfdy5A7QE6erAWKrk58l4fRzs3Jul4SDgdwuS5hjquXRKkttdDc7SA0Y6sybmaCSRZE8/TJ5MEiFMLx/geYNm9GoRuphZjr6wn29uI9JSt3jthUXAiXM2vwyJhzTCl9IwaPNUWmmzKYjMiCU9RLgkHcR47Iq5IoVZuh8xj40qcsDOvWERoYwHcxcRRtoMuFusSY9QMqW0ymhSgUmklvXpQkCW11TtZ1E5e+HeNQEYpsXX2jfPg38mp3509BlXpKqKaigsI//M84Gt7H/t6e8V2jsBYMBWNeBqIrhvmlVVitK+m17SHU7yU07MvaQgXA7W5BCH9C8T1KbYkFTyBEW79rfPc8w0wwyQbZPViZtAjvOXmSUF8f5vpECwnTli2gVmOPqLqOdwzRpF+B8mojBCfmozQhbM3yF9OQR02RibZ+F77gpLULXRdGZMGVSfd7z54l7HIljOiVXWhDSV1o4xnpNxmRCAsh8E+ykiuKQqHBZFo86UV4AN3cHMLOAMFed9rj7FeOEswNkmNYmfa4MVw9Co3/Bmu+LacSM5D32GNoF9XS/Tc/IjQ8DqVZ/CyguMAY9eRaWGqmqPBOnM5zDF08C4yvXjJio7JwzL6RIvxM3WS8zASTLJDlwbOSrkwcexqQ1GpMt92WsF1psWBctw5Hw/uEQmFOdgxhL1knjzHtvI6zxfouxGzna4pMhAW09qV/2Ew3ovNkks4xIa5esnbtyMbZa0GpSakKiqIuK0NdMSehbhIa9iM8wSkJJiCnumQH4cmVacf6TTJIhHvP/AaAwoXJ3I1SEPTD7v8MljLY9pdZfURSqSj90Y8IDQzS+4//mP21QH4ZcFyDgZbYpnNddspz9Vh0agoL5e4EW+97KCwaVAXZpyOdziYkSYPBMNZyZ16xCaVCmqmbTICZYJIlhsg8+HiEEDgaGjBu2IDSNLZZylx/B4H2dloOn8TuDWKafxsgZczlTxpCyCuTAnmuR3XED+xmS3VFg3jSCYvI9RLt/Pmo8vNHNqr1MLsuq9+1cW0d7iNHECF5xTZVxfcoFssywmEvLteFST2vMk+HMkeL71L6usng0CEUTgU5C7MSZcrs/xfoPQc7/hl0Y+eIpEK/eDH5TzzO0CuvZj1DBpAVeZDwMtDUZY+tHPT62ZhMixgUn6CbayVuSkZGnI7zmIzzUCjGzojXqZXMLZixVZkIM8EkS/SGCtzuRHmwr6mJQGdnTMU1GvO2bSBJdL0hO/Yvqq6E0qXXL5i4bOAdiq1MqgtNSNLNF0w8nraUsuCw34/72LHEekmUqs0pXWjjMayrI+xw4D0npz8CXREblalamVhlOe5kF+FjdZMrw4gUBeRwOIzLfBXjcCmKFPNexmC7APt+AovvhwXj75Yv+IM/QD1nDl1/+ReEvVn6ueZXg7ks9l3x+EO09rkSPLnyDVvxWC4iVY2vY10eiDU2xRWltnRmUNZEmAkmWSK7BzsJxMmD7Q0NoFBg2ro16WdU+fkYVq1CfWAvRo1SnsdeuSmrhrpJITpdMbIy0WuUzMrR33TyYLe7NaUs2HvyJMLrTayXRKncBAho25/2/FG7+mjdJNDlQpmnQ6Ed++Y6Geh0s2UH4Smom2irrYTdwZiv2Gjsl/YTsoTJtaxNun8M4TC88YegNsAXfjyhe1LodJT+9V8TaGun71//NbsPjZoF1NzjICxgUZwnl2VI/hnsudm3p/l8NgKBfkzmscX3KLWlFq4NexlyX8fa5v8BzASTLEk2D96xpwHDmjWoclN7Xpm315PT3cFtRo/sFJxlQ92k0Dd2VO/NqOjyRKznk+FqPAwKBYY1a8bunLVKfghmWAmqCgrQ1FTL50I2eJyqVQnIKwi5eXEqgkm03yR5qqv33GsAFC2+P7sTfvoLaD8Id/4dmCZuFGpcV4f1yw/Q/4tn8J47l92HqjaDuw96mzgfWSnEr0ykKzloPGX0uz7M+j6caYrvUaImkjOmj+NjJphkSTRfH62b+C5fxn/5Mub65CmuKJot8qplqy0yAqZifVYNdZOC7QJoTGAZsZ6vKTTRYnPeNDp6WRbcnrpecugQutpalJYkeXyVBuasz2j6CPIoX/ennxJyegj2eSbFdj4dFstyXK5Lk+4grLJqURXoUzYvDjmOohxWYp6bWY3FcCc0/A+YuwWWP/SZ7634T/4EZV6u7CwczEJ8EOs32UdTlx2jRsnsXLkxUYQF/hY7uWxiaKiRQGAwzYlGiAaTZD0mURbN2KpMiJlgkiVReXB0ZRK1mx8tCR7NBYxcyCmn5nykv0Rrhlkrr08w6WuGgnlyyiBCTZEJXzBM500ynlSWBfuSrkzCHg/ukyfTjuilahPYmsCZvhPbsK4O4XbjOngGxNTVS6LIzYsCu/30pJ9bW22V6yahxBeGcCiIy9qNyVmeuV4iBLz1xxAOwj3/T8Lf0ERRWq2U/PkP8Z47x8Bzz2f+QM4cyKmA1k9o6nKwsNSCItL3E+hyITxBioruQogQtr4PsroHh/M8Wm0JanVqKXGhWUu+UTMTTMbJTDDJkhF5sLwycTQ0oF+2DHVxihGyEU60D/H7sqVoL50n0BWx0Miyoe4zY7sAhYnL+ZqiiKLLdnMs4aPBO1mPief4cQgEMK5L85Yd93abDuOaNSBJuI9fBiZvhkkqLJalwOQ7CIOc6hK+EP7OxH/jwaYPCJvC5Oauz3ySs6/DhXdg6w8gb/LGPZu312O6Yxu2n/4Uf3t75g9UbUa0fkJz91DCDJNoGi9v/lp02jJstuwaI53OpqTNivHItiqWmV6TcTITTMaBXl+Bx9NKoLMT79mzKVVc8ZzoGOLC/FUAON6PvD1l2VCXChEMI4IZHFm9dlmnHym+R4kFk5ukbhJNKyZLc7kONYJKhWFlmua7kogLbZJRsPEoc3LQ1i7E3zGMpFWizB2/s/N47P3V6hz0+sqpCSZzo/NNElNdtgu/A6BoSYYRve4BeOe/QulyqPtPk3pvkiRR8sMfIqlUdP3FX2bu1q+6Dck7zGzfpYR6ie/yEKpCPSqrjsKiOxkY+IRgMP3fdDjsw+1uSXAKTkVtqZnmHgfB0AScjz+nzASTcWAwVOJ2t2F/X+5qN9+RPsUFcjApXbwA7byakRkns+uyaqhLRd/z57D9PEN6pE82wYsvvgPkGDQUmDQ3TTBxe1pRKDRJZcGuxkPolyxBYUyzilCqoHKjbE4YTt/5b6xbh/BpUBfpx22j8slFG8v+ag+ftqWXIccTHeM72Q7CSpMGVbFhTBF+yH0c1aAac8WK9CfY9w9yQNn5U/n3N8moi4sp+v73cR86lGCGmpTILKANirOxYCJCYXxX7DGxQWHhnYTDfvr796Y9lct1CSFCGVcmIBf6/cEwV/pmbFWyZSaYjAN9xD148JN30C5YgKYi9dQ/gAGXn/YBN8vn5GCur8d99CjBgQG5oa58bca35WT4u1z4Lgzib7Xja0+T040quQoWjNlVXXjzKLo8blnJNVoWHHI68Z45m75eEmXpV8F+FS68l/YwQ10dCvMsJNX4HQKe3tdCKCz4999nPxTKYl2G39876Q7CALrqHPxt9tgKNhz04861YfKk/5vF54BjL8AtD8g9UVNEzle+jLq8nIEXMtROzCUM6CtZrzjHwsh0RX+nE+EPxTr+c6wrUavz6bWl//d1JBmIlYpo4Do3UzfJmplgMg6ieXvXtZMZVVwAJzvkN8Pls+VgQjiM88OIjLFqM3SdythQNxrXwWtIagWSVonrwLXUB9qa5dVPbuWYXVF58GS/EU8Fbk9r0uK7++hRCIUw1mWhSlp4j6xoa/y3tIdpqpcgqfUEB8Y3JfBSr5NPLvZRaNby3tkerg1lJ26wxByEp6huEgjjb5fz/v2n3kLoBXn5G9N/8MTL4HdA3Xcn/Z7ikZRKch9+GM/RT/E2NaU99pR6GeuUzRiU0fklkXnvc+WViSQpKSysp79/L6GQL+V5nM7zKBQ6DCkMQ+OpLjShVkozdZNxMBNMxkE0bx8sDGcVTI53DKGQYMksK9qFC1GXl2PfEykUVm0mm4a6eMLuAO7jvRhWFGFcVYz7dB8hR4rGKlsz5FUnTVPMKzJh9waxOVN/8aYDMVlwsmByqBFJo0G/IovhTkoVrPmWnFbsPZ/ysLBdfov3nR/fjLbnD7aiUSr4+TdWI4Tgl4fST+WMYjYtRJI0U1c3kYhZ0tsuvwVA8bIHU38oHIbDu+T+nPJVk35Po8l54H4kvZ6BX/4y7XEf+BagxyuLVpBrQeoSI0qjOnZMUeGdhEJuBgaTj/sFcDqaMJkWIEnKlMdE0agUVBeaZhRd42AmmIwDnW4WhCXEPAva+fMyHn+yY4j5xWaMWhWSJGGur8d18BAhhyOuoS77VJfrSA8iEMa0oQzjhjIICVyNKVIkfc1QOD/prpoiOV0w3VNdMVlwsuJ7YyP6FStQaFPboCew8nFQauWHZQpkGxWB58QnhF3Z5crt3gC/+fQq9ywrZdnsHOoXFfPy4Xa8gczOzAqFFrN50ZQEE4VehbrMhK9FDibDvlOo+zQYytIUn1s+hP5LU74qiaK0WLDetxP7m28RHEzeJ+L0BXlzOGLI2LoPEQzja7WPsZzPzV2HSmXB1ps81SWESDoQKx2LZmxVxsVMMBkHwuFBOQAszM9oLCeE4OTVIZbPHtGzm+vrIRDAuffjSEPduqz7TURY4Dx4De1cK+oSI+oCPboFuTgbu8YquwJeeVJdknoJjCi6pvs8+FRz34ODg/jOn09uoZIKYz4s+Qqc/BV4kneH+7tcKIwS+Ny4jx3L6rSvHr2Kyx/i8Q2VADy2oZJBd4DdJ9OkIOOwWJZht5+edAdhkFNd/nYHAbsdT34/Zn91+g807gJjESz64qTfSyryHn4Y4fOlHPHb3G1nEAuOnIVwZR/+djsEw2Ms5xUKDQUFW7H1fUA4PNary+frJhgcGlcwqS210Ovw0T/NV/DThZlgMg6ce/ei6oFgUeZaQ2u/myF3ICGY6JcvQ1VYOKLqqtqcVUMdgLepn9CQD9OGstg204Yywo4AnjN9iQcPXAYRHqPkilJs0WLSqrg4zYNJdLKlwZDY5+A+cgSESG7umI66J+URAMeTp1UCXS40FblIajWuQ4eSHhNPOCx4/mArK+fksLRc/ndePzefBcVmnjvQmlVNympZRjjsiY2gnUx01VYICXr270ZoIbd4U+qD+y/DxT2w+pvyi851QjtvHob16xh8+eWkXfGxeexVm6G9Ee+FfpBAWzV2GFZR4Z0Eg0MMDR0es8/plNOb2RTfo8zMNhkfM8FkHNgbGlC7jHhFT8YHxYkOedm+LC6YSAoF5vo7cH7yCWGPByqza6gDcO6/hjJHi652xGZdOy8XVYEe5/5Rb8GjDB5HI0kS1TeBR5fb05ZUFuw+1IhkMKC/5ZbxnbB0mWyvcuRnY2TCYW+Q0IAXTbkF/fLluLOwS//4go3WfjePRVYlIP9uH9tQydlrdo62Zbb4iBbhpyLVpam0gkJioPcAhKF4eZp6yeGfgUIFq5+Y9PvIRN4jjxDs6sLxwViPraYuOxadCtOC2yHkw3f+GupZJhT6sbXAvLxNKBR6epM0MI7YqIxnZWKO3cMMmZkJJlkSdrtxffJ7TIWLI+7B6VVYJzuGMWiUzC82J2w319cjPB5c+/fLDzetJaNEONDtwtcyjGl9KZJyJL0mKSRM60vxdzjwd8S9PfVdACTZSiUFNTeBPNjjbk0qC3Y1NmJYtQpJM4E36LVPyinAi4kPnECPLAdWlxox1NXhPXcu43TAZw+0UmTW8oVbShO2f3FFGVa9mmcPtGa8Hb2+ArU6d2rqJlolmtlmnPpLaPr06AtTdLL7HHDiRVj8JTCP7eeZakxbtqCeNYvBJIX48112FpZakCo3EkaPvyeMLsVURaVST37+bdhsexAiMfXrcDah05WjUpmTfjYZ+SYtRWYtTd0zwSQbZoJJljg/+T3C58O6UF5NJJu6GM/xjiGWzLLKTsFxGFavRmm1yqkupQoqNmZcmTgPXAOVAsPqsV90w6piJI1SPiaKrVn2NVK0NzldAAAgAElEQVSnnj5XU2Si1+HD7h3fLIjriTuJW3DQZsN/+fL46iXx1N4rz8loTCzEjwzEMsnnFkKWH6fgss3JxxdsPFxXgUaV+DUyaFR8dc1s3j3TTddweplw1EF4smebRFFVaPDmtmEOJV+lAnIdyWeHtU9NyT1kQlIqyX3oIdxHjuBtbo5tD4cF57sdsvGizoo/914QirQjeosK78Tv72XYfjxhu3OcxfcoM7Yq2TMTTLLE0dCAMjeX3CXydLpk8+Cj+IIhmq7ZWT5n7B+9pFZj2roVx0d7EX6/nAseaIHhq0nPFZUDG1cUJUghoyh0Koyri3Gfso3IhONG9aZiutuqyLLgtjHF96hNvGHtBIOJUg1rvgktH42kA5HrJZJehdKqQb90KZJOl3Yy4AsH21ArJR6qm5N0/6PrKhBC8OKhzP5TFvMyXK6LGe1AJoJLHEAog1gNtyU/IByGw09D2UooXz3p18+WnC8/gKTXJ6xO2gfcuP2hWLrJp9kEBNGUpZb2FhTcjiSpE1RdoZAHt7s1rVNwKmpLLVzqdeDPZF80w0wwyYaw349z715M27aiN1UAirQrk3PX7PhDYZaXJ3+DMtfXE7bbcR0+ErOLSCURdh2V5cDGuML7aIzrS0dkwuGQbKWSol4SZboHE5+vJ6ks2N14CIXZjG7R+B8MMVY9EZEJPx3bFOhyoSk1IkkSkkaDYeVK3CmK8A5vgFeOdnDP0jIKzcmlybPzDGyrLealLGTCFqvsIOxwnJnwj5SKQfv7EFZgJkXxveUj+eWj7qlJcQaeKEqrFeu99zK8+42YTLhp1AwTr7sCjdSMontsgT2KSmUmL28DvbY9sbqm03UBCI+r+B6lttRMICS4fJMNlLsRzASTLHAfOkTY6cRSX49CoUGvK0+7Mol1vidZmQAYN25AMhhw7NkDRYtBn5c01RWVA2uqrGnna6gLDWjn5+Js7Eb0t0LIl3FlMjtXj0apmLby4Njc9yQrE8PatUjKzI1nKTEWyHYhJ14GrzziNtDtSnAKNqxbh+/iRYL9/WM+/ptPE+XAqXhiQyUDLj9vnkpvl2Kdwk54hziHbqiMUKoF0uGnwVgo10tuMLmPyDLh4d/8BpCDiUKC+cVmwt4ggT4FWuXZjGnhwsI78Xo7YkV3pyPzQKxUzMw2yZ6ZYJIFjoYGFEYjhvWydbfeUJF2ZXKiY4hii5ZSa/KahUKrxXTbZhwffCC/PVVtkr8goxRi3qYBQoOJcuBUyDJhP56jLfKGFD0mUVRKBVUFxmm7MokGa32c9Xygs5NAezvGuixHzqaj7kkIuOD4iwQHvAh/OGGGSbQm4z6c+BYcDgueO9jG8tk5CUq9ZKyvzmd+sYlnD1xJq/5Tq3PR6yuwT3LdxG+34S10YnRVE+hyEXKNqo8NtMh+ZaueAFWWzZ9TiG7+fAx1dQy89BIiGORcl4O5hSZ0aiW+lmEQoC3xZw4mBXcAiphXl9N1HqXSiF4/e9z3VFVgRKNSzASTLJgJJhkQwSCO9z/AtGULioh6yKCvxONpS/mAONGR2KyYDEt9PaH+fnkmR+Um2YhwMNETynnwGkqrFv2i/BRnGUE3PxdVvg7nqYhWP0X3ezw1RaZpOw8+6has040opWL1kmz8uDJRtkJ2bz78NIHI3I/4YKJbtAiFyTSmbrLvoo0rfS6e2FiZ8RJRmfCZTjvH2tPLhC2WZdiHJ3dl0nv816CE/AI5MPqvjFKnHf45KJRyb8k0Ie/RRwhe68Lx0Uc0ddljKS5fyzCoFGgXVkLXyZSNpwAaTT45OWuwRYOJ43zERmX8jzuVUsGCYvNMET4LZoJJBtyfHiM0OIh5+/bYNr2hgmDQkVQePOjy09rvzvjWatx8G5JGI6u6qiLF0bg3rkCPC9+lIYyj5MCpkBQSxvVl+AdN+LVrQZ96Ln2U6iITHQPurKw/rjceTxs63ZyEB4C7sRFlXh7aeTWTc5G6p2DwCoFzZ0AB6uKRYCKpVBhWr8bdmBhMnj3QSmESOXAqvrRiFhadimf2t6Y9zmpZhs/fg9fXPe4fIxX9nR9AEIpvfQBJo4j5dAHgc8LxF2DRfWDJ7me5Hphuvx11WRm2516gc8gzUny/PIS2woxUs0luyG07kPY8RYV34nJdxOVqwek6P6F6SZTaUjNNXfabwhj1RjITTDLgaGhA0moxbbo1ti3qHhwd3BTPyasjTsHpUJqMGDduxN7QgMivAVNJQjCR5cASxjXZ6/6Nq4uRJB9OkV3+u6bIRFgwLWc2uN2tCQOxhBByf8natUiZRs5mS+1OMJcSaGlHVWBAUo+S+K6rw9/aSqBbfsBf6XOxt9nGw3VzxsiBU2HQqHhwtSwT7h72pjzOYpENKydzdWJXXEBns6CxFqCptCbONzkVkQNfJx+ubJHdhB/Cf/QIlcNd1JZYCLkCBLpcsiS4fA2odFnUTWQj1o6OXxAMOiZUL4mysMRCv8uPzTFjq5KOKQ0mkiTdJUlSsyRJlyRJ+m9J9v+RJEnnJEk6JUnSB5IkZfaGvo6IcBhHQwPGTbeiMBhi26O9D9GRsvGc6BhCkojZa6TDXF9P8FoX3nNNkbrJJyCELAc+1otheXI5cCoUWiUG9ce4HYsIOVO4CcdRUzg9FV3J3IIDbW0Eu7sn3l+SDKUaVn+LgMOMOm+s9DM6Dji6OnnuQGtaOXAqvrG+kpAQvNiYWrRhMtUiSepJq5t4+zvwF3iwKhcDsrVKsNcjy8eFgMan5UmK5Wsm5XqTSc4DDxDSaNnZ8ntqSy1yigvZawyVVk5PZmj01enKsFiWca1L9vyaiCw4ysxsk+yYsmAiyT7P/wp8AVgEfF2SpEWjDjsOrBZCLAVeBX4yVfczEbxnzhDs6cEyym5ery9HlgePfTic6BhifpEZkzbzhDrT7VtAqYykujaDqxdszbg+HXEHHhfOHky8BkKJqzFzumRuoRFJmn7BRJYFexNkwdHaxbj9uDIQXvQoIYpQ+8YaO2rnz0eZk4PrUCNOX5BXP73KjiWlFJnHN9J3Tr6BbQuLeKmxHV8weUpRqdRiNtVOmqKr98SvQQEFlXcCxBr9fJeHoGWv7Cpd990bKgdOhTInh0tLb2Xr1WMUhD34Lg8haRRoyuWXH6o2Q88ZcPWlPU9h4Z0IEQAkjMbMNcRULJrx6MqKqVyZrAUuCSFahBB+4FfAffEHCCE+EkJEx9odAsqn8H7GjaOhAVQqTFu2JGyXC8OzYkaEUYQQnOwYYtnssSZ0yVDl5mJYu2YkmACiZR/Og11oKi1oykzju2FbM2rFVbTlQnYTzjC/WqdWMifPMO2K8J4kbsHuw42oiovRVFZO6rUCDjkwaHp+B97EN09JocCwdi2uxkP85mgHTl8wwYdrPDy+oYp+l583T6aWCVusy3A4TiNE6hpWT08PbnfmSZD93XuR/FCwXE55qstMSDqlPBe+cRcYCuCW+8f/g1wn3q65FW0owPBrr8n1kiorkjLyuIrWGDOsTooK5TqnXj8HlSrNaOcMWA1qyqy6GUVXBqYymMwCOuL++2pkWyq+BbyTbIckSU9KknRUkqSjNpttEm8xNUII7Hv2YKyrQ2kdGxwMhsoxK5P3zvYw6A6wpjIv6+uY6+vxt7TgGwhBzhy8J1sJDXjHvyqBWEe3aUMZYbsfz5mxPRKjqSk0Tbtek2j6MCoLFkLgOtSIoW5tRuv/8eLvkutF6tA5OPHSmP2GdXUEr3Xx5p6jLJudw4o5mYUNydhYk09NkYln07gJWyzLCYXcuFyXku632Ww8/fTT/PKXvyQUSi+acKguo+/LRaWTX0gkhYS2yor3og0uvCsbOk4DOXAygqEwHwet9FYvZvDXuwnaPIkWKmUrQGPOOAvIYKjCYllBbs5nX83Wzsw2yci0KMBLkvQIsBr4h2T7hRBPCyFWCyFWFxYWXpd78l28SKCtPeVERb2+Ao9n5MEw7AnwF787Q22phS+uSBczEzFvuwNAbmCs3Iyzo1y29FicWQ48hr5m0FrQLZuLMl+X6NeVgpoiEy19LkLh6aNU8XjakCQNOp0sPvBdvEhoYCC7Eb3jJNDlQmFUoyifJw/OCieu5oyRtFpe82ke3zDxkl5UJny6c5hj7cllrSPNi2PrJuFwmN27dwNw7do1GhtTW724uy8SKPRh0STOcNdW5xAaChGkZFrJgUfT2u/GFwzjvfcBREgOIgnBRKmCivVZuW2vWvkiCxb86DPfU22phZY+17RUPk4XpjKYdALxXULlkW0JSJJ0B/ADYKcQYtrIJRwNDSBJmLdtTbrfYKiMyIPl/oEfv3uePqePHz+wBLUy+1+rurgI/fLl2BsaCORtxRdcgnGRNLKkHw+2ZiiYj6RUYFpfhr/Njv9q+jxvdZEJfzBMx0Dm1Mn1Qp77Pic2XtUd6S+Z1OJ7hEC3C3WpEWndU3IT3+UPEvZr5s7FabSydugKdy/5bBLa+1fMwqxT8VwKN2G9vhKVyop9eGwwOXr0KB0dHdx7773Mnz+fDz/8kIGB5M7VvSd/DUDh3C8kbNfNkfukfMWPgmUCK9/rRHQFUL5jO+o5KxBhX0IPECCnhfsvgj29u4BCoUWhyFy/zERtqYVQWEy7+uJ0YiqDyRFgniRJVZIkaYCvAbvjD5AkaQWwCzmQZJ4QdR1x7GlAv2olqhQroWg+3+Np5VBLPy81tvOtW6uyUnGNxlxfj+9cE/bLZYAfo2V8M8hjxBk8GlcXI2kUGVcnUY+u6TQoy+Nuw2AYWQW4Gg+hLi9HPSv7FV82iJAg0O2WH1S1O2V5duO/JRzT1u/mSO5cVg5cRjORAB+HUSvLhN8+3UWPfaxMOOogbHecStg+PDzM+++/z9y5c1m2bBk7duxAoVDw5ptvJk2ZDdh+j+SF/GX3JmxXde9GwRA+XQrTx2lCU5cdlUKipjQHddkSgt3n8F0aNTwsUmPMVDeZLKL9LjOKrtRMWTARQgSBPwDeA5qAXwshzkqS9NeSJO2MHPYPgAl4RZKkE5Ik7U5xuuuKv60NX3PzGBVXPNF8/rDjCn/22mlm5+n5Xv3EFCPm7fWg1uO54MdgOI7y2t7xn8QzBM6emMGjQqfCsLIY90lbWpnwdDN8FCKM29MW6+URoRDuw0cwTMGqJNjvgWDERkWlkVM/l96HvpGaxfMH2zhTWIPOPoi/peUzX/Mb6ysiMuHkZllWy3KczgsEg3ItRwjBW2+9hRCCe++9F0mSsFqt1NfX09LSwsmTY9VfDt0VDAMFKNVxqjMhkI48jdbYga9bPa0b8Jq67NQUmVDaA4ighvDQJQZfHFXPKl4Cuhy48vF1uaeKfCN6tXKmbpKGKa2ZCCHeFkLMF0JUCyH+NrLtL4QQuyP/+w4hRLEQYnnk/3amP+P1wfH++wCY77gj5TFRefC+pmNc6XPxP7+0FINmYstpzezZ6Nd8CYQC03wXtO2H0DjnjPRdkP9/nMGjaUOZ7CZ8OLVM2KJTU2TWTptg4vP3yrLgyMrP23SesN0+RfWSkRkmgFyUVqhjbsIuX5BXjnaQu2mD/N9ZjPLNREW+ka0LinipsS2pTFievBiOOQifPXuWCxcucPvtt5ObO1L8X7VqFbNnz+bdd9/F6Rz5t3N2nCKYF8CqW5F44isfg+082oWzCA37CfanbqC80TR1OSL9JXJtSbekjOHf/S5xWJlCAZW3ZlU3mQyUCokFJeaZYJKGaVGAn2449jSgW7w4bVpFodCgVJfSYbvIl1eVc+u8gglfT4QFqrL1BPsvIZVXgt8J18bZvJZkVK+6yIB2Xg6uQ+llwtPJo2tk7nslMNIwaJgMc8dRBLpcoJRQF0YMOU1Fslz2xEvgtfPasas4fEEe2LEWdVlZrHbzWXlsQyV9Tj9vnx6b77dY5KK53X4Ct9vN22+/TVlZGXWj+msUCgU7d+4kEAjw7rvvxrb3nnoFgML5iSkuGp8GQz7aW+UUV0I3/DRi0OWn2+6lttSM7/IwCqOavEfuQ3i9DL36m8SDq26DoXZ5cuZ1IDooazqv6m4kM8FkFIGeHjwnT6ZUcUUJhsK0DOZQaurjB3d/htkagLd5AIJaApc/wHk5siIZ7/K9r1me0ZFbmbDZtL6MkN2P52xqmXBNkSwPng5fkqjcOroycTUeQjN3Luqiokm/VqDLhbrQgBRvjVL3FPgdiBMv8eyBVpaWW1kxJxfDunW4GxsR4c8+JGnTvAKqC408m8SvS6PJR6+bw7D9FHv27MHr9bJz506USSz3CwsL2bx5M2fOnKE5MqFwYPAgCrdE3uI7Rw4cbIXmt2HV46hKrCgsmmkbTGIzTErMcn9JtRV9bS2G1asZfOklRLwkOsMsoMlmUamZYU+ArjS2OJ9nZoLJKGIpru3pg8mzB1q5PJBLubmfHEP2lifJcB64hsKiQaEZxPHxQXnGyXgLi7YLkF8ju8DGoVuYhzIvvUy4psiE0xekx37jxXQed2tEFlyKCARwH/10SlRcIPeYjFEJzVoFs1bj2f9vtNgcPL6hEkmSMNatJTQ8jC9urOxEicqET14d5ngSN2GLdRkDA0c5ceIEGzdupKQktT/bxo0bKSoq4q233sLj8eA0tmMYLEahjEu5Hvk5SApY/S0kSUJXnYPv8vC0eHkYTbTAvUCrIWT3xyTBuY88QqCzE+fevSMHFy6UZ7Fcp1RX7cxsk7TMBJNROBreR1NdjXbu3JTHtPe7+cc9zeSYq5CEMyYPngiBXje+i0OY1pVirt+G6/BhQkXroP0QBMfxcO9rTmo7LykkTOtL8bfa8XcmT2VNJ48uee77bCRJiefMGYTbPTmW86MIuQKE7f6xwQSg7rsYHFe4x9DEjqWyHDhq4+JK098xHu5fWY5Zq+LZJDJho2ExoVAfxcVaNm/enPY8KpWKnTt3Yrfb+eDNZwlZQ+SYVo0c4HfBseeh9l6wymlbbbWVsCtAsGf6yMGjNHU5KDBpMXR5gJH+EvMd21CVlDAQN9YXSZJVXUlmAU0FC0rMkXucCSbJmAkmcQQHB3EfOYK5PnXhXQjBD357GpVCwX2r5QdMMvfgbHEeuAZKCePaEnk1FAzi6LVC0AtXj2R3koAHBttSDsQyri5BUqeWCY8oum6895Anzi04Vi9ZO/lmhCPF97HBpL2knl6Rw/cse9Gq5JWeuqQETWUl7jRz4ceDSaviy6vLeft0F72OxLTJhYvyTJpNm2ejVmde9ZaXl1NXV0dH/+8BKKqNc40+9WvwDie4A2vnxvl0TTPkGSZmfC1DKK0aVPmyIk1Sqcj9+tdxHzyE72KcTLhqMzi7oT+5a8BkYtapmZ2nn/HoSsFMMInD+eFHEAqlrZe8dqyTTy728ad3LWBWpNidzD04G8LeIO5jPRiWFaI0adDdcguqkhIcJzvltES2ueD+S4BIORBLoVdhWFmE+2Tv2Gl7QKFZi1mnuuFFeCFEZGUSqZccakS7cCGq3IlZmKQjELVRSRJMnj98jZdD25g7tB/6L8e2G+rqcB85gggGJ+UeHltfSTAseClOJtzZ2UnjoS6EUKLTpW/Ii2fr1q0UWLsJeLUY526UNwohK9NKlsCckdWdKk+HMk+H9/JwirPdGAKhMJd6nSwqkYvv2rk5CfY5OQ9+BUmjYeDFF0c+VBmtm1wfiXBtyYytSipmgkkcjj17UM+ahW7RaHNjmT6njx+9dY7VFbk8XFcRkwdPdGXiOtqD8I+4A0uShLm+HtfBRsL5S7LPBceUXKlH9Zo2lEEwuUxYkiRZ0XWD01w+v+wWbNBXEvb58Bw/HrMzmWwCXS4UZg1KkyZhu8sX5D+OdtCz4KGITPhnsX3GdXWEXS68585Nyj1UFhjZMr+QFxvb8QfDhEIhdu/ejcFgwWxamLQTPhVqtZo801UG7aXs379f3tj6CfSeS+oOrJ1rxdcyjJhGNjqXbU78oTArDXrCrkCihQqyMarlnnsY/t3uEZlw3lywlF/XusmVfhdu/+S8UPyfxEwwiRByOnEdOIC5vj6lmeBfvXEOty/E3z+wBIVCQqHQotOVpZ0HnwoRFjgPXkNTYUFTbo5tt2yvR/j9ON3VcprLn0Veu++CvJLJTz2BUF1sRFuTg+vQNURo7AOkptDEpd4bOyQrNvfdUIHnxEmEzzfplvNRAsmK78DrxztxeIM8sHklLP4SHP8l+OS0hmGtLE8ePcr3s/D4xipsDh/vnOniwIED9PT0sGPHDqw5K7BncBCOZ/jCPjAG0fuq+OSTT+jp6ZHdgfV5cMsDY47X1eQgvMHYCm06EH3jr/HKf5/a6rEGq3mPPIzweBh67XV5Q7Ru0vr7Mb5qU0FtqQUhoLl7JtU1mplgEsH58ceIQCCliuuDph7eOHmNP9haQ03RyMPfoK+MPQTHg/fCIKF+L6YNiX5P+pUrUebl4bjkh3AAOrJolLM1y5Jgdfo5G6YNZYSG/XjOjZ0DUVNkos/pY9g9zmbJSSQalA36StyNh0ChwLBm9aRfR4TCBHrdaEYFEyEEzx1oZcksKyvn5MZkwpz8FQCq/Hy08+bhnoTmxSibagqYW2DkpY/PsnfvXmpra6mtrcVqWUYo5ErpIDya3ib54bp+7TfQ6XTsfv1VwuffgVWPg1o/5vjpWDc53+VAo1Rg6fWgzNehyh3796xbtAj9qlUMvvjiiEy4ahO4++VV2BQTnW1yfiaYjGEmmERwNLyPsrAA/fLlY/Y5fUH+/LdnmF9s4ru3VSfs0xsqcHtS24qnIioH1t+S2OwoKZWYt23DefQ8YaHKbvnedyFtiiuKbmEeylxt0kL8vOJIEd52474kHndbTBbsOtSI7pZbUJrNmT84ToI2D4TEmJXJgcv9XOx18lhEDkz5alkq3DjiJmxYtw73sWOE/ZknWWaDQiHxjfUV5PafRqFUcffddwNxY3ztp9J9PMaQ8yjKYSWFC27lrrvuorPbxhGWwppvJT1eadGgKtRPq2ByrsvO/CIT/ivD6Oam9rjLe/QRAlev4vw48t2I1U2mPtVVnqvHpFXN1E2SMBNMgLDXi3PfPszbtiWdL/6Td8/Tbffy9w8sHTP726CvJBi0Ewxm/6UM2Nz4LgxiqitN6g5s3l5P2O3GFVic+QsSCkLfxZTF93hkmXAZ/it2/NcS6yM1hfJD+0bWTWS34NkIjw/PqVNTVi/xpyi+P7O/lXyjhnuWxq0W1z4lu9O2fATIdRPh9eI9ld1DPhvmq2yUKBwM59dijgRPg6ESlcqS1I5+NOFQEHduDybnbBQKBUsWVFOjuMr70maGROoBa9rqHHxX7BmHqF0vmrocbLYaEd5Q0hRXFPO2baiKixn85QvyhpzZcu3kOpg+KhQSC2dsVZIyE0wA14EDCLc7qYrraOsALxxq4/ENlXLqYxR6Q+p58KmIlwMnw1hXh8JkwtFlgWvHZWlnKgZb5XRYFisTiLgJJ5EJz8rVo1Upbmgw8XjaMOgrcH96DILBKayXOEEloSowxLZ1DLj54HwPX187B506rvFz8RfBWCSvTgDDmjWgUExa3cRut/Pxhx+AqZDX29UxmbAkKbCYl2LPYozv4Lk9hA2CvDzZQ0w68yr3hN8FpTqlszDINQnhD+G/euP7i2wOH31OH6skudlydPE9HkmtJvfrX8d14CC+S5E0YOUmuW4SmvrCeG2phfMztipjmAkmyF5cCosF49pE/ydfMMR/e+00ZVY939+e/GEddbdNNg8+GWFvEPenvRiWFqI0a5IeI2k0mG6/HefZbvmtse1g6hP2RZRchdkFE4VBLcuET9gSZMJKhcTcwhun6BJC4Ha3oTdE6iVqNYaVKzJ/cAIEulyoi41IyhGhxfMHW1FIEo+sGzUAS6WVDSAv7oH+yygtFnS1tZNWN3n77bcJhUJ88b6dBELwcuPIcFKLdRlOZzOhUHoRRu8F2Wy7aOlXZDlw4y5yiivZdkc9ly5d4vTp00k/N53qJtE3/TmOIKoifcrvRpQxMuGqzeCzQ3fm4PtZqS214PAFuTromfJr3Ux89qkxNzkiEMDx0UeYb78daVSD2P/+6DKXep0888QajNrkv6qYPNjditfr5eDBg9TW1qa0wHB92oPwhzKO5TXX34H9jTdw9xsxXtkHC+5KfmBMFjwv7fniMa0vw9XYjetIN5YtI/PLaopMnOiQu/l7e3s5cuRIxvGwnxVJkli2bBnFxVrCYQ8GfQWuxt3oly1FYTBkPsEECHS50C0cGa3s9gf5jyMd3HVLCSXWJCKG1d+ET/5JtiW5639iWFfH4PMvEPZ4UOjHFrez5dy5c5w/f5477riD5fNms2VBFy82tvGftlSjUSmwWpYDYeyOs+TmpG7cHPYcRyXUmGYvld/Oe8/Czp+ydvlaTp8+zbvvvkt1dTVGY2JaT2lUoy41ysFk65wJ/xyTQVOXHSWg7/GgXV2c8XhVXh6WHTsY/t1uir73PZTR+SZX9sl1rikkfrbJ7DwDnZ2dHD9+nPAUqslEMIjn2DFW3X038zZsmLLrfBY+98HEfeQI4eFhzHduT9h+ocfB/957iS8uL+P2BalNBqPy4IHBZt5662f09/ezf/9+7rnnHpaPKuaLsMB14BqaOWY0s9MXlk233oqk0+EYtMrBJBV9F8BcCrrUOebRqEuMaKutuA52Yd5UHntDryk08eapaxw7cYp33noDAK12aueE+/1+jh8/zrZtclDTiiIcZ89S8N3vZvjkxAg5/ISdgYR6yevHO7F7gzyxoTL5h8wlsOiLskz49h9gXLeOgX//hdwHM8Evtsfj4e2336akpIT169cDspvwE88c4Z0zXdy3fFaCg3CqYBIKeHHn9pMzGJGFN/4b6HNhyVdizsK7du3ivffe4/777x/zee1cK87GbkQgjKS+cYmKpi47txr14AqjS5Piiif3kYcZfv11hl57jfzHH4fCWrnR99bvTem9LigxI0lw7toweT7jQpUAACAASURBVO4O3nnnHVQqFRpN+tXUhAmFCA0PI0Ih5pw/PxNMpiv2PXuQDIaEh0IoLPjT35zCpFXxw3uSNzDGEwrl09l5DJ+vmq9+9as0Njby29/+lqtXr3LXXXehUsm/Zu/FQYL9XvLqM88SVxgMmDbdiuPIAYrnNSG5B8CQN/bAyKje8WLaUEb/C014m/pjirK5BXpWK9vZ/dsjzJ49m6985StYLJZxn3s8eL1eXn/9dU6dfpP58yFwvh/C4SkZhgVxne8lcjCJyoEXl1lYVZGm077uu3DmVTj1Kwwrvw4qFa5DjRMOJg0NDbhcLh566KGYI/Bt8wqpKjDy3IFW7ls+C42mAJ2uHPtw6tRN/6k3EXpBrnIjDHXA+bdgwx/G5MDFxcVs2rSJjz/+mCVLljBvXuIKVludg3P/NXzt9qwf4lNBU5eDh/R6cAfRVGX3YqRfvBj9ypUMvvgSeY8+ilS1SQ74Qb887GyKMGhUVOfp6Dr5CW85r1JTU8P999+PYQpW0sNvvUXXn/8QhdFI+f/6Z7lmN035XNdMRCiE4/0PMG3ejEI3kt544WArx9uH+Mt7F5NvSv1mHgwGeeedd2hr86DXO3nqqaeora3l0UcfZcOGDRw9epRnnnmG4Ui3rnP/NRRm9Rg5cCrM27cTHHLj7VcnV6oIEVFyZVcviUdXm48yR4tjv1yIdzgctB96h8WqHgrnLuaxxx6b8kACoNPp+OpXv8rChfmEwwpeOXAeR35+Uon2ZBD15Ir2mBy83M+FHmfMHTgl5auhbAU0Po3CYEC/ZEnMO2y8XLlyhWPHjrF+/XrKykbSnVGZ8LH2IU5dlesYFsuytIou2+W3AShe9qCchgNY8+2EYzZt2kRBQQFvvvkmPl+ieah2rhWkG1s38QVDXLY5WRyUUJcYURqzd+HOe+RhAh0dOPftk+smATd0fjqFdwsDAwPUBU6id15ly5YtPPTQQ5MeSEQgQPff/R3X/vj76GprqfrNb6Z1IIHPeTDxnDxJqK8vwdixc8jDT95r5rb5hdy3PHVdw26389xzz9HY2Ehx0S0olV50OllJolQq2b59Ow8++CA2m41du3Zx4VjTiBxYld2v3XTbbaBSYb9mSS4Rtl+Tm+omsDIZkQkPc+lYM7t27WKov5d9gbl4S5bGVlPXA4VCQX5+CK1mFm5/iIZtWzl/aWqM+/xdLpRWLYrI2IBnD7SSZ9Rw77L0NSwkSV6d9DVDy14M6+rwnDlDyDk+wUIgEOCNN94gNzeXLVu2jNn/5VXlGDXKmJuw1bIcn68Ln6836fns/lOo+7QYCubAsedg4Q5ZKhtH1Fl4eHiYjz76KGGfQqdCXW7G13LjfLou9jhRhAVF9mBaFVcyzPX1qIqKGPzli1CxEZCmVCLc3Cx/VzRhL+/757Fq3UYUSdoJPguBnl7aHnucwedfIO+xb1Dx3LOoiyd/ns9k87kOJo49DUhqtfzQRk55/PnrsvLlb790S8o31dbWVnbt2kV3dzdf/vKXWbFSLo67R3XCL1q0iCeffBKj0cjLu3/NSXUbhhRy4GQoLRaM69fj6DIhWpIEk3EquUZjWF3EGU0HL+7+FVqtlm9/+9uI3Dk3RNHl8bRhNlSw/Z23ydNq+fWvf82ePXsmXQAQb6PSMeDm/aYevr52dqIcOBWLvyTPz2jcJffAhEK4jx4d1/U//vhjBgYGuPfee5Pm2M06NV9eVc6bJ7voc/qwWJcBJJUIh7xOPAWDmAPVcPoV8AwmuAPHM2fOHNasWcOhQ4e4evVqwj7dXCv+dgdh/9SKLVLR1GVnMUoUYZG2vyQZskz4a7j278fXPSSbWk5B82I4HObDDz/k5ZdfJi8vj1Xbv0JnOGfSbVXcR45w5YEH8J4/T9k//SPFf/ZnY4RB05XPbTARQuBoaMC4YQNKk9zYtfvkNT5qtvH97Qsozx27bBVCcODAAZ577jl0Oh3f+c53uOWWWzBEXG6TeXQVFBTwrUefoEoUc0R5iVfeeg2vN/tJbeb6OwgMBvBdbgHHKJNGW2Tue5Y9JvH4fD5ee/t3HFJcoEIU8q2Hn6C4uJjqGyAPFkLg8bShHlRjcHt45K67WLNmDQcOHOCFF15ImHH+ma4TCBO0uWPB5JeH2pCSyYFTodLCqifgwrvoK3KQNJpxWdJ3dXWxf/9+VqxYwdw083K+saESfyjMy43tmE2LkSQVw0mCie3E6wgN5BdtlsfyFi2OvJ0nZ9u2bVgsFnbv3k0wzvlYW50DYYG/9cY04jV1OahTqEEB2izrJfHkPPggklotr06qNkNHozyWYZJwu928+OKL7Nu3jxUrVvDNb36TFfPLI/c+Ob8zIQT9v3iGtsefQGkyUfUfv8K6Y8eknPt68bkNJr6mJgKdnTEvrgGXn7964xzLZ+fwWBJVj8/n45VXXmHPnj0sXLiQ73znOxRFRsnq9bMBKaVHV/D0ILf7FnFH3e1cvHiRp59+WjbiywLztm0gSTg69GMt6fuaZRWXaXxLYJvNxs9+9jPOnTvH1rrNbPPdQui0LAmuKTLR2u8ieB27ov1+G6GQG+mKC4XRiGnZMnbs2MGXvvQlrl69yq5du+jo6Mh8ogwEet0QljvfPf4QvzrSwV2LSyi1jkPeu/qboFCiOPUC+hUrcB3OLpiMOAIb2L59e9pjqwtNbJ5fyC8b2wijwWRagD1J3aSv7T0IQ1FRDfSclr3E0tR9dDodO3bsoLe3d8RZGNBUWkAp3bC6SVOXnfUqDZpZZhS68adXVfn5WO6+m6Hf/pZQ0VoI+aHj8KTcW2dnJ7t27aK1tZV7772X++67D7VaTZlVh0Wn4twkzDYJOV10/pfv0fuTn2DeupXKV19BOy97qf904XMbTOwNDaBUYtq6FYC/efMcdk+AHz+wFKUi8QsZffg2NTVRX1/Pgw8+iC6uYJ/OPVh2B+5CO9vCrV+4jcceewy/38/Pf/5zTmVhyaHKz8ewahWOa8axMxtsEU+udIXjUZw9e5af/exnuN1uHn30UTZ/YSu6uTk4D3YhQoKaIhOBkKBt4PpN4Yu6B4jj19CvXoUUqdcsW7aMb3/726hUKp555hkaGxs/U9dx/AyT357oZNgTSPrikBZLKdTuhGMvYFi1HF/TeYKDmSdtNjY20tXVxd13340+i96UJzZU0mP38e6ZbiyW5djtpxEiMcAPB8+i6dOja34ddDmw5CsZz7tgwQIWL17Mvn37sNlsACg0SjSzzXhvQDARQtDaZacykL7rPRO5jz6KcLsZPt4LknJSUl2ffvopv/jFLwD45je/yapVI/0rkiTJnfDdn21l4rt8mdYHH8TR0EDRn3yfWf/vv8QyJTcbn9tg4mhowLBmDarcXD6+YOO14538X1uqY6M5o0Qfvh6Ph2984xts3LgxaS3FoK9MOtfEd3GQYJ8n1qRYUVHBU089RWlpKa+99hpvv/12QsohGebt9fgGFfhPjPqCpBjVm4xQKMR7773HK6+8QlFREU899VQs1WLaUEZoyIe3qT9u6uL1S3VFf2/iVA/GUSN6S0pKePLJJ6mpqeGdd97htddewz9Bk8VAlxNJrUCZp+PZ/a0sKrWwpnICg7fqvgu+YYz5dhAC95H0EzEHBgb48MMPWbBgAYtSzMoZzW3zC6nMN/DsgdaIg7ATl3tkUFfAOYC30I4lUAlNb8Kqx0CTnaLoC1/4Amq1mjfeeCPWaKetziHQ6STsub5zOnrsPuZ4wihFcsv5bNHfshj98uUM/MeriLIVnymYBAIBfve73/HGG29QWVnJk08+yaxZs8YcV1tqobnbQXiCM2Hs775L61ceJDQ8zJxf/IL8b30rvaJwmvO5DCa+lhb8ly5jrr8Dly/If3/tNNWFRv7vrSPzQJI9fKuqqlKeU2+oSOrP5TwQkQMvGZEDm81mHnvsMdatW8fhw4d59tlnsdtTv+GY75DVZvZz/fJ4XgD3ALhsWdVLHA4Hzz//PAcPHmTNmjU8/vjjWK0jX9yoTNh54BrVhXI94XoGE7enFUkoUQ7KRoqj0ev1fO1rX2Pr1q2cPn2an//85/T394/7OoEuF+oSI42tgzT3ODLLgVMxey2ULkPf/yaSQY+7MXVKRQjBG2+8gVKpZMeOHVlfT5YJV/Jp2yDdbjnox/eb2I6/CirI92sBMUYOnA6TycSdd95Je3s7n34qy2h11VYQ4LtyfVVdTV12VqJCKCQ0FZ9Nip776CME2tpxuefJ8mDf+FNQg4OD/Pu//zvHjx9n8+bNPPzww2OcA6IsKrXg9ofGvYoXgQA9f/9jOv/L99DOn0/Va79J+nd/s/G5DCaOhvcB+SH9T3su0Dnk4ccPLI3N+3Y4HDz33HMcPHiQtWvX8vjjj2fsuZDdg4cJBEZSBYE+D97/v71zj66quvP453dfeT8IARIMkEhSHvKUAPISBigFQUCFCgIiBJKZ2pm2dlanrrHtdKaPse0ap+10WgIIglZRVKSiQEBpR1TkFYTwhkB4BEgIed28b/b8cU7CNSQhyb034cL+rHXXPWeffc7dv5uT+zt779/+/k7cIGTEreHAVquVqVOnMmfOHK5evcqKFSvIzs5u9Nr27t0J7NObkguBN8Me883J9y59m21XTk4OK1as4NKlSzz22GNMnz79lrBfsQqho2KpPFtEYGEVMeGBnGnPnknZeexlwVjDIgno27g9FouFhx9+mIULF1JSUkJ6ejrHjx9v8Wcopai+YkRyrf00m07BdmY2E/rdLGaYsBScILhfAs49Tet0ZWZmkp2dzeTJk1u9bmdOchzBDiuv7gebLewr8yb5F3eCC7pcPQB9HoHI1smhDBkyhPvvv5+MjAyKiopw9AwHm6Xd502Oms7E1iMUi6MFEXXNED5lCrYuXSj4Ig+UC3Jap5926tQpI0S+sJD58+czceLEZsN++5m5TVozCV+Tl0fOkqUUrF1LpwUL6LXuFezdbi8f4w/cm85k+3aCBg/mSKWDNZ9ms+ihXiTHG6vLz58/z4oVK7h8+TKPP/44jzzySIvWXNTlLXfvnTg/M9SBQ0fGNnEWDBgwgOXLlxMUFMS6devYvXt3o/MCYdNnUlHgoPpghlFQp8nVxDCXUorPP/+ctWvXYrfbWbZsGYMHD26yHcHJMWAz1ISTuoW2az74svJzWC/XEDJieKMpANxJTEwkLS2Nzp0788Ybb7Bjx44WaSK5iquoLavBGWEn4+hV5jVUB24tDzwOwZ0J6VRI1ekz1JjzD+6Ulpaybds2evbs+ZXx9pYSboYJ/+XQFQKDB3wlt0kxxwi4GkBAVYEx8d5KRIQZM2ZQW1vLli1bwCoExIdT2c554c9eKKIPFoIT2zDc2ACx24mcPw/n/qNUOoNanBe+traWXbt28dprrxEREUFqaip9+ty+x5/ULRSrRVrsTMr27yf78ScoP3KE7r/+FTE/egHxlQRLB3DPOZPqS5eoyMoiaNJknn/nMN3CAvnB1D71P76vvPIKDoeD5cuXM2jQoBZfNzg4Hrg5/l9bWYNz31WCBkZjDW/+hunatSvLly+nX79+ZGRk8Oabb94SPlwnj1/yf1+YK99Pgi0IIm59Iq2qquLtt99m69atJCYmkpqa2qTwZB3WEDshQ7tSdvAa/SODOXOttF0ktpVSlDnPYcmpJLjBfElTREZGsmTJEoYNG8Ynn3zC+vXrcTqbTz9bN/m+Na+4deHATWEPhGFLCLYYP/DORoa6PvzwQ6qrq5k5c2abF7Y9PcoIEz5X3ItS53FcrnIqi65RGe0kPA/o2v9mcqhWEhUVxcSJEzl58iRHjx4loHcE1VecuEq9k/irJcjFEiyI16RcOtWFCV/q1aJ5k7KyMv785z+za9cuBg8eTEpKClFRjcgWNUKg3cr90SG3dSZKKQrWreP84meQ4CDiN2wg4tFHW/QZ/sQ950xKdhhDXO+HJ3H8Sgk/mz0Ah9SyceNGtm7dSlJSEqmpqXRrZdczMNAID67rmZQduIaqvL06cB0BAQHMnTuXKVOmcPz4cVauXMm1azdXPQckJBAQF03JmUq4fgbyjkN0IjT4kcrPz2flypVkZWUxceJE5s2b16LoIYCQ0d1R1bWMLgNnlYvcopavh2krVVV51KpybHnSqnFju91eH6pZN5TXcDGeO3UyKqtPXGFK/27cF9l2td96kpcS2MmFJch+i7TK8ePHycrKYvz48URHt0w+pzESu4YyLimaD09EoZSLkpIs8g5uACtE3yiAEamtiuZryMiRI4mNjeWDDz6gNs6QDmqveZOKahf3FddQYwFHT+9k1LRFRxP+yDSKsspw5Rw2FnI2QW5uLunp6Zw9e5bp06cze/bsVos19osN51gz4cG1TieXv//PXP3FLwkdP56EjRsJ7NN6xQp/4J5zJsUZGdA7iRcPlzFjUCxDulpZtWoVR48eZdKkSTz55JNfCfttKVarER5cXn7eCAf+9DL2uNDbqgO7IyKMHj2axYsXU1FRwcqVKzly5Ej98bDJkyjLc1Dz5dabYcFuHDt2jPT0dEpLS1m4cCEPP/xwq56IHbEhOBIi6JXjxEL7TMLX5YFxVEbg6N37NrVvZejQoaSkpGCxWFizZg179+5ttEdVneukPMRGbnk1z7Q2HLgpIu5DBswkOLoc5+c3c85UVFSwZcsWunbtymgvKLw+MzqeA7nGQ0lRcSb5lz+CaugSGACDvunRta1WK7NmzaKsrIxdRz5DHNZ2G+o6caWEodio6BrUYomhltBp4UJqK2soyg6Cc7sbrXPw4EFWr15NbW0tS5cuZfjw4W0KxugXG86lwnKKyqpvOVZ5NpvsJ5+keOtWunzve8T9/nc+SUN9p3BPOZOa/HzK9x/goy79CHJYWdjXRnp6Ok6nk0WLFjFu3DiPdHaCgox88JWnC6nJM8KB23KDxsfHk5aWRkxMTH2PyeVyETbzm6CE0g82QVFOvYyKy+UiIyODDRs2EB0dTVpaGr3b8MMMRpiwraSa0djax5mUGUEHYT2GtTkssnv37qSmppKQkMCWLVvYtGnTLeHD1blOjtVU0zcmjBEJLRvGaBEj0giJdlJ94SLVlw3RzJ07d1JaWsrMmTO9onE2oU9XIkNjKKmOprj4ECWWkwRdBHvyInA0HmnUGmJiYhgzZgyZhzK5FlPebpPwp87dIBErQUmez5e4EzRwIIGDBnLjVCjqzFfnTeq00d577z169OhBWloacXFxbf6svmZuk2MN1psUb9/OublzcV0voOfqVUSnpd52PtDfubuta0DJzo9AKTYGJbIsoYStm9+hS5cuX1lz4QnBwfGUlZ03woFD7QQP6tLma4WHh7N48WJGjhxZP5dTFReHvVMgxfvN9QbRX6O0tJT169eze/duhg0bxtKlS4mMbPv4c1D/zlgjAphvCWiXSfjS3C+hBiIGjffoOsHBwTz11FNMmDCBQ4cOsXr1agoKCgCorXJRnV9OZmUVS8a0MRy4KXo+RPADxvyLc88ecnJy2Lt3LyNHjvToR8odq6kmfPx6HHn5n1IVXUF4Xg0MX+6V6wOMHz+eqKgodhVnUpFXiqu48vYneUjpKWMIqtuAtv+fNEXUoqepKrHi/NtNYcvCwkLWrFnD/v37GTt2LIsWLWoy7Lel9G8Q0aVqarj2m99w6Z++g6N3byPs18xXc7fjU2ciIlNF5ISInBaRHzZyPEBENpjH94hIvC/bk//hNs5FdWd4jzKunz1McnIyS5Ys+cqaC08ICupFTU0hzjM5hIyI8bjrbrPZmDZtGk888UT9+G7JuBE4rwbgqhIuuDrXzxXMmjWLRx991OMnYbEKIaNiGVxrpeSid0XsGqP06pdYr0PoSM+HgywWCxMmTGDBggUUFRWRnp7OiRMnqLlahijIdcCsIbcuPvMIEQKmfQtrgIviHZvZvHkzkZGRTDSVFbzF3OQeXChNQNUWggWiwxKhk4dBBG7Y7XZDWbiihP22s+0y1BWUW0aFQECc94d+wr8xBWtEEAV7r0PpNU6fPs2KFSu4fv068+bNY/LkyV5R++0aFkBUiINjucXU5OeTk7KM66tWEzl/Hr1eXY89tulIzrsNnzkTEbECfwCmAf2B+SLScPlvCnBDKZUIvAS86Kv21BQVcfnMKfZMGE2Yq4TZs2czY8YMr0qt1+WDrwq5RuhD3ruJBg4cyLJly3A4HGwOieVEYh92lySzZtPHWK1WUlJSGDrUe/nSQ4bHUCMw6Krvn07LKy5gLwrC3tN7aWOTkpJIS0sjMjKS119/nQ937KQWxQNDYj0LB24CGTSX4Fj4orCM/Px8ZsyY4fWsexFBduJjjXwWUgldJv3Aq9cHY3j1wQcf5Igth5wjZ71+fXeUUvQqdXElwlaf6dObiMNBp1nTKM0N5KM31/Hqq68SFhZGamoqfZtYy9SmzxGhX2wYzoOZZD8xh/LMTGL/85fE/uQnWO6isN+WIL4K/xSRUcC/KaW+Ye4/D6CU+qVbnW1mnc9ExAZcAbqoZhqVnJys9rVS9htg089X8WXVRYIJZGroCKKt3umNuFMRcJEz/Z7D7uqCI9z7Wetqa2spKSmpT3Bkd7kIrq5GfPE3tIUi1kCU8q0seXVoHiHZY5FzS7x+bRcujlpPctGSS7AKwNE5FLvVN89PrmuXuKFsJOTmMCareXmVNn+GTXHhR5UEZAs/LVnlURRXU1hVNWOLv8BCLQ58m7LZpqAq0EJIROsDXlqCqqmh/MIFnKGhJFw+z8hj+7F7OaUBGJlZXcUKCQbHOAuWTr6TRLk+7LsMm95ytQN3RGS/UirZy02qx5cZkO4D3KVeLwINYz/r6yilakSkCOgM5LtXEpFUIBWMvAxtISwklJiSYKb1/TrBdt/cvDZ6E132KMRUYAnwzVcbGqrIP3UMl7OccLz/lF1HbYUFF+H4WikooCiayhtjqQrxxfdloxcDCXJ1piDwBt1ivP8AUYcKDaLbwc8YVnSWgFjffU7E30o5HTmapBjfRQWpgGGEFZwFXy8zEoi5L5zAIN/l66gqukJMThZ9blxCuvpGQLHGpSjprqgeFkVZgO/+JwEcoV4MHvEyvuyZzAGmKqWWmfuLgJFKqW+71Tli1rlo7p8x6+Q3dk1oe89Eo9Fo7mV83TPx5QT8JcA9f2icWdZoHXOYKwJovYKfRqPRaDoUXzqTvUCSiCSIiAOYB2xuUGczsNjcngN81Nx8iUaj0WjuTHw2Z2LOgXwb2AZYgZeVUlki8u/APqXUZmA1sF5ETgMFGA5Ho9FoNH6GLyfgUUp9AHzQoOzHbtsVwO3Tw2k0Go3mjuaeWgGv0Wg0Gt+gnYlGo9FoPEY7E41Go9F4jHYmGo1Go/EYny1a9BUikgec7+h23IZoGqzi91PuFjtA23KncrfY4g929FJKeV+i2cTvnIk/ICL7fLnStL24W+wAbcudyt1iy91ihyfoYS6NRqPReIx2JhqNRqPxGO1MfEN6RzfAS9wtdoC25U7lbrHlbrGjzeg5E41Go9F4jO6ZaDQajcZjtDPRaDQajcdoZ9JKRORlEblmJvaqK4sSkQwROWW+dzLLRUR+JyKnReRLEXmw41p+KyLSQ0Q+FpGjIpIlIt8xy/3KHhEJFJEvROSQacdPzfIEEdljtneDmQoBEQkw90+bx+M7sv2NISJWETkoIu+b+35pi4icE5HDIpIpIvvMMr+6v+oQkUgR2Sgix0XkmIiM8ldbfIF2Jq1nLTC1QdkPgZ1KqSRgp7kPMA1IMl+pwB/bqY0tpQb4vlKqP/AQ8KyI9Mf/7KkEJiqlBgNDgKki8hDwIvCSUioRuAGkmPVTgBtm+UtmvTuN7wDH3Pb92Za/U0oNcVuH4W/3Vx2/BbYqpfoCgzH+Pv5qi/dRSulXK19APHDEbf8EEGtuxwInzO0VwPzG6t2JL+A94Ov+bA8QDBwARmKsSLaZ5aOAbeb2NmCUuW0z60lHt93NhjiMH6aJwPuA+LEt54DoBmV+d39hZIHNbvjd+qMtvnrpnol36KaUyjW3rwDdzO37gAtu9S6aZXcc5vDIUGAPfmiPOSyUCVwDMoAzQKFSqsas4t7WejvM40VA5/ZtcbP8N/ADoNbc74z/2qKA7SKyX0RSzTK/u7+ABCAPWGMOP64SkRD80xafoJ2Jl1HGY4hfxVuLSCjwNvBdpVSx+zF/sUcp5VJKDcF4qh8B9O3gJrUJEZkBXFNK7e/otniJsUqpBzGGfZ4VkYfdD/rL/YXR63sQ+KNSaijg5OaQFuBXtvgE7Uy8w1URiQUw36+Z5ZeAHm714syyOwYRsWM4kteUUu+YxX5rj1KqEPgYYygoUkTqsom6t7XeDvN4BHC9nZvaFGOAmSJyDngDY6jrt/inLSilLpnv14B3MRy9P95fF4GLSqk95v5GDOfij7b4BO1MvMNmYLG5vRhj7qGu/GkzsuMhoMitS9zhiIgAq4FjSqn/cjvkV/aISBcRiTS3gzDmfY5hOJU5ZrWGdtTZNwf4yHyq7HCUUs8rpeKUUvHAPIy2LcAPbRGREBEJq9sGpgBH8LP7C0ApdQW4ICJ9zKJJwFH80Baf0dGTNv72Al4HcoFqjKeVFIwx6p3AKWAHEGXWFeAPGOP3h4Hkjm5/A1vGYnTLvwQyzdcj/mYPMAg4aNpxBPixWX4/8AVwGngLCDDLA8390+bx+zvahibsmgC876+2mG0+ZL6ygH81y/3q/nKzZwiwz7zPNgGd/NUWX7y0nIpGo9FoPEYPc2k0Go3GY7Qz0Wg0Go3HaGei0Wg0Go/RzkSj0Wg0HqOdiUaj0Wg8RjsTjd8jIvHipuLckddurr4pwdHfe63TaO4cbLevotHcHYiIVSnl6qjPV0ota019EbGpm3pcGs0dje6ZaNoN86n9mIisFCPvyHZzxToiMkREPjdzP7zrlhdil4i8JCL7zHOHi8g7Zv6In7ld3iYi21NSoAAAA7hJREFUr5l1NopIsHn+ORF5UUQOAHNFZIqIfCYiB0TkLVOXrGE7h4mRG+UQ8KxbuVVEfi0ie812pjVhalNt2SUiyeZ2ioicFCMPy0oR+R+zfK2I/ElE9gC/EpERZnsPisindSuwReQZEdkkRg6NcyLybRF5zqz3uYhEteb7E5GFZlsyRWSFaavVbM8RMXKSfK+Nf3rNPYB2Jpr2Jgn4g1LqAaAQeMIsXwf8i1JqEMaK4Z+4nVOljFwYf8KQq3gWGAA8IyJ1Crl9gP9VSvUDioFvuZ1/XRligzuAF4DJ5v4+4LlG2rgG+Edl5EdxJwVDFmM4MBxYLiIJjZzfXFsQke7AjzByyIzhVlHKOGC0Uuo54DgwThnigj8GfuFWbwDwuNmWnwNlZr3PgKfd6jX7/YlIP+BJYIwyxDJdwAKMFd/3KaUGKKUGmt+LRtMo2plo2ptspVSmub0fiBeRCCBSKfVXs/wVwF1ddrP5fhjIUkrlKqUqgbPcFNO7oJTabW6/iiEVU8cG8/0hoD+wWwy5+sVAL/fGmRpfkUqpv5lF690OT8HQW8rEkOrvjOEcG9JcW8AQO/yrUqpAKVWNIYfizltuw3ERwFvmPMxLwANu9T5WSpUopfIwpOf/YpYfxsi5U8ftvr9JwDBgr2nbJAwplLPA/SLyexGZiuEYNZpG0XMmmvam0m3bBQS14pzaBufXcvMebqgL5L7vNN8FyFBKzW9ZU29BMHos225Tr7m2tASn2/Z/YDiNx8TIObPL7VjD78L9e7I1Uq+p70+AV5RSzzdsiIgMBr4B/D3wTWBp60zR3Cvonommw1FKFQE3RGScWbQI+GszpzRGTxEZZW4/BXzSSJ3PgTEikgj1qrZfa9CWQqBQROp6EwvcDm8D/kEM2X5E5GtiqOG2ti17gfEi0kkM2fgnaJoIbkqXP9NMPU/YCcwRka5Qn6O9l4hEAxal1NsYw4N3fR5zTdvRPRPNncJi4E/mZPVZYEkrzz+BkXzpZQxp8Ftybiul8kTkGeB1EQkwi18ATjaougR4WUQUsN2tfBXG8NEBERGMzHuzW9sWpdQlEfkFhspvAca8SFETdv0KeEVEXgC2NFHHI5RSR83rbxcRC4Yi9rNAOUZmwbqHzlt6LhpNHVo1WKPpAEQkVClVavZM3gVeVkq929Ht0mjaih7m0mg6hn8zJ7uPANkY+TE0Gr9F90w0Go1G4zG6Z6LRaDQaj9HORKPRaDQeo52JRqPRaDxGOxONRqPReIx2JhqNRqPxmP8H+PdwX7Isn0MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([x*50 for x in range(1,mx_big//50)])\n",
    "for j in range(0,len(codeLangues)) : \n",
    "  y = np.array([i[j] for i in lang])\n",
    "  print(y)\n",
    "  plt.plot(x, y)\n",
    "\n",
    "plt.title(\"Evolution de l'acuracy en fonction du nombre de bigrammes \")\n",
    "plt.xlabel(\"nombre de bigrammes\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dDTkus_ZY5e"
   },
   "source": [
    "Nous avons récupéré dans la liste précédente le premier endroit où l’accuracy est au maximum puis nous avons mis sur un même graphe nos différentes langues pour les comparer.\n",
    "\n",
    "Nous observons dans ces résultats que pour six langues, la taille de nos données ne permettent pas de déterminer avec certitude la langue  : pour les autres, l'accuracy est déjà dès le début à son maximum.\n",
    "\n",
    "Selon les tirages, il n'y a pas le même nombre de langues qui ne sont pas discriminées complétement, comme precedemment nous pourrions faire des moyennes sur plusieurs tirages pour voir s'il y a des langues qui ressortent particulièrement dans les erreurs de reconnaissance.\n",
    "\n",
    "Cet apprentissage connait ainsi des limites selon les langues d'entrainement et de test, il serait alors interessant dans un projet futur de voir quelles sont ces langues, et avec lesquelles elles sont confondues.\n",
    "\n",
    "Nous allons maintenant déterminer le nombre de données qu'il faut au sein de chaque langue pour avoir la meilleure exactitude.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ae7qBYiLhVO3"
   },
   "source": [
    "### Nombre de données permettant la meilleure détection pour chaque langue dans le corpus précédent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vq5BLxXqhUTk",
    "outputId": "4ee64798-0506-46df-8081-074ec5aee4e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La langue en a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue fr a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue it a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue nl a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue sl a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue es a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue pt a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue de a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue ca a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue af a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue el a la detection la plus haute à partir de la 3 itération (50 bigrammes/itération)\n",
      "La langue be a la detection la plus haute à partir de la 4 itération (50 bigrammes/itération)\n",
      "La langue ja a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue kk a la detection la plus haute à partir de la 6 itération (50 bigrammes/itération)\n",
      "La langue la a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue ar a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n",
      "La langue bg a la detection la plus haute à partir de la 7 itération (50 bigrammes/itération)\n",
      "La langue bxr a la detection la plus haute à partir de la 8 itération (50 bigrammes/itération)\n",
      "La langue cop a la detection la plus haute à partir de la 1 itération (50 bigrammes/itération)\n"
     ]
    }
   ],
   "source": [
    "n =0\n",
    "for  j in codeLangues: \n",
    "  l = [i[n] for i in lang]\n",
    "  y = argmax(l) + 1\n",
    "  print('La langue '+j + ' a la detection la plus haute à partir de la '+ str(y) + ' itération (50 bigrammes/itération)')\n",
    "  n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGcrx6BQaZ0D"
   },
   "source": [
    "Nous observons une nouvelle fois que pour la majorité des langues, il suffit d'une itération, soient 50 bigrammes pour que notre seuil de détection soit au plus haut.\n",
    "\n",
    "Pour d'autres langues en revanche, il faut plus d'étapes d'entrainement, par exemple dans ce tirage pour \"bxr\" il en faut 8, nous avons donc des disparités de reconnaissance en fonction des langues : certaines ont besoin de plus de bigrammes que d'autres afin de garantir leur reconnaissance.\n",
    "\n",
    "Puisque nous n'avons pas de résultats homogènes entres les langues, nous pouvons dire qu'il ne faut pas le même nombre de données pour reconnaître chaque langue : certaines en nécessitent plus que d'autres indépendamment de la taille du corpus de langue. Un grand corpus entraine des résultats moins bons qu'un plus petit, mais ce nombre de corpus varie en fonction de la langue étudiée.\n",
    "\n",
    "\n",
    "L'augmentation du nombre de bigrammes ne se fait pas non plus sans risque de surapprentissage : plus nous augmentons le nombre de bigrammes et plus il est possible de tomber sur des bigrammes peu fréquents dans une langue, induisant une mauvaise interprétation du classifieur. Ainsi à partir d'un nombre trop grand de données en entrées, nous pouvons plus facilement tomber sur des exceptions qui n'en seraient pas dans d'autres langues, ce qui réduirait la précision de notre classifieur.\n",
    "\n",
    "De plus, les langues ayant des constructions syntaxiques et grammaticales précodées dans le langage naturel, il n'en existe pas une infinité de bigrammes différents, il faut alors en fonction des langues le nombre de bigrammes adapté pour qu'il soit à la fois représentatif des fréquences les plus observées, et à la fois incomplet pour qu'il ne trompe pas la détermination de la langue.\n",
    "\n",
    "Il nous faudrait donc extraire un nombre particulier et adapté de bigrammes pour chacune des langues dans le classifieur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1IyN0lzffYH"
   },
   "source": [
    "## Projet 2 \n",
    "Nous voulons maintenant étudier comment nous pouvons distinguer les langues entre elles.\n",
    "\n",
    "Pour ce faire, nous allons comparer les résultats avec un matrice de confusion, dans laquelle nous rentrons les données prédites et les données observées pour chacune des langues. Nous ajoutons alors le nombre de prédictions correctes entre elles : celle de non-reconnaissances justes, et celle de reconnaissances de bigrammes justes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khv98OWNxX2n"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7-mrGCjLjff",
    "outputId": "89cbbbc3-272c-4e2d-ea77-00e1ca815296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langue : en code =  0\n",
      "langue : fr code =  1\n",
      "langue : it code =  2\n",
      "langue : nl code =  3\n",
      "langue : sl code =  4\n",
      "langue : es code =  5\n",
      "langue : pt code =  6\n",
      "langue : de code =  7\n",
      "langue : ca code =  8\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "train_p2.dat\n",
      "900 exemples lus\n",
      "traite corpus ./test/en_partut-ud-test.txt\n",
      "traite corpus ./test/fr_sequoia-ud-test.txt\n",
      "traite corpus ./test/it_partut-ud-test.txt\n",
      "traite corpus ./test/nl_lassysmall-ud-test.txt\n",
      "traite corpus ./test/sl_sst-ud-test.txt\n",
      "traite corpus ./test/es_ancora-ud-test.txt\n",
      "traite corpus ./test/pt_bosque-ud-test.txt\n",
      "traite corpus ./test/de_gsd-ud-test.txt\n",
      "traite corpus ./test/ca_ancora-ud-test.txt\n",
      "test_p2.dat\n",
      "90 exemples lus\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 6ms/step - loss: 2.1839 - accuracy: 0.2060 - val_loss: 2.1308 - val_accuracy: 0.7222\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 2.0978 - accuracy: 0.8689 - val_loss: 2.0109 - val_accuracy: 0.8611\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.9585 - accuracy: 0.9137 - val_loss: 1.8239 - val_accuracy: 0.9944\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.7508 - accuracy: 0.9731 - val_loss: 1.5880 - val_accuracy: 0.9944\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.5061 - accuracy: 1.0000 - val_loss: 1.3430 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.2741 - accuracy: 1.0000 - val_loss: 1.1177 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0280 - accuracy: 1.0000 - val_loss: 0.9211 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8749 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.7168 - accuracy: 1.0000 - val_loss: 0.6263 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 1.0000 - val_loss: 0.5160 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2380 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "l_corpus_train=[\n",
    "['en', './train/en_partut-ud-train.txt'],\n",
    "['fr', './train/fr_sequoia-ud-train.txt'],\n",
    "['it', './train/it_partut-ud-train.txt'],\n",
    "['nl', './train/nl_lassysmall-ud-train.txt'],\n",
    "['sl', './train/sl_sst-ud-train.txt'],\n",
    "['es', './train/es_ancora-ud-train.txt'],\n",
    "['pt', './train/pt_bosque-ud-train.txt'],\n",
    "['de', './train/de_gsd-ud-train.txt'],\n",
    "['ca', './train/ca_ancora-ud-train.txt']\n",
    "]\n",
    "\n",
    "codeLangues = calculeCodeLangues(l_corpus_train)\n",
    "l_id = l_identifiants(codeLangues)\n",
    "\n",
    "l_corpus_test=[\n",
    "['en', './test/en_partut-ud-test.txt'],\n",
    "['fr', './test/fr_sequoia-ud-test.txt'],\n",
    "['it', './test/it_partut-ud-test.txt'],\n",
    "['nl', './test/nl_lassysmall-ud-test.txt'],\n",
    "['sl', './test/sl_sst-ud-test.txt'],\n",
    "['es', './test/es_ancora-ud-test.txt'],\n",
    "['pt', './test/pt_bosque-ud-test.txt'],\n",
    "['de', './test/de_gsd-ud-test.txt'],\n",
    "['ca', './test/ca_ancora-ud-test.txt']\n",
    "]\n",
    "\n",
    "extract_bigrams(l_corpus_train, 'random', 600, 100, 'train_p2.dat')\n",
    "(x_train, y_train) = lectureDonnees('train_p2.dat', codeLangues)\n",
    "\n",
    "extract_bigrams(l_corpus_test, 'random', 500, 10, 'test_p2.dat')\n",
    "(x_test_2, y_test_2) = lectureDonnees('test_p2.dat', codeLangues)\n",
    "\n",
    "model = Sequential() # type de model \n",
    "nbLangues = len(codeLangues.keys()) \n",
    "model.add(Dense(units=100, activation='tanh', input_dim=28*28)) # premiere couche du RNN \n",
    "model.add(Dense(units=nbLangues, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=16, validation_split=0.2)\n",
    "l_pred = model.predict(x_test, batch_size=None, verbose=1, steps=None) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "ieqR_BnWfegX",
    "outputId": "6e246099-10e7-49fc-b43f-bd889b455ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[[10.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 10.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 10.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 10.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. 10.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 10.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 10.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. 10.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. 10.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(l_pred)\n",
    "pred_bool = []\n",
    "\n",
    "\n",
    "for i in l_pred : \n",
    "  max = argmax(i)\n",
    "  sous_l = []\n",
    "  for j in range(len(i)) :\n",
    "    if j == max : \n",
    "      sous_l.append(1)\n",
    "    else : \n",
    "      sous_l.append(0)\n",
    "  pred_bool.append(sous_l)\n",
    "\n",
    "#print(pred_bool)\n",
    "\n",
    "\n",
    "mat_vf = np.zeros(shape = [2,9])\n",
    "\n",
    "for index, i in enumerate(y_test) : \n",
    "  if argmax(i) == argmax(pred_bool[index]) : \n",
    "    mat_vf[0][argmax(i)] +=1 \n",
    "  else : \n",
    "    mat_vf[1][argmax(i)] +=1 \n",
    "\n",
    "print(mat_vf)\n",
    "\n",
    "\n",
    "mat_confusion = np.zeros(shape = [9,9])\n",
    "\n",
    "for index, i in enumerate(y_test) : \n",
    "  if argmax(i) == argmax(pred_bool[index]) : \n",
    "    mat_confusion[argmax(pred_bool[index])][argmax(i)] +=1 \n",
    "  else : \n",
    "    mat_confusion[argmax(i)][pred_bool[index]] +=1 \n",
    "\n",
    "print(mat_confusion)\n",
    "\n",
    "\n",
    "y_test_ind = []\n",
    "for i in y_test : \n",
    "  y_test_ind.append(argmax(i))\n",
    "\n",
    "pred_ind = []\n",
    "for i in pred_bool : \n",
    "  pred_ind.append(argmax(i))\n",
    "\n",
    "cm = confusion_matrix(y_test_ind, pred_ind)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RftiRjmOR6l"
   },
   "source": [
    "On obtient une matrice de confusion indiquant que tout est juste pour chacune des langues du premier pool.\n",
    "Precedemment nous avons observé que nos accuracy étaient à 1 pour ces langues, expliquant peut-être pourquoi nous n'observons aucune erreur de prédiction depuis cette matrice de confusion.\n",
    "\n",
    "On se retrouve dans un résultat quasi-parfait. Si ce n'était pas le cas, nous aurions d'autres carrés colorés dans notre matrice, indépendamment de la diagonale.\n",
    "\n",
    "Nous décidons de rajouter les mêmes dix langues que dans le premier projet pour voir si ces résultats sont similaires aux huit premières langues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MY37t8YRS0AI",
    "outputId": "a036bac8-dd9f-4548-e627-496ae7691514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langue : en code =  0\n",
      "langue : fr code =  1\n",
      "langue : it code =  2\n",
      "langue : nl code =  3\n",
      "langue : sl code =  4\n",
      "langue : es code =  5\n",
      "langue : pt code =  6\n",
      "langue : de code =  7\n",
      "langue : ca code =  8\n",
      "langue : af code =  9\n",
      "langue : el code =  10\n",
      "langue : be code =  11\n",
      "langue : ja code =  12\n",
      "langue : kk code =  13\n",
      "langue : la code =  14\n",
      "langue : ar code =  15\n",
      "langue : bg code =  16\n",
      "langue : bxr code =  17\n",
      "langue : cop code =  18\n",
      "traite corpus ./test/en_partut-ud-test.txt\n",
      "traite corpus ./test/fr_sequoia-ud-test.txt\n",
      "traite corpus ./test/it_partut-ud-test.txt\n",
      "traite corpus ./test/nl_lassysmall-ud-test.txt\n",
      "traite corpus ./test/sl_sst-ud-test.txt\n",
      "traite corpus ./test/es_ancora-ud-test.txt\n",
      "traite corpus ./test/pt_bosque-ud-test.txt\n",
      "traite corpus ./test/de_gsd-ud-test.txt\n",
      "traite corpus ./test/ca_ancora-ud-test.txt\n",
      "traite corpus ./test/af_afribooms-ud-test.txt\n",
      "traite corpus ./test/el_gdt-ud-test.txt\n",
      "traite corpus ./test/be_hse-ud-test.txt\n",
      "traite corpus ./test/ja_gsd-ud-test.txt\n",
      "traite corpus ./test/kk_ktb-ud-test.txt\n",
      "traite corpus ./test/la_ittb-ud-test.txt\n",
      "traite corpus ./test/ar_nyuad-ud-test.txt\n",
      "traite corpus ./test/be_hse-ud-test.txt\n",
      "traite corpus ./test/bxr_bdt-ud-test.txt\n",
      "traite corpus ./test/cop_scriptorium-ud-test.txt\n",
      "test_3.dat\n",
      "190 exemples lus\n",
      "traite corpus ./train/en_partut-ud-train.txt\n",
      "traite corpus ./train/fr_sequoia-ud-train.txt\n",
      "traite corpus ./train/it_partut-ud-train.txt\n",
      "traite corpus ./train/nl_lassysmall-ud-train.txt\n",
      "traite corpus ./train/sl_sst-ud-train.txt\n",
      "traite corpus ./train/es_ancora-ud-train.txt\n",
      "traite corpus ./train/pt_bosque-ud-train.txt\n",
      "traite corpus ./train/de_gsd-ud-train.txt\n",
      "traite corpus ./train/ca_ancora-ud-train.txt\n",
      "traite corpus ./train/af_afribooms-ud-train.txt\n",
      "traite corpus ./train/el_gdt-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/ja_gsd-ud-train.txt\n",
      "traite corpus ./train/kk_ktb-ud-train.txt\n",
      "traite corpus ./train/la_ittb-ud-train.txt\n",
      "traite corpus ./train/ar_nyuad-ud-train.txt\n",
      "traite corpus ./train/be_hse-ud-train.txt\n",
      "traite corpus ./train/bxr_bdt-ud-train.txt\n",
      "traite corpus ./train/cop_scriptorium-ud-train.txt\n",
      "train_3.dat\n",
      "1900 exemples lus\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 4ms/step - loss: 2.8731 - accuracy: 0.2260 - val_loss: 2.5539 - val_accuracy: 0.4342\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4432 - accuracy: 0.4622 - val_loss: 2.0987 - val_accuracy: 0.5500\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.0535 - accuracy: 0.5588 - val_loss: 1.8190 - val_accuracy: 0.5921\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.8029 - accuracy: 0.6043 - val_loss: 1.5799 - val_accuracy: 0.6947\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.5571 - accuracy: 0.6996 - val_loss: 1.3745 - val_accuracy: 0.7342\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.7102 - val_loss: 1.2085 - val_accuracy: 0.7789\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.2254 - accuracy: 0.7280 - val_loss: 1.0749 - val_accuracy: 0.7526\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.0822 - accuracy: 0.7472 - val_loss: 0.9652 - val_accuracy: 0.7868\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9797 - accuracy: 0.7479 - val_loss: 0.8835 - val_accuracy: 0.7763\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.9014 - accuracy: 0.7542 - val_loss: 0.8176 - val_accuracy: 0.7711\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.8240 - accuracy: 0.7466 - val_loss: 0.7596 - val_accuracy: 0.7579\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7519 - accuracy: 0.7761 - val_loss: 0.7151 - val_accuracy: 0.7816\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7419 - accuracy: 0.7629 - val_loss: 0.6835 - val_accuracy: 0.7605\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7077 - accuracy: 0.7496 - val_loss: 0.6541 - val_accuracy: 0.7789\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.7633 - val_loss: 0.6315 - val_accuracy: 0.7868\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7143 - accuracy: 0.7347 - val_loss: 0.6122 - val_accuracy: 0.7737\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.7525 - val_loss: 0.5960 - val_accuracy: 0.7711\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.7510 - val_loss: 0.5834 - val_accuracy: 0.7605\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.7812 - val_loss: 0.5740 - val_accuracy: 0.7684\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7875 - val_loss: 0.5612 - val_accuracy: 0.7789\n",
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l_corpus_train=[\n",
    "['en', './train/en_partut-ud-train.txt'],\n",
    "['fr', './train/fr_sequoia-ud-train.txt'],\n",
    "['it', './train/it_partut-ud-train.txt'],\n",
    "['nl', './train/nl_lassysmall-ud-train.txt'],\n",
    "['sl', './train/sl_sst-ud-train.txt'],\n",
    "['es', './train/es_ancora-ud-train.txt'],\n",
    "['pt', './train/pt_bosque-ud-train.txt'],\n",
    "['de', './train/de_gsd-ud-train.txt'],\n",
    "['ca', './train/ca_ancora-ud-train.txt'],\n",
    "['af', './train/af_afribooms-ud-train.txt'],\n",
    "['el', './train/el_gdt-ud-train.txt'],\n",
    "['be', './train/be_hse-ud-train.txt'],\n",
    "['ja', './train/ja_gsd-ud-train.txt'],\n",
    "['kk', './train/kk_ktb-ud-train.txt'],\n",
    "['la', './train/la_ittb-ud-train.txt'], \n",
    "['ar', './train/ar_nyuad-ud-train.txt'], \n",
    "['bg','./train/be_hse-ud-train.txt'], \n",
    "['bxr', './train/bxr_bdt-ud-train.txt'],\n",
    "['cop', './train/cop_scriptorium-ud-train.txt']\n",
    "]\n",
    "\n",
    "codeLangues = calculeCodeLangues(l_corpus_train)\n",
    "l_id = l_identifiants(codeLangues)\n",
    "\n",
    "l_corpus_test=[\n",
    "['en', './test/en_partut-ud-test.txt'],\n",
    "['fr', './test/fr_sequoia-ud-test.txt'],\n",
    "['it', './test/it_partut-ud-test.txt'],\n",
    "['nl', './test/nl_lassysmall-ud-test.txt'],\n",
    "['sl', './test/sl_sst-ud-test.txt'],\n",
    "['es', './test/es_ancora-ud-test.txt'],\n",
    "['pt', './test/pt_bosque-ud-test.txt'],\n",
    "['de', './test/de_gsd-ud-test.txt'],\n",
    "['ca', './test/ca_ancora-ud-test.txt'],\n",
    "['af', './test/af_afribooms-ud-test.txt'],\n",
    "['el', './test/el_gdt-ud-test.txt'],\n",
    "['be', './test/be_hse-ud-test.txt'],\n",
    "['ja', './test/ja_gsd-ud-test.txt'],\n",
    "['kk', './test/kk_ktb-ud-test.txt'],\n",
    "['la', './test/la_ittb-ud-test.txt'],\n",
    "['ar', './test/ar_nyuad-ud-test.txt'], \n",
    "['bg','./test/be_hse-ud-test.txt'], \n",
    "['bxr', './test/bxr_bdt-ud-test.txt'],\n",
    "['cop', './test/cop_scriptorium-ud-test.txt']\n",
    "]\n",
    "\n",
    "extract_bigrams(l_corpus_test, 'random', 500, 10, 'test_3.dat')\n",
    "(x_test_3, y_test_3) = lectureDonnees('test_3.dat', codeLangues)\n",
    "\n",
    "\n",
    "extract_bigrams(l_corpus_train, 'random', 600, 100, 'train_3.dat')\n",
    "(x_train_3, y_train_3) = lectureDonnees('train_3.dat', codeLangues)\n",
    "\n",
    "model = Sequential() # type de model \n",
    "nbLangues = len(codeLangues.keys()) \n",
    "model.add(Dense(units=100, activation='tanh', input_dim=28*28)) # premiere couche du RNN \n",
    "model.add(Dense(units=nbLangues, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "model.fit(x_train_3, y_train_3, epochs=20, batch_size=16, validation_split=0.2)\n",
    "\n",
    "l_pred = model.predict(x_test_3, batch_size=None, verbose=1, steps=None) \n",
    "\n",
    "\n",
    "pred_bool = []\n",
    "\n",
    "\n",
    "for i in l_pred : \n",
    "  max = argmax(i)\n",
    "  sous_l = []\n",
    "  for j in range(len(i)) :\n",
    "    if j == max : \n",
    "      sous_l.append(1)\n",
    "    else : \n",
    "      sous_l.append(0)\n",
    "  pred_bool.append(sous_l)\n",
    "\n",
    "y_test_ind = []\n",
    "for i in y_test_3 : \n",
    "  y_test_ind.append(argmax(i))\n",
    "\n",
    "pred_ind = []\n",
    "for i in pred_bool : \n",
    "  pred_ind.append(argmax(i))\n",
    "\n",
    "cm = confusion_matrix(y_test_ind, pred_ind)\n",
    "\n",
    "plot_confusion_matrix(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXxwgqoBFjIo"
   },
   "source": [
    "Nous reconnaissons dans les valeurs de cette seconde matrice les résultats que nous obtenions dans la première en haut à gauche : les résultats sont quasi-parfaits. Nous observons plus loin sur la diagonale que seules quelques langues ont un résultat \"parfait\", mais aussi qu'il y en a certaines qui ne le sont pas du tout, ce que l'on observe par l'absence de certains carrés colorés dans la diagonale. \n",
    "\n",
    "Nous retrouvons ainsi les langues pour lesquelles l'accuracy n'était pas à 1, et pouvons voir avec quelles langues elles sont confondues. Nous remarquons ainsi qu'il n'y a pas de stricte symétrie entre les langues confondues, si c'était le cas nous osbervrions des carrés de mêmes couleurs au sein des lignes et des colonnes de même indice.\n",
    "\n",
    "\n",
    "Pour continuer l'analyse des langues et de leurs similarités, nous pourrions retourner au niveau des bigrammes eux-mêmes, et les comparer entre les langues pour comprendre pourquoi le classifieur fait des erreurs de détection. Nous avons toutefois déjà une première idée de la proximité de langues entre elles à partir de celles qui sont confondues : s'il y a ces erreurs, c'est qu'il y a des fréquences de bigrammes qui sont semblables entre des langues et qui par conséquent sont mal attribuées par le classifieur.\n",
    "\n",
    "Les familles de langue ne sont pas détectables à partir de cette matrice de confusion, premièrement parce que nous ne les avons pas définies, mais ensuite parce que nous ne savons pas quels sont les bigrammes qui ont donné ces résultats. De plus, l'ordre de nos langues a été déterminé par l'import dans le classifieur, et pas par rapport à une proximité entre elles : si c'était le cas, alors nous pourrions conclure quant au lien entre leur proximité et les erreurs du classifieur. Affiner les résultats de ce projet passerait ainsi par une classification des langues selon des critères linguistiques, ainsi qu'étymologie des différents bigrammes."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "detecte_langue.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
