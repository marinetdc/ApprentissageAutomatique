{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj62zlzJjn7x"
   },
   "source": [
    "# **TP2 Introduction à l'Apprentissage Automatique**\n",
    "## Anaïs ARTAUD & Marine TROADEC  \n",
    "### Master 1 Sciences Cognitives\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiEuU__gkOSV"
   },
   "source": [
    "Nous avons décidé de traiter les 2 dernières études du sujet :   \n",
    "\n",
    "* l'introduction de bruit dans les données \n",
    "* la présentation de caractères inconnus au réseau\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sa1Lrq28bBc",
    "outputId": "85c6c9ea-6763-4b62-f0e4-f8d0be06b353"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emnist\n",
      "  Downloading emnist-0.0-py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: numpy in /Users/marinetroadec/opt/anaconda3/lib/python3.8/site-packages (from emnist) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /Users/marinetroadec/opt/anaconda3/lib/python3.8/site-packages (from emnist) (4.47.0)\n",
      "Requirement already satisfied: requests in /Users/marinetroadec/opt/anaconda3/lib/python3.8/site-packages (from emnist) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marinetroadec/opt/anaconda3/lib/python3.8/site-packages (from requests->emnist) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/marinetroadec/opt/anaconda3/lib/python3.8/site-packages (from requests->emnist) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/marinetroadec/opt/anaconda3/lib/python3.8/site-packages (from requests->emnist) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/marinetroadec/opt/anaconda3/lib/python3.8/site-packages (from requests->emnist) (1.25.9)\n",
      "Installing collected packages: emnist\n",
      "Successfully installed emnist-0.0\n"
     ]
    }
   ],
   "source": [
    "# Import \n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import sklearn\n",
    "!pip install emnist\n",
    "from emnist import list_datasets\n",
    "from random import randint, uniform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myN0-u898C64"
   },
   "source": [
    "\n",
    "# Récupération des données et visualisation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82mWYy1z03aC"
   },
   "source": [
    "## On récupère les données de train et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6B2tyHV0RGF",
    "outputId": "d933ec5a-b399-4409-c85d-731a4f5d77d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 14.7M  100 14.7M    0     0  1033k      0  0:00:14  0:00:14 --:--:-- 1047k\n",
      "tar: Error opening archive: Failed to open 'mnist.tgz'\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'#wget http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_Apprentissage_Automatique/mnist.tgz\\ncurl http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_AA/mnist.tgz\\ntar xvfz mnist.tgz\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4ee86ae00100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#wget http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_Apprentissage_Automatique/mnist.tgz\\ncurl http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_AA/mnist.tgz\\ntar xvfz mnist.tgz\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2369\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2371\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2372\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'#wget http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_Apprentissage_Automatique/mnist.tgz\\ncurl http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_AA/mnist.tgz\\ntar xvfz mnist.tgz\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "##wget http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_Apprentissage_Automatique/mnist.tgz\n",
    "curl http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_AA/mnist.tgz\n",
    "tar xvfz mnist.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_olsRxA1CeL"
   },
   "source": [
    "## On met en forme les données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IG-ave69Gkyp"
   },
   "outputs": [],
   "source": [
    "num_categories = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyE8xJTOG8xN",
    "outputId": "5cf7e0fc-a54e-42a8-c451-29d74b5ee566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lecture des donnees d'entrée depuis le fichier :  data/train_image_file.txt\n",
      "lecture des donnees de sortie depuis le fichier :  data/train_label_file.txt\n",
      "x shape =  (60000, 28, 28, 1)\n",
      "y shape =  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "def lecture_images(nom_fichier_image, display=False):\n",
    "    try:                      \n",
    "        with open(nom_fichier_image) as f:\n",
    "            print(\"lecture des donnees d'entrée depuis le fichier : \", nom_fichier_image)\n",
    "            tab = np.asarray(list(map(lambda x: np.asarray([x.split()]).reshape(28, 28, 1), f.readlines()))).astype(\"float32\") / 255 # On divise par 255 \n",
    "# pour normaliser les données et ainsi faire converger le modèle plus rapidement\n",
    "            if display:\n",
    "                print(*tab, sep='\\n')\n",
    "            return tab\n",
    "    except IOError:\n",
    "        print(\"le fichier\", nom_fichier_image, \"n'existe pas\")\n",
    "        return np.asarray([])\n",
    "\n",
    "\n",
    "def lecture_labels(nom_fichier_labels):\n",
    "    print(\"lecture des donnees de sortie depuis le fichier : \", nom_fichier_labels)\n",
    "    try:\n",
    "        with open(nom_fichier_labels) as f:\n",
    "            return to_categorical(np.asarray(list(map(int, f.readlines()))), num_categories)\n",
    "    except IOError:\n",
    "        print(\"le fichier\", nom_fichier_labels, \"n'existe pas\")\n",
    "        return to_categorical(np.asarray([]), num_categories)\n",
    "\n",
    "\n",
    "x_train = lecture_images('data/train_image_file.txt')\n",
    "y_train = lecture_labels('data/train_label_file.txt')\n",
    "\n",
    "\n",
    "print('x shape = ', x_train.shape)\n",
    "print('y shape = ', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvnYb-267zOY"
   },
   "source": [
    "## Visualisation de la première image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "Fl48BJ2t7mdq",
    "outputId": "67cde0cb-be00-4da2-e4a7-65d1b07417e1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le chiffre détecté à la première image est  (array([5]),)\n"
     ]
    }
   ],
   "source": [
    "imgplot = plt.imshow(x_train[0].reshape(28,28), cmap='gray')\n",
    "plt.show()\n",
    "print(\"Le chiffre détecté à la première image est \", np.where(y_train[0]==1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWsQgvNTKrw7"
   },
   "source": [
    "# Construction et apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ov_pD_6An7Ah"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jL8kWVEXqe6g"
   },
   "outputs": [],
   "source": [
    "def build_model(conv2d_filters=32, conv2d_kernel_size=(2, 2), conv2d_strides=(1, 1), conv2d_activation='relu', conv2d_input_shape=(28, 28, 1), \n",
    "                pool2d_pool_size=(2, 2), pool2D_strides=(2, 2), dropout_value=0.5, dense_activation='softmax', model_optimizer='adam', model_loss='mse'):\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=conv2d_filters, kernel_size=conv2d_kernel_size, strides=conv2d_strides, activation=conv2d_activation, input_shape=conv2d_input_shape),\n",
    "        MaxPooling2D(pool_size=pool2d_pool_size, strides=pool2D_strides),\n",
    "        Flatten(),\n",
    "        Dropout(dropout_value),\n",
    "        Dense(num_categories, activation=dense_activation),\n",
    "    ])\n",
    "    model.summary()\n",
    "    model.compile(optimizer=model_optimizer, loss=model_loss, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWRTZ5FJqrvL",
    "outputId": "63be85f2-a6a1-44f6-fd3d-0d3cfd661058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 27, 27, 32)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                54090     \n",
      "=================================================================\n",
      "Total params: 54,250\n",
      "Trainable params: 54,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0375 - accuracy: 0.7622 - val_loss: 0.0112 - val_accuracy: 0.9287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcbb8ab1580>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAngA5yRLVy8"
   },
   "source": [
    "### **Autre model**\n",
    "\n",
    "Le modèle ci dessous présente 2 couches de convolutions et de pooling. La fonction d'acitvation choisi est la fonction *sigmoid*. De plus le nombre de filtre à la seconde couche est de *64*. Le padding défini est *same*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZT0YfkXaPr3p"
   },
   "outputs": [],
   "source": [
    "def build_model_other(conv2d_filters=32,conv2d_filters2= 64, conv2d_kernel_size=(5, 5), conv2d_strides=(1, 1), conv2d_activation='sigmoid', conv2d_input_shape=(28, 28, 1), \n",
    "                pool2d_pool_size=(2, 2), pool2D_strides=(2, 2), dropout_value=0.5, dense_activation='softmax', model_optimizer='adam', model_loss='mse'):\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=conv2d_filters,padding = 'same',kernel_size=conv2d_kernel_size, strides=conv2d_strides, activation=conv2d_activation, input_shape=conv2d_input_shape),\n",
    "        MaxPooling2D(pool_size=pool2d_pool_size, strides=pool2D_strides),\n",
    "        Conv2D(filters=conv2d_filters2, padding = 'same', kernel_size=conv2d_kernel_size, strides=conv2d_strides, activation=conv2d_activation, input_shape=conv2d_input_shape),\n",
    "        MaxPooling2D(pool_size=pool2d_pool_size, strides=pool2D_strides),\n",
    "        Flatten(),\n",
    "        #Dropout(dropout_value),\n",
    "        Dense(num_categories, activation=dense_activation),\n",
    "    ])\n",
    "    model.summary()\n",
    "    model.compile(optimizer=model_optimizer, loss=model_loss, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQqrhyqkQy1L",
    "outputId": "7d6af3e7-1a39-4a7f-924b-28efd4a4e5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 83,466\n",
      "Trainable params: 83,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "375/375 [==============================] - 26s 70ms/step - loss: 0.0906 - accuracy: 0.1493 - val_loss: 0.0204 - val_accuracy: 0.8688\n",
      "Epoch 2/2\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.0172 - accuracy: 0.8898 - val_loss: 0.0089 - val_accuracy: 0.9447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcbb8f873a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_other = build_model_other()\n",
    "model_other.fit(x_train, y_train, epochs = 2, batch_size = batch_size, validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLoH6Krl0878"
   },
   "source": [
    "## On met en forme les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6iN2imATLaFu",
    "outputId": "d59c0061-efc2-4693-9456-dc39d9dbe7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lecture des donnees d'entrée depuis le fichier :  data/test_image_file.txt\n",
      "lecture des donnees de sortie depuis le fichier :  data/test_label_file.txt\n"
     ]
    }
   ],
   "source": [
    "x_test = lecture_images('data/test_image_file.txt')\n",
    "y_test = lecture_labels('data/test_label_file.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2eKYXeXLjXn"
   },
   "source": [
    "## On évalue les prédictions sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "f02slM5uLpY5"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_tr, y_tr, x_te, y_te):\n",
    "    model.fit(x_tr, y_tr, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "    score = model.evaluate(x_te, y_te, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_GfAMNrEBtq",
    "outputId": "e3c6672a-aedc-48ce-b88c-c21984c52117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0121 - accuracy: 0.9221 - val_loss: 0.0070 - val_accuracy: 0.9562\n",
      "Test loss: 0.008573678322136402\n",
      "Test accuracy: 0.9460999965667725\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "qkVbi5vepXOY",
    "outputId": "98a3b3fb-e8e9-48d9-df9c-03eec5e3e652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 30s 70ms/step - loss: 0.0071 - accuracy: 0.9567 - val_loss: 0.0049 - val_accuracy: 0.9677\n",
      "Test loss: 0.005504149477928877\n",
      "Test accuracy: 0.9649999737739563\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_other, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1P_WGgS16qUK"
   },
   "source": [
    "# Caractères inconnus. Que se passe-t-il lorsqu’on présente au réseau une entrée qui ne correspond pas à un chiffre ? serait-il possible de créer une nouvelle classe qui corresponde aux images qui ne sont pas des chiffres ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMQE_-OvAT9f"
   },
   "source": [
    "- Chargement des données\n",
    "\n",
    "> Ici nous chargeons des données venant de la base EMNIST, cette dernière comprend des lettres et autres caractères. Elles sont sous la meme forme que les données de MNIST.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbKVeKpI6v-4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading emnist.zip: 355MB [06:13, 1.09MB/s] "
     ]
    }
   ],
   "source": [
    "# Import des lettres de la dataset  EMNIST\n",
    "list_datasets()\n",
    "from emnist import extract_training_samples\n",
    "images_train, labels_train = extract_training_samples('letters')\n",
    "from emnist import extract_test_samples\n",
    "images_test, labels_test = extract_test_samples('letters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WvGT0OnB_0h"
   },
   "outputs": [],
   "source": [
    "# Liste contenant l'alphabet\n",
    "import string \n",
    "def listAlphabet():\n",
    "  return list(string.ascii_lowercase)\n",
    "alphabet = listAlphabet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3I13gliyCyBV",
    "outputId": "d1b48092-50e3-4d59-fb8c-688e3b16698c"
   },
   "outputs": [],
   "source": [
    "xl_train = images_train.reshape(124800,28, 28, 1).astype(\"float32\") / 255\n",
    "xl_test = images_test.reshape(labels_test.shape[0],28, 28, 1).astype(\"float32\") / 255\n",
    "yl_train = np.zeros((124800,27))\n",
    "for j,i in zip(range(0,124800),labels_train) : \n",
    "  yl_train[j][i] = 1 \n",
    "yl_test = np.zeros((labels_test.shape[0],27))\n",
    "for j,i in zip(range(0,labels_test.shape[0]),labels_test) : \n",
    "  yl_test[j][i] = 1 \n",
    "print('x train shape = ', xl_train.shape)\n",
    "print('y train shape = ', yl_train.shape)\n",
    "print('x test shape = ', xl_test.shape)\n",
    "print('y test shape = ', yl_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaL7wRwp7yCk"
   },
   "source": [
    "Les données mises en forme ci-dessus peuvent servir à entrainer un modèle à la reconnaissance des lettres. Leur mise en forme correspond à celle faite pour les données de MNSIT au dessus. Nous n'utliserons par la suite seulement les données xl_trainet xl_test. Il serait possible de combiner les données d'entrée x de lettres avec les chiffres afin d'entrainer un autre model capable de reconnaitres l'ensemble de ces caractères. Cela demanderai de changer les données de y afin que la longueur du vecteur OneHot soit 10 + 27. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5RQRb7PBMJS"
   },
   "source": [
    "- Visulasition des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "abGVHR8yBLub",
    "outputId": "3f49f4eb-3037-46ed-cc42-4d8313d27666"
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(images_train[0].reshape(28,28), cmap='gray')\n",
    "plt.show()\n",
    "print(\"Le chiffre décté à la première image est \", alphabet[labels_train[0]-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZy7rksS5vdI"
   },
   "source": [
    "Ici nous regardons avec lemodèle entrainé seulement pour reconnaitre des chiffres et paramétrée pour la reconnaissance des chiffres de 0 à 9 quel est la classe prose par la lettre W. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqLPkw0ABqCU"
   },
   "outputs": [],
   "source": [
    "yl_pred = model.predict(xl_train[0:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1ulP2glBVIs",
    "outputId": "b2f0764b-c340-486e-f0c8-6457fbaece89"
   },
   "outputs": [],
   "source": [
    "print(np.argmax(yl_pred[0]))\n",
    "print(yl_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bkoFK3LjJCk"
   },
   "source": [
    "La lettre W est reconnue comme étant le chiffre 3, mais les prédictions sont très basses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyfrNJp-AUt0"
   },
   "source": [
    "- Mise en forme des données (les lettres et les chiffres sont concaténées) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6Slaw5Tixgv"
   },
   "outputs": [],
   "source": [
    "x_train2 = np.concatenate((x_train, xl_train[:8000])) # nous récupérons 8000 images de lettres afin d'entrainer le model à niveau égal en les différentes valeurs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtuPrly-prG5"
   },
   "outputs": [],
   "source": [
    "a = np.array([[0,0,0,0,0,0,0,0,0,0,1] for i in range(0,8000)])\n",
    "y_train2 = np.concatenate((y_train, [[0] for i in range(0,60000)]),axis = 1 ) # les lettres sont associée dans le model à une 11ième classe.  \n",
    "y_train2 = np.concatenate((y_train2, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uwveqze5RS1"
   },
   "outputs": [],
   "source": [
    "x_test2 = np.concatenate((x_test, xl_test[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "152KLjhLmEmY",
    "outputId": "ec5a379e-eb30-484e-b650-a02b4055b241"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 11)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[0,0,0,0,0,0,0,0,0,0,1] for i in range(0,1000)])\n",
    "y_test2 = np.concatenate((y_test, [[0] for i in range(0,10000)]),axis = 1 )\n",
    "y_test2 = np.concatenate((y_test2, a))\n",
    "y_test2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IW3knjkAdqg"
   },
   "source": [
    "- Entrainenement du modele "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHngkM_kronk",
    "outputId": "26cff110-c77b-48a8-c45c-0f8f23224d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 27, 27, 32)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                59499     \n",
      "=================================================================\n",
      "Total params: 59,659\n",
      "Trainable params: 59,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "425/425 [==============================] - 21s 49ms/step - loss: 0.0311 - accuracy: 0.7790 - val_loss: 0.0909 - val_accuracy: 0.3862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fab91597a50>"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_categories = 11\n",
    "model_2 = build_model()\n",
    "model_2.fit(x_train2, y_train2, epochs = epochs, batch_size = batch_size, validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn9t9loeAkMo"
   },
   "source": [
    "- Evaluation du modele \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ICLweiT4ozI",
    "outputId": "5e1f075e-cb80-4b69-e67f-ee6da8174b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479/479 [==============================] - 23s 48ms/step - loss: 0.0137 - accuracy: 0.9033 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
      "Test loss: 0.020491568371653557\n",
      "Test accuracy: 0.8567273020744324\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_2,x_train2,y_train2,x_test2,y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MCbz8bL6nnb"
   },
   "source": [
    "La fonction ci-dessous renvoie la fréquence des erreurs de prédiction par classe du model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVwxQaBX7yCw"
   },
   "outputs": [],
   "source": [
    "def err_par_classe(pred , y, taille) :  \n",
    "    count = [0 for i in range(11)] # nombre de chaque caractère qui doit etre reconnu nombre de (0,1,2,3,4,5,6,7,8,9, lettre)\n",
    "    err = [0 for i in range(11)]. # liste des erreurs de prédictions selon les caractères \n",
    "    for j in range(taille) :        \n",
    "        count[np.argmax(y[j])] += 1\n",
    "        if np.argmax(pred[j]) != np.argmax(y[j]) : \n",
    "          err[np.argmax(y[j])] += 1      \n",
    "    for i in range(11) :\n",
    "      err[i] /= count[i]\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uo2KjAQM9HRG",
    "outputId": "a82fe07f-50ef-4e02-d6a0-de7fd98b0810"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.017346938775510204,\n",
       " 0.016740088105726872,\n",
       " 0.06782945736434108,\n",
       " 0.07326732673267326,\n",
       " 0.06415478615071284,\n",
       " 0.10650224215246637,\n",
       " 0.021920668058455117,\n",
       " 0.07587548638132295,\n",
       " 0.07905544147843943,\n",
       " 0.061446977205153616,\n",
       " 1.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_par_classe(model_2.predict(x_test2), y_test2, 11000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4vtBpLN9rqD"
   },
   "source": [
    "On peut remarquer que le modèle n'arrive pas à associer des lettres à une classe particulière qui reconnaitrait que les lettres. En effet cette classe doit normalement être associée à toutes les lettres de l'alphabet. \n",
    "Cela peut être du à la ressemblance de certaines lettres avec des chiffres, le modele arrive donc mieux à trouver les ressemblances entre certaines lettres et certains chiffres qu'entre toutes les lettres entre elles. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oy_Gx9X2H3WO"
   },
   "source": [
    "# Bruit. \n",
    "\n",
    "On peut de manière aléatoire modifier la valeur de certain pixels dans l’image. Comment est ce que les performances décroissent en fonction du taux de pixels modifiés. Que se passe-t-il lorsqu’on ajoute du bruit dans les données d’apprentissage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDecsZAToG9-"
   },
   "source": [
    "* Implémentation de la fonction *add_noise* qui va créer le bruit dans les données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Us9whx5H6hr"
   },
   "outputs": [],
   "source": [
    "def add_noise(x, noise_ratio=0.1):\n",
    "    x_copy = x.copy()            #On travaille ici sur une copie des données pour ne pas modifier les données de bases \n",
    "    nb_pixel = img_rows * img_cols * noise_ratio  \n",
    " #      \n",
    "    for xi in x_copy:\n",
    "        coords_set = set()     #Pour supprimer les doublons\n",
    "        while len(coords_set) < nb_pixel:\n",
    "            x, y = 29, 29     #On fixe x et y à une valeur impossible pour remplir la liste\n",
    "            while (x, y) == (29, 29):    #Tant que l'aléa retourne (29, 29), on relance un calcul aléatoire pour avoir une nouvelle coordonnées x, y\n",
    "                x, y = randint(0, img_cols - 1), randint(0, img_rows - 1) \n",
    "            coords_set.add((x, y))\n",
    "        for x, y in coords_set:\n",
    "            xi[x][y] = uniform(0, 1) #Pour chaque coordonnée dans le set, on change la valeur du pixel avec une valeur aléatoire entre 0 et 1\n",
    "    return x_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgASkxnEysLa"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "* On bruite les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT8tKzZJ1mqH"
   },
   "source": [
    "Ici, on bruite les données puis on les affiche à la suite des données non bruitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BtNSza-IjDH",
    "outputId": "544aab94-057b-4723-c38b-10f399af990b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "[[[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.32941177]\n",
      "  [0.7254902 ]\n",
      "  [0.62352943]\n",
      "  [0.5921569 ]\n",
      "  [0.23529412]\n",
      "  [0.14117648]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.87058824]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.94509804]\n",
      "  [0.7764706 ]\n",
      "  [0.7764706 ]\n",
      "  [0.7764706 ]\n",
      "  [0.7764706 ]\n",
      "  [0.7764706 ]\n",
      "  [0.7764706 ]\n",
      "  [0.7764706 ]\n",
      "  [0.7764706 ]\n",
      "  [0.6666667 ]\n",
      "  [0.20392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.2627451 ]\n",
      "  [0.44705883]\n",
      "  [0.28235295]\n",
      "  [0.44705883]\n",
      "  [0.6392157 ]\n",
      "  [0.8901961 ]\n",
      "  [0.99607843]\n",
      "  [0.88235295]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.98039216]\n",
      "  [0.8980392 ]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.54901963]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.06666667]\n",
      "  [0.25882354]\n",
      "  [0.05490196]\n",
      "  [0.2627451 ]\n",
      "  [0.2627451 ]\n",
      "  [0.2627451 ]\n",
      "  [0.23137255]\n",
      "  [0.08235294]\n",
      "  [0.9254902 ]\n",
      "  [0.99607843]\n",
      "  [0.41568628]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.3254902 ]\n",
      "  [0.99215686]\n",
      "  [0.81960785]\n",
      "  [0.07058824]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.08627451]\n",
      "  [0.9137255 ]\n",
      "  [1.        ]\n",
      "  [0.3254902 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.5058824 ]\n",
      "  [0.99607843]\n",
      "  [0.93333334]\n",
      "  [0.17254902]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.23137255]\n",
      "  [0.9764706 ]\n",
      "  [0.99607843]\n",
      "  [0.24313726]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.52156866]\n",
      "  [0.99607843]\n",
      "  [0.73333335]\n",
      "  [0.01960784]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.03529412]\n",
      "  [0.8039216 ]\n",
      "  [0.972549  ]\n",
      "  [0.22745098]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.49411765]\n",
      "  [0.99607843]\n",
      "  [0.7137255 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.29411766]\n",
      "  [0.9843137 ]\n",
      "  [0.9411765 ]\n",
      "  [0.22352941]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07450981]\n",
      "  [0.8666667 ]\n",
      "  [0.99607843]\n",
      "  [0.6509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01176471]\n",
      "  [0.79607844]\n",
      "  [0.99607843]\n",
      "  [0.85882354]\n",
      "  [0.13725491]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.14901961]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.3019608 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.12156863]\n",
      "  [0.8784314 ]\n",
      "  [0.99607843]\n",
      "  [0.4509804 ]\n",
      "  [0.00392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.52156866]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.20392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.23921569]\n",
      "  [0.9490196 ]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.20392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.4745098 ]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.85882354]\n",
      "  [0.15686275]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.4745098 ]\n",
      "  [0.99607843]\n",
      "  [0.8117647 ]\n",
      "  [0.07058824]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n",
      "Noisy\n",
      "[[[0.        ]\n",
      "  [0.1619673 ]\n",
      "  [0.        ]\n",
      "  [0.75543004]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.64498895]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01922476]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.10958749]\n",
      "  [0.        ]\n",
      "  [0.23896061]\n",
      "  [0.        ]\n",
      "  [0.72306937]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.50723463]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.14577185]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9720934 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.3156386 ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.272103  ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.16804375]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.46221194]\n",
      "  [0.70141065]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.6829528 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.76251435]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.69922113]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.83517045]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.0258727 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01176471]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.74996346]\n",
      "  [0.49411765]\n",
      "  [0.53333336]\n",
      "  [0.6862745 ]\n",
      "  [0.10196079]\n",
      "  [0.00191098]\n",
      "  [1.        ]\n",
      "  [0.96862745]\n",
      "  [0.49803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.4196386 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.11764706]\n",
      "  [0.14117648]\n",
      "  [0.36862746]\n",
      "  [0.21753415]\n",
      "  [0.6666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.88235295]\n",
      "  [0.6745098 ]\n",
      "  [0.99215686]\n",
      "  [0.9490196 ]\n",
      "  [0.7647059 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.5459663 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9527014 ]\n",
      "  [0.        ]\n",
      "  [0.19215687]\n",
      "  [0.93333334]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.9112938 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.9843137 ]\n",
      "  [0.3647059 ]\n",
      "  [0.32156864]\n",
      "  [0.32156864]\n",
      "  [0.73404264]\n",
      "  [0.15294118]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.894144  ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.9044045 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.83292115]\n",
      "  [0.7764706 ]\n",
      "  [0.7137255 ]\n",
      "  [0.96862745]\n",
      "  [0.94509804]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.3137255 ]\n",
      "  [0.6117647 ]\n",
      "  [0.41960785]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8039216 ]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.16862746]\n",
      "  [0.6039216 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.25066033]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.5478699 ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.28233585]\n",
      "  [0.05490196]\n",
      "  [0.00392157]\n",
      "  [0.29861942]\n",
      "  [0.99215686]\n",
      "  [0.3529412 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.06459171]\n",
      "  [0.09749093]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.54509807]\n",
      "  [0.4126204 ]\n",
      "  [0.74509805]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.86491764]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.04313726]\n",
      "  [0.74509805]\n",
      "  [0.99215686]\n",
      "  [0.27450982]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.5939264 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.2863287 ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.11175314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.13725491]\n",
      "  [0.73925465]\n",
      "  [0.88235295]\n",
      "  [0.627451  ]\n",
      "  [0.42352942]\n",
      "  [0.5292286 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.08343485]\n",
      "  [0.6111646 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.31764707]\n",
      "  [0.9411765 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.46666667]\n",
      "  [0.09803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.99446285]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.5817724 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.16959608]\n",
      "  [0.        ]\n",
      "  [0.28224558]\n",
      "  [0.7294118 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.5882353 ]\n",
      "  [0.10588235]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.0627451 ]\n",
      "  [0.3647059 ]\n",
      "  [0.9882353 ]\n",
      "  [0.99215686]\n",
      "  [0.21141465]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.60685825]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9764706 ]\n",
      "  [0.99215686]\n",
      "  [0.9764706 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.45787057]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.26559493]\n",
      "  [0.50980395]\n",
      "  [0.7176471 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8117647 ]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.80456656]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.24395177]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.2679451 ]\n",
      "  [0.5803922 ]\n",
      "  [0.8980392 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.98039216]\n",
      "  [0.7137255 ]\n",
      "  [0.        ]\n",
      "  [0.08325882]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.10871729]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.40265456]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09411765]\n",
      "  [0.44705883]\n",
      "  [0.8666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7882353 ]\n",
      "  [0.30588236]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.91439   ]\n",
      "  [0.        ]\n",
      "  [0.27031693]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09019608]\n",
      "  [0.25882354]\n",
      "  [0.8352941 ]\n",
      "  [0.02614462]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.31764707]\n",
      "  [0.558381  ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9041377 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.67058825]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7647059 ]\n",
      "  [0.2921873 ]\n",
      "  [0.03529412]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.39843184]\n",
      "  [0.18137607]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.52109563]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.19101308]\n",
      "  [0.        ]\n",
      "  [0.21568628]\n",
      "  [0.6745098 ]\n",
      "  [0.8862745 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.95686275]\n",
      "  [0.52156866]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.64713526]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.53333336]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.83137256]\n",
      "  [0.5294118 ]\n",
      "  [0.5176471 ]\n",
      "  [0.3361684 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.056601  ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.88754934]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.02121525]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.40861532]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9043181 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.27108425]\n",
      "  [0.2694793 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "x_test_noisy = add_noise(x_test)\n",
    "x_train_noisy = add_noise(x_train)\n",
    "print(\"Original\")\n",
    "print(x_test[0])\n",
    "print(\"Noisy\")\n",
    "print(x_train_noisy[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vg2BjaNh7dfo"
   },
   "source": [
    "On remarque que les données non bruitées comportent une certaine structure : les nuances de gris sont regroupées pour former l'image et tous les autres pixels sont blancs pour constituer le fond de l'image.  \n",
    "Dans les données bruitées, quelques pixels gris se retrouvent en dehors des groupes de pixels qui constituent les nuances de gris. Ces pixels \"parasites\" se retrouvent parmi les pixels blancs qui consitutent le fond de l'image et vont donc troubler l'image globale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJ5qKY9-3mD2"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "* Comparaison d'une image bruitée et non bruitée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "pPjU5j4uIuCA",
    "outputId": "affac6b9-bf5d-487a-ee06-7e667c554eb9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "plt.subplot(131)\n",
    "imgplot = plt.imshow(x_train[0].reshape(28,28), cmap='gray')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(132)\n",
    "imgplot = plt.imshow(x_train_noisy[0].reshape(28,28), cmap='gray')\n",
    "plt.title('Noisy')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWie5zNq3vCJ"
   },
   "source": [
    "On peut remarquer que l'image non bruitée est beaucoup plus nette que l'image bruitée, dans laquelle on retrouve les pixels \"parasites\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HH0O3bR4ACN"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "* On évalue les prédicitons sur les données bruitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBf4fd1cMGRR",
    "outputId": "75b462ee-aff4-476b-e8f6-d7f0b6c43aeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 20s 48ms/step - loss: 0.0102 - accuracy: 0.9340 - val_loss: 0.0061 - val_accuracy: 0.9617\n",
      "Test loss: 0.04333072528243065\n",
      "Test accuracy: 0.6991000175476074\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, x_train, y_train, x_test_noisy, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3psWnr8MIsr",
    "outputId": "722b5a87-5a8c-4e1a-fa58-1ca886b97376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 21s 49ms/step - loss: 0.0142 - accuracy: 0.9059 - val_loss: 0.0080 - val_accuracy: 0.9475\n",
      "Test loss: 0.00992005504667759\n",
      "Test accuracy: 0.9340999722480774\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, x_train_noisy, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O--pvPjMMKjI",
    "outputId": "d97d8713-efdf-4607-ec11-8c537acaf320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 20s 48ms/step - loss: 0.0117 - accuracy: 0.9241 - val_loss: 0.0075 - val_accuracy: 0.9508\n",
      "Test loss: 0.008985204622149467\n",
      "Test accuracy: 0.9412000179290771\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, x_train_noisy, y_train, x_test_noisy, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjQ4siC1D8Ve"
   },
   "source": [
    "# Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZriU0qt5cfW"
   },
   "source": [
    "Pour la première étude, sur la détection de lettres nous pouvons conclure qu'il faudrait entrainer le modèle à la détection de ces dernières afin qu'il soit efficace. En effet, créer une classe sensée être associée à toutes les lettres n'est pas pertinant comme la caligraphie des lettres se rapprochent des chiffres. \n",
    "\n",
    "\n",
    "Pour la seconde étude, on s'aperçoit que l'introduction de bruit dans les données nuit aux performances du modèle et donc sur la qualité de l'image. Aussi, la précision des prédicitons du modèle est altérée lorsque les données sont bruitées.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Le site internet suivant permet de visualiser les couches de convolution d'un modèle entrainé par la base de données MNIST : https://www.cs.ryerson.ca/~aharley/vis/conv/ développé par Adam W. Harley"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "QAngA5yRLVy8"
   ],
   "name": "TP2_ARTAUD_TROADEC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
